<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-04-20T07:38:25+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Cloud Native Journey</title><subtitle>Software Engineer/Architect</subtitle><author><name>Jaeguk Yun</name></author><entry><title type="html"></title><link href="http://localhost:4000/2023-04-16-install-lua/" rel="alternate" type="text/html" title="" /><published>2023-04-20T07:38:25+09:00</published><updated>2023-04-20T07:38:25+09:00</updated><id>http://localhost:4000/2023-04-16-install-lua</id><content type="html" xml:base="http://localhost:4000/2023-04-16-install-lua/"><![CDATA[<h2 id="lua-설치---사전준비">lua 설치 - 사전준비</h2>
<p>사전에 compiler가 설치되어 있어야 합니다.
Compiler가 설치되어 있지 않는 경우 다음을 실행합니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo yum update -y
yum groupinstall -y 'Development Tools'
</code></pre></div></div>
<h2 id="lua-설치">lua 설치</h2>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-R</span> <span class="nt">-O</span> http://www.lua.org/ftp/lua-5.4.4.tar.gz
<span class="nb">tar </span>zxf lua-5.4.4.tar.gz
<span class="nb">cd </span>lua-5.4.4
make all <span class="nb">test</span>
</code></pre></div></div>

<h2 id="lua-cli-실행">lua cli 실행</h2>
<p>lua를 실행하고 Hello World를 출력합니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>src/lua
str = "Hello World"
print(str)
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author></entry><entry><title type="html">Springboot기반 Redis @Transactional 어노테이션 사용</title><link href="http://localhost:4000/springboot/springboot-redis-transactional/" rel="alternate" type="text/html" title="Springboot기반 Redis @Transactional 어노테이션 사용" /><published>2023-04-18T00:00:00+09:00</published><updated>2023-04-18T00:00:00+09:00</updated><id>http://localhost:4000/springboot/springboot-redis-transactional</id><content type="html" xml:base="http://localhost:4000/springboot/springboot-redis-transactional/"><![CDATA[<h2 id="transactional">@Transactional</h2>
<p>Springboot 기반 Redis를 사용할 때 @Tranactional 사용하여 commit 과 rollback 을 처리할 수 있습니다.
rollback 은 exception을 throw하면 redis cache에 데이터가 저장되지 않습니다.<br />
PlatformTransactionManager를 Bean으로 등록되어 있고, 메소드에 @tranactional 어노테이션이 있고,메소드 로직에 @redisTemplate을 사용하고 있다면 이는 트랜잭션으로 처리되어, 예외(Exception)가 발생하면 데이터베이스에 처리했던 작업이 rollback 되고, 또한 로직에서 Redis에 저장했던 데이터 또한 저장되지 않고 rollback 됩니다.</p>

<p><strong>@Transactional</strong> 어노테이션이 있을때, Redis는 메서드 시작시 transaction 시작으로 <strong>MULTI</strong>, 메서드 종료시 transaction 커밋으로 <strong>EXEC</strong> 명령어를 실행하는 것으로 구현하고 있습니다. 만약 Exception이 발생하면 <strong>DISCARD</strong> 가 실행됩니다.</p>

<h2 id="redis-환경설정">Redis 환경설정</h2>
<p>Redis를 @Transaction 어노테이션과 함께 사용하고 싶을 때는 3가지 방법이 있습니다.</p>
<ul>
  <li>자바의 database configuration에 PlatformTransactionManager를 Bean으로 등록 사용</li>
  <li>자바의 Redis Configuration에 PlatformTransactionManager를 Bean으로 등록</li>
  <li>RedisTemplate 단독으로 사용하고 있다면 @EnableTransactionManagement 어노테이션 추가</li>
</ul>

<h4 id="java-database-configuration-사용---예시">java database configuration 사용 - 예시</h4>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Configuration</span>
<span class="nd">@PropertySource</span><span class="o">(</span><span class="s">"classpath:/application.properties"</span><span class="o">)</span>
<span class="nd">@EnableTransactionManagement</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">DatabaseConfiguration</span> <span class="o">{</span>
<span class="o">...</span>
	<span class="nd">@Bean</span>
	<span class="kd">public</span> <span class="nc">PlatformTransactionManager</span> <span class="nf">transactionManager</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
		<span class="k">return</span> <span class="k">new</span> <span class="nf">DataSourceTransactionManager</span><span class="o">(</span><span class="n">dataSource</span><span class="o">());</span>
	<span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<h4 id="redis-configuration-사용---예제">Redis Configuration 사용 - 예제</h4>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Configuration</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">RedisConfig</span> <span class="o">{</span>

  <span class="nd">@Bean</span>
  <span class="kd">public</span> <span class="nc">RedisTemplate</span><span class="o">&lt;?,</span> <span class="o">?&gt;</span> <span class="n">redisTemplate</span><span class="o">(</span><span class="nc">RedisConnectionFactory</span> <span class="n">redisConnectionFactory</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">RedisTemplate</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">[],</span> <span class="kt">byte</span><span class="o">[]&gt;</span> <span class="n">redisTemplate</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">RedisTemplate</span><span class="o">&lt;&gt;();</span>
    <span class="n">redisTemplate</span><span class="o">.</span><span class="na">setConnectionFactory</span><span class="o">(</span><span class="n">redisConnectionFactory</span><span class="o">);</span>
    <span class="n">redisTemplate</span><span class="o">.</span><span class="na">setEnableTransactionSupport</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span> <span class="c1">// redis Transaction On !</span>
    <span class="k">return</span> <span class="n">redisTemplate</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Bean</span> <span class="c1">// 만약 PlatformTransactionManager 등록이 안되어 있다면 해야함, 되어있다면 할 필요 없음</span>
  <span class="kd">public</span> <span class="nc">PlatformTransactionManager</span> <span class="nf">transactionManager</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">SQLException</span> <span class="o">{</span>
      <span class="c1">// 사용하고 있는 datasource 관련 내용, 아래는 JDBC</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nf">DataSourceTransactionManager</span><span class="o">(</span><span class="n">datasource</span><span class="o">());</span> 

    <span class="c1">// JPA 사용하고 있다면 아래처럼 사용하고 있음</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nf">JpaTransactionManager</span><span class="o">(</span><span class="n">entityManagerFactory</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<h4 id="redistemplate-단독으로-사용---예제">RedisTemplate 단독으로 사용 - 예제</h4>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Configuration</span>
<span class="nd">@EnableTransactionManagement</span>                                 
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">RedisTxContextConfiguration</span> <span class="o">{</span>

  <span class="nd">@Bean</span>
  <span class="kd">public</span> <span class="nc">StringRedisTemplate</span> <span class="nf">redisTemplate</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">StringRedisTemplate</span> <span class="n">template</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">StringRedisTemplate</span><span class="o">(</span><span class="n">redisConnectionFactory</span><span class="o">());</span>
    <span class="c1">// explicitly enable transaction support</span>
    <span class="n">template</span><span class="o">.</span><span class="na">setEnableTransactionSupport</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>              
    <span class="k">return</span> <span class="n">template</span><span class="o">;</span>
  <span class="o">}</span>

  <span class="nd">@Bean</span>
  <span class="kd">public</span> <span class="nc">PlatformTransactionManager</span> <span class="nf">transactionManager</span><span class="o">()</span> <span class="kd">throws</span> <span class="nc">SQLException</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nf">DataSourceTransactionManager</span><span class="o">();</span>   
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<h2 id="참조">참조</h2>
<p><a href="https://sabarada.tistory.com/178">사바라다는 차곡차곡</a></p>]]></content><author><name>Jaeguk Yun</name></author><category term="springboot" /><category term="springboot" /><summary type="html"><![CDATA[@Transactional Springboot 기반 Redis를 사용할 때 @Tranactional 사용하여 commit 과 rollback 을 처리할 수 있습니다. rollback 은 exception을 throw하면 redis cache에 데이터가 저장되지 않습니다. PlatformTransactionManager를 Bean으로 등록되어 있고, 메소드에 @tranactional 어노테이션이 있고,메소드 로직에 @redisTemplate을 사용하고 있다면 이는 트랜잭션으로 처리되어, 예외(Exception)가 발생하면 데이터베이스에 처리했던 작업이 rollback 되고, 또한 로직에서 Redis에 저장했던 데이터 또한 저장되지 않고 rollback 됩니다.]]></summary></entry><entry><title type="html">Redis 시작하기 - Redis with lua</title><link href="http://localhost:4000/cache/redis-with-lua/" rel="alternate" type="text/html" title="Redis 시작하기 - Redis with lua" /><published>2023-04-18T00:00:00+09:00</published><updated>2023-04-18T00:00:00+09:00</updated><id>http://localhost:4000/cache/redis-with-lua</id><content type="html" xml:base="http://localhost:4000/cache/redis-with-lua/"><![CDATA[<h2 id="lua-script-사용-명령어">Lua Script 사용 명령어</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">eval</span> <span class="s2">"lua script"</span> 키개수 <span class="o">[</span>KEY1,KEY2,...] <span class="o">[</span>ARGV1,ARGV2,...]
</code></pre></div></div>
<p>eval : lua script를 실행하기 위한 예약어<br />
lua script : Redis에서 실행하기 위한 lua script 입니다.<br />
키개수 : 파라메터로 받을 키(KEYS)개수 입니다. 이는 뒤에 추가적으로 붙을 선택 인자들 중 몇 개가 key인지를 lua가 알 수 있도록 하기 위함입니다.<br />
KEYS : 키개수 다음으로 오는 파라메터로 키개수 만큼 파라메터를 입력합니다. 그러면 lua는 KEYS 배열에 바인딩됩니다</p>

<ul>
  <li>0 이면  KEYS 파라메터가 없는 script입니다.</li>
  <li>1 이면  =&gt; 1 KEY1</li>
  <li>2 이면  =&gt; 2 KEY1 KEY2</li>
  <li>3 이면  =&gt; 3 KEY1 KEY2 KEY3
script에서는 KEYS[1], KEYS[2], KEYS[3]  이렇게 참조합니다.</li>
</ul>

<p>ARGV : ARGV는 lua에서 가변적으로 입력받는 파라메터입니다. 인자 [ARGV …]는 각각 lua에서 사용할 수 있도록 ARGV 배열에 바인팅 됩니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">eval</span> <span class="s2">"return { KEYS[1], KEYS[2], KEYS[3], ARGV[1], ARGV[2]}"</span> 3 k1 k2 k3 arg1 arg2

<span class="c"># 결과</span>
1<span class="o">)</span> <span class="s2">"k1"</span> 
2<span class="o">)</span> <span class="s2">"k2"</span>
3<span class="o">)</span> <span class="s2">"k3"</span>
4<span class="o">)</span> <span class="s2">"arg1"</span>
5<span class="o">)</span> <span class="s2">"arg2"</span>
</code></pre></div></div>

<h2 id="lua-script-load">lua script load</h2>
<p>아래와 같은 lua script를 redis-cli로 load시 반환값으로 출력되는 sha값으로 lua를 실행할 수 도 있습니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">local </span>current <span class="o">=</span> redis.call<span class="o">(</span><span class="s1">'zrangebyscore'</span>, KEYS[1], ARGV[1], ARGV[2], <span class="s1">'LIMIT'</span>, ARGV[3], ARGV[4]<span class="o">)</span>
<span class="k">if</span> <span class="o">(</span>current <span class="o">==</span> nil or current <span class="o">==</span> <span class="s1">''</span><span class="o">)</span> <span class="k">then
    return</span> <span class="s2">"failed"</span>
<span class="k">else
    for </span>i, mem <span class="k">in </span>pairs<span class="o">(</span>current<span class="o">)</span> <span class="k">do
        </span>redis.call<span class="o">(</span><span class="s1">'zincrby'</span>, KEYS[1], 1, mem<span class="o">)</span>
        <span class="k">return </span>current
    end
end
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat </span>ex01.lua | redis-cli <span class="nt">-x</span> script load

<span class="c"># 출력결과</span>
<span class="s2">"d57be6feffc53b0a7096b8a5d1c802c04ebc139e"</span>

</code></pre></div></div>
<p>redis-cli를 redis에 접속하여 다음과 같이 실행할 수 있습니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127.0.0.1:6379&gt; zadd <span class="nb">users</span>:point 0 jason
127.0.0.1:6379&gt; zadd <span class="nb">users</span>:point 10 mason 20 jane

127.0.0.1:6379&gt; evalsha d57be6feffc53b0a7096b8a5d1c802c04ebc139e 1 <span class="nb">users</span>:point <span class="nt">-inf</span> inf 0
</code></pre></div></div>
<h2 id="참고">참고</h2>
<p><a href="https://code-factory.tistory.com/13">코드공장</a>
<a href="https://luran.me/381">everydayminder</a>
<a href="http://www.w3big.com/ko/redis/sorted-sets-zrangebyscore.html#gsc.tab=0">Redis 코스</a></p>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><category term="lua" /><summary type="html"><![CDATA[Lua Script 사용 명령어]]></summary></entry><entry><title type="html">Redis 시작하기 - RediSearch</title><link href="http://localhost:4000/cache/installl-redisearch-on-docker/" rel="alternate" type="text/html" title="Redis 시작하기 - RediSearch" /><published>2023-04-17T00:00:00+09:00</published><updated>2023-04-17T00:00:00+09:00</updated><id>http://localhost:4000/cache/installl-redisearch-on-docker</id><content type="html" xml:base="http://localhost:4000/cache/installl-redisearch-on-docker/"><![CDATA[<h2 id="redisearch-소개">RediSearch 소개</h2>
<p>Redis는 다음과 같이 key/value 형식으로 조회가 가능합니다.</p>
<ul>
  <li>set user1 value1 GET user1</li>
  <li>HSET user1 name jaeguk HGETALL user1 name</li>
</ul>

<p>그러나 아래와 같이 SQL의 WHERE 절의 Parameters 처럼 조회는 지원하지 않습니다.</p>
<ul>
  <li>GET users WHERE name=”jaeguk”</li>
  <li>GET users WHERE name like “jae%”</li>
</ul>

<p>위한 같이 <strong>SQL과 유사한 기능</strong>  사용할 슈 있게 지원하는 것이 RediSearch 솔루션입니다.<br />
RediSearch 는 다믐의 기능을 지원합니다.</p>
<ul>
  <li>Secondary index over</li>
  <li>Full-text engine</li>
  <li>Incremental indexing</li>
  <li>Multi-field queries</li>
  <li>AND OR NOT complex Boolean queries</li>
  <li>Numeric filters and ranges</li>
  <li>Data Aggregation</li>
  <li>Auto-complete suggestions</li>
  <li>Geo Indexing and filtering</li>
</ul>

<h2 id="redisearch-실습환경-구성">RediSearch 실습환경 구성</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-d</span> <span class="nt">--name</span> redis-stack-server <span class="nt">-p</span> 6379:6379 redis/redis-stack-server
</code></pre></div></div>

<h2 id="인덱스-생성">인덱스 생성</h2>
<p>FT.CREATE 명령을 사용하여 필드와 인덱스를 생성합니다(기본 가중치는 1.0).</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127.0.0.1:6379&gt; FT.CREATE myIdx ON HASH PREFIX 1 doc: SCHEMA title TEXT WEIGHT 5.0 body TEXT url TEXT
OK
</code></pre></div></div>

<p>doc:xx 접두사가 있는 키가 있는 기존 해시 문서는 이때 자동으로 인덱스에 추가됩니다.</p>

<h2 id="documents-추가">documents 추가</h2>

<p>색인을 만든 후 doc: 접두사가 있는 새 해시 문서는 생성 시 자동으로 색인이 생성됩니다.</p>

<p>HSET 명령을 사용하여 새 해시 문서를 만들고 인덱스에 추가합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127.0.0.1:6379&gt; HSET doc:1 title <span class="s2">"hello world"</span> body <span class="s2">"lorem ipsum"</span> url <span class="s2">"http://redis.io"</span>
<span class="o">(</span>integer<span class="o">)</span> 3
</code></pre></div></div>

<h2 id="색인index-검색">색인(index) 검색</h2>
<p>특정 단어가 포함된 문서의 색인을 검색하려면 FT.SEARCH 명령을 사용하십시오.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127.0.0.1:6379&gt; FT.SEARCH myIdx <span class="s2">"hello world"</span> LIMIT 0 10
1<span class="o">)</span> <span class="o">(</span>integer<span class="o">)</span> 1
2<span class="o">)</span> <span class="s2">"doc:1"</span>
3<span class="o">)</span> 1<span class="o">)</span> <span class="s2">"title"</span>
   2<span class="o">)</span> <span class="s2">"hello world"</span>
   3<span class="o">)</span> <span class="s2">"body"</span>
   4<span class="o">)</span> <span class="s2">"lorem ipsum"</span>
   5<span class="o">)</span> <span class="s2">"url"</span>
   6<span class="o">)</span> <span class="s2">"http://redis.io"</span>
</code></pre></div></div>

<h2 id="색인index-삭제">색인(index) 삭제</h2>
<p>연관된 해시 문서를 삭제하지 않고 색인을 제거하려면 DD 옵션 없이 FT.DROPINDEX를 실행하십시오.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127.0.0.1:6379&gt; FT.DROPINDEX myIdx
OK
</code></pre></div></div>

<p>인덱스 및 모든 인덱스 해시 문서를 삭제하려면 명령에 DD 옵션을 추가합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>127.0.0.1:6379&gt; FT.SUGGET autocomplete <span class="s2">"he"</span>
1<span class="o">)</span> <span class="s2">"hello world"</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><category term="redisearch" /><summary type="html"><![CDATA[RediSearch 소개 Redis는 다음과 같이 key/value 형식으로 조회가 가능합니다. set user1 value1 GET user1 HSET user1 name jaeguk HGETALL user1 name]]></summary></entry><entry><title type="html">Redis 시작하기 - Redis 복제</title><link href="http://localhost:4000/cache/replication/" rel="alternate" type="text/html" title="Redis 시작하기 - Redis 복제" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/cache/replication</id><content type="html" xml:base="http://localhost:4000/cache/replication/"><![CDATA[<h2 id="redis-replication">Redis replication</h2>
<p>Redis가 복제를 통해 고가용성 및 장애 조치를 지원하는 방법<br />
Redis 복제의 기반(Redis Cluster 또는 Redis Sentinel에서 추가 계층으로 제공하는 고가용성 기능 제외)에는  사용 및 구성이 간편한 리더 팔로워(마스터-복제본) 복제가 있습니다. 이를 통해 복제본 Redis 인스턴스는 마스터 인스턴스의 정확한 복사본이 될 수 있습니다. 복제본은 링크가 끊어질 때마다 자동으로 마스터에 다시 연결되며 마스터에  어떤 일이 발생하든 관계없이 복제본의 정확한 복사본이 되려고 시도합니다.</p>

<p>이 시스템은 세 가지 주요 메커니즘을 사용하여 작동합니다:</p>
<ol>
  <li>마스터와 복제본 인스턴스가 잘 연결되어 있는 경우 마스터는 클라이언트 쓰기, 키 만료 또는 제거, 마스터 데이터 세트를 변경하는 기타 작업으로 인해 마스터 측에서 발생하는 데이터 세트에 미치는 영향을 복제하기 위해 복제본에 명령 스트림을 전송하여 복제본을 업데이트된 상태로 유지합니다.</li>
  <li>마스터와 복제본 간의 연결이 끊어지거나, 네트워크 문제가 있거나, 마스터 또는 복제본에서 시간 초과가 감지되어 복제본이 다시 연결되고 부분 다시 동기화를 진행하려고 시도하며, 이는 연결이 끊기는 동안 누락된 명령 스트림의 일부만 가져오려고 시도한다는 의미입니다.</li>
  <li>부분 다시 동기화가 불가능한 경우 복제본은 전체 다시 동기화를 요청합니다. 여기에는 마스터가 모든 데이터의 스냅샷을 만들어 복제본으로 보낸 다음 데이터 세트가 변경됨에 따라 명령 스트림을 계속 보내야 하는 더 복잡한 프로세스가 포함됩니다.</li>
</ol>

<p>Redis는 기본적으로 대기 시간이 짧고 성능이 뛰어난 비동기식 복제를 사용하며, 대부분의 Redis 사용 사례에서 자연스러운 복제 모드입니다. 그러나 Redis 복제본은 마스터와 주기적으로 수신한 데이터의 양을 비동기식으로 인식합니다. 따라서 마스터는 복제본에서 명령을 처리할 때마다 기다리지 않지만 필요한 경우 어떤 복제본이 어떤 명령을 이미 처리했는지 알 수 있습니다. 이렇게 하면 선택적 동기 복제를 사용할 수 있습니다.
특정 데이터의 동기 복제는 WAIT 명령을 사용하여 클라이언트에서 요청할 수 있습니다  .</p>

<p>그러나  WAIT는 다른 Redis 인스턴스에 지정된 수의 승인된 복사본이 있는지 확인할 수만 있으며, Redis 인스턴스 집합을 강력한 일관성을 가진 CP 시스템으로 전환하지 않습니다. 그러나 WAIT를 사용하면 실패  이벤트 후 쓰기가 손실될 확률이 트리거하기 어려운 특정 실패 모드로 크게 줄어듭니다.</p>

<p>고가용성 및 장애 조치에 대한 자세한 내용은 Redis Sentinel 또는 Redis 클러스터 설명서를 확인할 수 있습니다. 이 문서의 나머지 부분에서는 주로 Redis 기본 복제의 기본 특성에 대해 설명합니다.</p>

<p>Important facts about Redis replication</p>
<ul>
  <li>Redis는 비동기식 복제를 사용하며, 비동기식 복제본-마스터는 처리된 데이터의 양을 승인합니다.</li>
  <li>마스터에는 여러 복제본이 있을 수 있습니다.</li>
  <li>복제본은 다른 복제본의 연결을 수락할 수 있습니다. 여러 복제본을 동일한 마스터에 연결하는 것 외에도 계단식 구조의 다른 복제본에 연결할 수도 있습니다. Redis 4.0부터 모든 하위 복제본은 마스터에서 정확히 동일한 복제 스트림을 받습니다.</li>
  <li>Redis 복제는 마스터 측에서 비차단됩니다. 즉, 마스터는 하나 이상의 복제본이 초기 동기화 또는 부분 다시 동기화를 수행할 때 쿼리를 계속 처리합니다.</li>
  <li>또한 복제는 복제본 쪽에서 대부분 비차단입니다. 복제본이 초기 동기화를 수행하는 동안 redis.conf에서 Redis를 구성했다고 가정하고 이전 버전의 데이터 세트를 사용하여 쿼리를 처리할 수 있습니다. 그렇지 않으면 복제 스트림이 다운된 경우 클라이언트에 오류를 반환하도록 Redis 복제본을 구성할 수 있습니다. 그러나 초기 동기화 후에는 이전 데이터 세트를 삭제하고 새 데이터 세트를 로드해야 합니다. 복제본은 이 짧은 기간 동안 들어오는 연결을 차단합니다(매우 큰 데이터 세트의 경우 몇 초까지 걸릴 수 있음). Redis 4.0부터 이전 데이터 세트의 삭제가 다른 스레드에서 발생하도록 Redis를 구성할 수 있지만 새 초기 데이터 세트 로드는 여전히 기본 스레드에서 발생하고 복제본을 차단합니다.</li>
  <li>복제는 확장성을 위해 사용할 수 있으며, 읽기 전용 쿼리를 위한 여러 복제본을 보유하거나(예: 느린 O(N) 작업을 복제본으로 오프로드할 수 있음) 단순히 데이터 안전 및 고가용성을 향상시키는 데 사용할 수 있습니다.</li>
  <li>복제를 사용하여 마스터가 전체 데이터 세트를 디스크에 쓰는 비용을 피할 수 있습니다: 일반적인 기술은 디스크에 전혀 지속되지 않도록 마스터 redis.conf를 구성한  다음, 수시로 저장하도록 구성된 복제본을 연결하거나 AOF를 활성화하여 연결하는 것입니다. 그러나 마스터를 다시 시작하면 빈 데이터 세트로 시작하므로 이 설정은 주의해서 처리해야 합니다: 복제본이 동기화하려고 하면 복제본도 비워집니다.</li>
</ul>

<h2 id="마스터가-지속성을-해제한-경우-복제의-안전성">마스터가 지속성을 해제한 경우 복제의 안전성</h2>
<p>Redis 복제가 사용되는 설정에서는 마스터 및 복제본에서 지속성을 설정하는 것이 좋습니다. 예를 들어 매우 느린 디스크로 인한 지연 시간 문제로 인해 이것이 가능하지 않은 경우  재부팅 후 자동으로 다시 시작되지 않도록 인스턴스를 구성해야 합니다.
자동 다시 시작으로 구성된 지속성이 해제된 마스터가 위험한 이유를 더 잘 이해하려면 마스터 및 모든 복제본에서 데이터가 지워지는 다음 오류 모드를 확인합니다:</p>
<ol>
  <li>노드 A가 마스터 역할을 하고 지속성이 꺼지고 노드 B와 C가 노드 A에서 복제되는 설정이 있습니다.</li>
  <li>노드 A는 충돌하지만 프로세스를 다시 시작하는 자동 재시작 시스템이 있습니다. 그러나 지속성이 꺼져 있으므로 노드는 비어 있는 데이터 세트로 다시 시작됩니다.</li>
  <li>노드 B와 C는 비어 있는 노드 A에서 복제되므로 데이터 복사본을 효과적으로 삭제합니다.<br />
고가용성을 위해 Redis Sentinel을 사용하는 경우 프로세스의 자동 재시작과 함께 마스터의 지속성을 해제하는 것도 위험합니다. 예를 들어 마스터는 Sentinel이 장애를 감지하지 못할 만큼 빠르게 다시 시작하여 위에서 설명한 장애 모드가 발생하도록 할 수 있습니다.</li>
</ol>

<p>데이터 안전이 중요하고 지속성 없이 구성된 마스터와 함께 복제를 사용할 때마다 인스턴스의 자동 재시작을 비활성화해야 합니다.</p>

<h2 id="how-redis-replication-works">How Redis replication works</h2>
<p>모든 Redis 마스터에는 복제 ID가 있으며, 이는 데이터 세트의 지정된 스토리를 표시하는 큰 난수 문자열입니다. 또한 각 마스터는 복제본으로 전송하기 위해 생성되는 복제 스트림의 모든 바이트에 대해 증가하는 오프셋을 사용하여 데이터 세트를 수정하는 새로운 변경 사항으로 복제본의 상태를 업데이트합니다. 복제 오프셋은 실제로 연결된 복제본이 없더라도 증가하므로 기본적으로 모든 주어진 쌍:</p>
<h4 id="replication-id-offset">Replication ID, offset</h4>
<p>마스터 데이터 세트의 정확한 버전을 식별합니다.<br />
복제본이 마스터에 연결되면 PSYNC 명령을 사용하여 이전 마스터 복제 ID와 지금까지 처리한 오프셋을 보냅니다. 이렇게 하면 마스터가 필요한 증분 부분만 보낼 수 있습니다. 그러나  마스터 버퍼에 백로그가 충분하지 않거나 복제본이  더 이상 알 수 없는 기록(복제 ID)을 참조하는 경우 전체 재동기화가 발생합니다.이 경우 복제본은 처음부터 데이터 세트의 전체 복사본을 가져옵니다.<br />
전체 동기화가 작동하는 방식입니다.:<br />
마스터는 백그라운드 저장 프로세스를 시작하여 RDB 파일을 생성합니다. 동시에 클라이언트로부터 받은 모든 새 쓰기 명령을 버퍼링하기 시작합니다. 백그라운드 저장이 완료되면 마스터는 데이터베이스 파일을 복제본으로 전송하여 디스크에 저장한 다음 메모리에 로드합니다. 그런 다음 마스터는 버퍼링된 모든 명령을 복제본으로 보냅니다. 이 작업은 명령 스트림으로 수행되며 Redis 프로토콜 자체와 동일한 형식입니다.<br />
텔넷을 통해 직접 시도해 볼 수 있습니다. 서버가 일부 작업을 수행하는 동안 Redis 포트에 연결하고 SYNC 명령을 실행합니다. 대량 전송이 표시되고 마스터가 수신한 모든 명령이 텔넷 세션에서 다시 실행됩니다. 실제로  SYNC는 최신 Redis 인스턴스에서 더 이상 사용되지 않는 이전 프로토콜이지만 이전 버전과의 호환성을 위해 여전히 존재합니다 : 부분 재 동기화를 허용하지 않으므로 이제 PSYNC가 대신 사용됩니다.<br />
이미 언급했듯이 복제본은 어떤 이유로 마스터-복제본 링크가 다운되면 자동으로 다시 연결할 수 있습니다. 마스터가 여러 개의 동시 복제본 동기화 요청을 수신하는 경우 단일 백그라운드 저장을 수행하여 모든 요청을 처리합니다.</p>

<h2 id="replication-id-explained">Replication ID explained</h2>
<p>이전 섹션에서는 두 인스턴스가 동일한 복제 ID와 복제 오프셋을 갖는 경우 정확히 동일한 데이터를 갖는다고 설명했습니다. 그러나 복제 ID가 정확히 무엇인지, 그리고 인스턴스에 실제로 두 개의 복제 ID(기본 ID와 보조 ID)가 있는 이유를 이해하는 것이 유용합니다.<br />
복제 ID는 기본적으로 데이터 세트의 지정된 기록을 표시합니다  . 인스턴스가 마스터로 처음부터 다시 시작되거나 복제본이 마스터로 승격될 때마다 이 인스턴스에 대한 새 복제 ID가 생성됩니다. 마스터에 연결된 복제본은 핸드셰이크 후 복제 ID를 상속합니다. 따라서 동일한 ID를 가진 두 인스턴스는 동일한 데이터를 보유하지만 잠재적으로 다른 시간에 있다는 사실과 관련이 있습니다. 지정된 기록(복제 ID)에 대해 가장 업데이트된 데이터 세트를 보유하는 사용자를 이해하는 논리적 시간으로 작동하는 오프셋입니다.<br />
예를 들어, 두 인스턴스 A와 B의 복제 ID가 동일하지만 오프셋이 1000인 인스턴스와 오프셋이 1023인 인스턴스 B의 경우 첫 번째 인스턴스에는 데이터 세트에 적용된 특정 명령이 없음을 의미합니다. 또한 A가 몇 가지 명령만 적용하면 정확히 동일한 B 상태에 도달할 수 있음을 의미합니다.<br />
Redis 인스턴스에 두 개의 복제 ID가 있는 이유는 마스터로 승격된 복제본 때문입니다. 장애 조치(failover) 후 승격된 복제본은 이전 복제 ID가 이전 마스터 중 하나였기 때문에 이전 복제 ID를 계속 기억해야 합니다. 이러한 방식으로 다른 복제본이 새 마스터와 동기화될 때 이전 마스터 복제 ID를 사용하여 부분 다시 동기화를 수행하려고 합니다. 복제본이 마스터로 승격될 때 보조 ID를 기본 ID로 설정하고 이 ID 전환이 발생했을 때 오프셋이 무엇인지 기억하기 때문에 예상대로 작동합니다. 나중에 새 기록이 시작되므로 새 임의 복제 ID를 선택합니다. 새 복제본 연결을 처리할 때 마스터는 해당 ID 및 오프셋을 현재 ID 및 보조 ID와 일치시킵니다(안전을 위해 지정된 오프셋까지). 즉, 장애 조치(failover) 후 새로 승격된 마스터에 연결하는 복제본은 전체 동기화를 수행할 필요가 없습니다.<br />
마스터로 승격된 복제본이 장애 조치 후 복제 ID를 변경해야 하는 이유가 궁금한 경우: 일부 네트워크 파티션으로 인해 이전 마스터가 여전히 마스터로 작동할 수 있습니다. 동일한 복제 ID를 유지하는 것은 두 임의 인스턴스의 동일한 ID와 동일한 오프셋이 동일한 데이터 세트를 갖는다는 것을 의미한다는 사실을 위반합니다.</p>

<h2 id="diskless-replication">Diskless replication</h2>
<p>일반적으로 전체 다시 동기화하려면 디스크에 RDB 파일을 만든 다음 디스크에서 동일한 RDB를 다시 로드하여 복제본에 데이터를 공급해야 합니다.
느린 디스크를 사용하면 마스터에게 매우 스트레스가 되는 작업이 될 수 있습니다. Redis 버전 2.8.18은 디스크 없는 복제를 지원하는 첫 번째 버전입니다. 이 설정에서 자식 프로세스는 디스크를 중간 스토리지로 사용하지 않고 유선으로 RDB를 복제본으로 직접 보냅니다.</p>

<h2 id="configuration">Configuration</h2>
<p>기본 Redis 복제를 구성하는 것은 간단합니다 : 복제본 구성 파일에 다음 줄을 추가하기 만하면됩니다:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>replicaof 192.168.1.1 6379
</code></pre></div></div>
<p>물론 192.168.1.1 6379를 마스터 IP 주소(또는 호스트 이름) 및 포트로 바꿔야 합니다. 또는 REPLICAOF 명령을 호출할 수  있으며 마스터 호스트는 복제본과의 동기화를 시작합니다.
또한 부분 재동기화를 수행하기 위해 마스터가 메모리에서 가져온 복제 백로그를 조정하기 위한 몇 가지 매개 변수가 있습니다.  자세한 내용은 Redis 배포와 함께 제공되는 redis.conf 예제를 참조하십시오.
디스크 없는 복제는 repl-diskless-sync 구성 매개변수를 사용하여 사용할 수 있습니다  . 첫 번째 복제본 이후에 더 많은 복제본이 도착할 때까지 기다리는 전송 시작 지연은 repl-diskless-sync-delay 매개 변수에 의해 제어됩니다  .  자세한 내용은 Redis 배포의 예제 redis.conf 파일을 참조하십시오.</p>

<h2 id="read-only-replica">Read-only replica</h2>
<p>Redis 2.6부터 복제본은 기본적으로 활성화되는 읽기 전용 모드를 지원합니다. 이 동작은 redis.conf 파일의 replica-read-only 옵션에 의해 제어되며 CONFIG SET를  사용하여 런타임에 활성화 및 비활성화할 수  있습니다.<br />
읽기 전용 복제본은 모든 쓰기 명령을 거부하므로 실수로 인해 복제본입니다. 그렇다고 해서 DEBUG 또는 CONFIG와 같은 관리 명령이 여전히 활성화되어 있기 때문에 이 기능이 복제본 인스턴스를 인터넷이나 더 일반적으로 신뢰할 수 없는 클라이언트가 있는 네트워크에 노출하기 위한 것은 아닙니다  . 보안 페이지에서는 Redis 인스턴스를 보호하는 방법을 설명합니다.</p>

<p>읽기 전용 설정을 되돌리고 쓰기 작업의 대상이 될 수 있는 복제본 인스턴스를 가질 수 있는 이유가 궁금할 수 있습니다. 대답은 쓰기 가능한 복제본이 역사적인 이유로만 존재한다는 것입니다. 쓰기 가능한 복제본을 사용하면 마스터와 복제본 간에 불일치가 발생할 수 있으므로 쓰기 가능한 복제본을 사용하지 않는 것이 좋습니다. 이것이 어떤 상황에서 문제가 될 수 있는지 이해하려면 복제가 작동하는 방식을 이해해야 합니다. 마스터의 변경 사항은 일반 Redis 명령을 복제본에 전파하여 복제됩니다. 마스터에서 키가 만료되면 DEL 명령으로 전파됩니다. 마스터에 있지만 삭제되거나 만료되었거나 복제본에서 마스터와 다른 유형을 가진 키가 마스터에서 전파된 DEL, INCR 또는 RPOP와 같은 명령에 의도한 것과 다르게 반응합니다. 전파된 명령이 복제본에서 실패하거나 다른 결과가 발생할 수 있습니다. 위험을 최소화하려면(쓰기 가능한 복제본을 계속 사용해야 하는 경우) 다음 권장 사항을 따르는 것이 좋습니다.</p>
<ul>
  <li>마스터에서도 사용되는 쓰기 가능한 복제본의 키에 쓰지 마세요. (마스터에 쓰는 모든 클라이언트를 제어할 수 없는 경우 이를 보장하기 어려울 수 있습니다.)</li>
  <li>실행 중인 시스템에서 인스턴스 집합을 업그레이드할 때 중간 단계로 인스턴스를 쓰기 가능한 복제본으로 구성하지 마세요. 일반적으로 데이터 일관성을 보장하려는 경우 인스턴스를 마스터로 승격할 수 있는 경우 쓰기 가능한 복제본으로 구성하지 마세요.
역사적으로 쓰기 가능한 복제본에 대해 합법적인 것으로 간주되는 몇 가지 사용 사례가 있었습니다. 버전 7.0부터 이러한 사용 사례는 이제 모두 사용되지 않으며 다른 방법으로도 동일한 작업을 수행할 수 있습니다. 예를 들어:</li>
  <li>느린 집합 또는 정렬된 집합 연산을 계산하고 SUNIONSTORE 및 ZINTERSTORE와 같은 명령을 사용하여 결과를 임시 로컬 키에 저장합니다. 대신 SUNION 및 ZINTER와 같이 결과를 저장하지 않고 반환하는 명령을 사용합니다.</li>
  <li>SORT 명령  (선택적 STORE 옵션으로 인해 읽기 전용 명령으로 간주되지 않으므로 읽기 전용 복제본에서 사용할 수 없음) 사용. 대신 읽기 전용 명령인 SORT_RO를 사용합니다.</li>
  <li>EVAL 및 EVALSHA를 사용하는 것도 Lua 스크립트가 쓰기 명령을 호출할 수 있기 때문에 읽기 전용 명령으로 간주되지 않습니다. 대신  Lua 스크립트가 읽기 전용 명령만 호출할 수 있는 EVAL_RO 및 EVALSHA_RO 사용합니다.</li>
</ul>

<p>복제본과 마스터가 다시 동기화되거나 복제본이 다시 시작되면 복제본에 대한 쓰기가 삭제되지만 자동으로 동기화된다는 보장은 없습니다.
버전 4.0 이전에는 쓰기 가능한 복제본이 TTL(Time to Live)이 설정된 키를 만료할 수 없었습니다. 즉  , EXPIRE 또는 키에 대한 최대 TTL을 설정하는 다른 명령을 사용하면 키가 누수되고 읽기 명령으로 액세스하는 동안 더 이상 키가 표시되지 않을 수 있지만 키 수에는 키가 표시되고 여전히 메모리를 사용합니다. Redis 4.0 RC3 이상 버전에서는 63보다 큰 DB 번호로 작성된 키를 제외하고 마스터와 마찬가지로 TTL이 있는 키를 제거할 수 있습니다(그러나 기본적으로 Redis 인스턴스에는 16개의 데이터베이스만 있음). 4.0 이상의 버전에서도  마스터에 존재할 수 있는 키에 EXPIRE를 사용하면  복제본과 마스터 간에 불일치가 발생할 수 있습니다.
또한 Redis 4.0 복제본 쓰기는 로컬에서만 수행되며 인스턴스에 연결된 하위 복제본으로 전파되지 않습니다. 대신 하위 복제본은 항상 최상위 마스터가 중간 복제본으로 보낸 것과 동일한 복제 스트림을 받습니다. 예를 들어 다음 설정에서:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A <span class="nt">---</span><span class="o">&gt;</span> B <span class="nt">---</span><span class="o">&gt;</span> C
</code></pre></div></div>
<p>B가 쓰기 가능하더라도 C는 B 쓰기를 볼 수 없으며  대신 마스터 인스턴스 A와 동일한 데이터 세트를 갖게 됩니다 .
Setting a replica to authenticate to a master
마스터에 requirepass를 통한 암호가 있는 경우 모든 동기화 작업에서 해당 암호를 사용하도록 복제본을 구성하는 것은 간단합니다.
실행 중인 인스턴스에서 이 작업을 수행하려면 redis-cli를 사용하고:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>config <span class="nb">set </span>masterauth &lt;password&gt;
</code></pre></div></div>
<p>영구적으로 설정하려면 구성 파일에 추가하십시오.:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>masterauth &lt;password&gt;
</code></pre></div></div>
<h2 id="allow-writes-only-with-n-attached-replicas">Allow writes only with N attached replicas</h2>
<p>Redis 2.8부터는 현재 N개 이상의 복제본이 마스터에 연결되어 있는 경우에만 쓰기 쿼리를 허용하도록 Redis 마스터를 구성할 수 있습니다.
그러나 Redis는 비동기 복제를 사용하기 때문에 복제본이 실제로 지정된 쓰기를 수신했는지 확인할 수 없으므로 항상 데이터 손실 기간이 있습니다.</p>

<p>기능이 작동하는 방식은 다음과 같습니다.:</p>
<ul>
  <li>Redis 복제본은 매초마다 마스터를 ping하여 처리된 복제 스트림의 양을 확인합니다.</li>
  <li>Redis 마스터는 모든 복제본에서 마지막으로 ping을 수신한 시간을 기억합니다.</li>
  <li>사용자는 최대 시간(초)보다 지연이 없는 최소 복제본 수를 구성할 수 있습니다.
지연이 M초 미만인 복제본이 N개 이상 있는 경우 쓰기가 허용됩니다.
지정된 쓰기에 대해 일관성이 보장되지 않지만 적어도 데이터 손실에 대한 시간이 지정된 시간(초)으로 제한되는 최선의 데이터 안전 메커니즘으로 생각할 수 있습니다. 일반적으로 바운드 데이터 손실은 바인딩되지 않은 데이터 손실보다 낫습니다..
조건이 충족되지 않으면 마스터는 대신 오류로 응답하고 쓰기가 허용되지 않습니다.
이 기능에는 두 가지 구성 매개 변수가 있습니다:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>min-replicas-to-write &lt;number of replicas&gt;
min-replicas-max-lag &lt;number of seconds&gt;
</code></pre></div>    </div>
  </li>
</ul>

<p>자세한 내용은  Redis 소스 배포와 함께 제공되는 예제 redis.conf 파일을 확인하십시오.</p>
<h2 id="how-redis-replication-deals-with-expires-on-keys">How Redis replication deals with expires on keys</h2>
<p>Redis 만료를 통해 키의 TTL(Time to Live)을 제한할 수 있습니다. 이러한 기능은 인스턴스를 계산하는 기능에 따라 달라지지만, Redis 복제본은 Lua 스크립트를 사용하여 이러한 키를 변경하더라도 만료된 키를 올바르게 복제합니다.
이러한 기능을 구현하기 위해 Redis는 마스터와 복제본의 클럭 동기화 기능에 의존할 수 없으며, 이는 해결할 수 없는 문제이며 경합 상태와 데이터 세트의 분기를 초래할 수 있으므로 Redis는 세 가지 주요 기술을 사용하여 만료된 키의 복제가 작동할 수 있도록 합니다:</p>
<ol>
  <li>복제본은 키를 만료하지 않고 마스터가 키를 만료할 때까지 기다립니다. 마스터가 키를 만료시키면(또는 LRU로 인해 키를 제거하면)  모든 복제본에 전송되는 DEL 명령을 합성합니다.</li>
  <li>그러나 마스터 구동 만료로 인해 마스터가 제 시간에 DEL 명령을 제공할 수 없었기 때문에 복제본에 이미 논리적으로 만료된 메모리 키가 남아 있을 수 있습니다  . 이를 처리하기 위해 복제본은 논리 시계를 사용하여  데이터 세트의 일관성을 위반하지 않는 읽기 작업에만 키가 존재하지 않는다고 보고합니다  (마스터의 새 명령이 도착할 때). 이러한 방식으로 복제본은 여전히 존재하는 논리적으로 만료된 키를 보고하지 않습니다. 실제로 복제본을 사용하여 크기를 조정하는 HTML 조각 캐시는 원하는 TTL(Time to Live)보다 이미 오래된 항목을 반환하지 않도록 합니다.</li>
  <li>Lua 스크립트 실행 중에는 키 만료가 수행되지 않습니다. Lua 스크립트가 실행되면 개념적으로 마스터의 시간이 고정되므로 스크립트가 실행되는 모든 시간 동안 지정된 키가 존재하거나 존재하지 않습니다. 이렇게 하면 스크립트 중간에 키가 만료되는 것을 방지할 수 있으며, 데이터 세트에서 동일한 효과를 보장하는 방식으로 동일한 스크립트를 복제본에 보내는 데 필요합니다.</li>
</ol>

<p>복제본이 마스터로 승격되면 키가 독립적으로 만료되기 시작하며 이전 마스터의 도움이 필요하지 않습니다.</p>

<h2 id="configuring-replication-in-docker-and-nat">Configuring replication in Docker and NAT</h2>
<p>Docker 또는 포트 전달 또는 네트워크 주소 변환을 사용하는 다른 유형의 컨테이너를 사용하는 경우, 특히 Redis Sentinel 또는 마스터 INFO 또는 ROLE 명령 출력을 스캔하여 복제본의 주소를 검색하는 다른 시스템을 사용할 때 Redis 복제에 각별한 주의가 필요합니다.
문제는 마스터 인스턴스로 실행될 때 ROLE 명령과 INFO 출력의 복제 섹션  이 마스터에 연결하는 데 사용하는  IP 주소를 갖는 것으로 복제본을 표시한다는 것인데, NAT를 사용하는 환경에서는 복제본 인스턴스의 논리 주소(클라이언트가 복제본에 연결하는 데 사용해야 하는 주소)와 다를 수 있습니다.<br />
마찬가지로 복제본은 redis.conf에 구성된 수신 포트와 함께 나열되며, 포트가 다시 매핑되는 경우 전달된 포트와 다를 수 있습니다.
두 문제를 모두 해결하기 위해 Redis 3.2.2부터 복제본이 임의의 IP 및 포트 쌍을 마스터에 알리도록 강제할 수 있습니다. 사용할 두 가지 구성 지시문은 다음과 같습니다.:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>replica-announce-ip 5.5.5.5
replica-announce-port 1234
</code></pre></div></div>
<p>그리고  최근 Redis 배포판의 redis.conf 예제에 설명되어 있습니다.</p>

<h2 id="the-info-and-role-command">The INFO and ROLE command</h2>
<p>마스터 및 복제본 인스턴스의 현재 복제 파라미터에 대한 많은 정보를 제공하는 두 가지 Redis 명령이 있습니다. 하나는 INFO입니다. replication 인수를 INFO 복제로 사용하여 명령을 호출하면  복제와 관련된 정보만 표시됩니다. 컴퓨터 친화적인 또 다른 명령은 마스터 및 복제본의 복제 상태와 복제 오프셋, 연결된 복제본 목록 등을 제공하는 ROLE입니다.</p>

<h2 id="partial-sync-after-restarts-and-failovers">Partial sync after restarts and failovers</h2>
<p>Redis 4.0부터는 장애 조치 후 인스턴스가 마스터로 승격되면 이전 마스터의 복제본과 부분 재동기화를 계속 수행할 수 있습니다. 이를 위해 복제본은 이전 복제 ID와 이전 마스터의 오프셋을 기억하므로 이전 복제 ID를 요청하더라도 연결 복제본에 백로그의 일부를 제공할 수 있습니다.
그러나 승격된 복제본의 새 복제 ID는 데이터 집합의 다른 기록을 구성하기 때문에 다릅니다. 예를 들어 마스터는 사용 가능을 반환할 수 있고 일정 시간 동안 쓰기를 계속 수락할 수 있으므로 승격된 복제본에서 동일한 복제 ID를 사용하면 복제 ID와 오프셋 쌍이 단일 데이터 세트만 식별한다는 규칙을 위반하게 됩니다.
또한 복제본은 전원을 부드럽게 껐다가 다시 시작하면  마스터와 다시 동기화하는 데 필요한 정보를 RDB 파일에 저장할 수 있습니다. 이는 업그레이드의 경우에 유용합니다. 이것이 필요한 경우,  복제본에 대한 저장 및 종료 작업을  수행하기 위해 SHUTDOWN 명령을 사용하는 것이 좋습니다.
AOF 파일을 통해 다시 시작된 복제본을 부분적으로 동기화할 수 없습니다. 그러나 인스턴스를 종료하기 전에 RDB 지속성으로 전환하여 다시 시작할 수 있으며 마지막으로 AOF를 다시 활성화 할 수 있습니다.</p>

<h2 id="maxmemory-on-replicas">Maxmemory on replicas</h2>
<p>기본적으로 복제본은 maxmemory를 무시합니다  (장애 조치 후 또는 수동으로 마스터로 승격되지 않는 한). 즉, 키 제거는 마스터에서 처리되며, DEL 명령을 마스터 측에서 키가 제거될 때 복제본에 보냅니다.
이 동작은 마스터와 복제본이 일관성을 유지하도록 하며, 이는 일반적으로 원하는 것입니다. 그러나 복제본에 쓰기 가능하거나 복제본에 다른 메모리 설정을 적용하려는 경우 복제본에 수행된 모든 쓰기가 idempotent라고 확신하는 경우 이 기본값을 변경할 수 있습니다(그러나 수행 중인 작업을 이해해야 함).
복제본은 기본적으로 제거되지 않으므로 maxmemory를 통해 설정된 것보다 더 많은 메모리를 사용하게 될 수 있습니다  (복제본에서 더 클 수 있는 특정 버퍼가 있거나 데이터 구조가 때때로 더 많은 메모리를 차지할 수 있기 때문에). 복제본을 모니터링하고, 마스터가 구성된 maxmemory 설정에 도달하기 전에 실제 메모리 부족 상태에 도달하지 않도록 충분한 메모리가 있는지 확인합니다  .
이 동작을 변경하려면 복제본이 maxmemory를 무시하지 않도록 허용할 수 있습니다. 사용할 구성 지시문은 다음과 같습니다.:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>replica-ignore-maxmemory no
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><summary type="html"><![CDATA[Redis replication Redis가 복제를 통해 고가용성 및 장애 조치를 지원하는 방법 Redis 복제의 기반(Redis Cluster 또는 Redis Sentinel에서 추가 계층으로 제공하는 고가용성 기능 제외)에는 사용 및 구성이 간편한 리더 팔로워(마스터-복제본) 복제가 있습니다. 이를 통해 복제본 Redis 인스턴스는 마스터 인스턴스의 정확한 복사본이 될 수 있습니다. 복제본은 링크가 끊어질 때마다 자동으로 마스터에 다시 연결되며 마스터에 어떤 일이 발생하든 관계없이 복제본의 정확한 복사본이 되려고 시도합니다.]]></summary></entry><entry><title type="html">Redis 시작하기 - Redis 관리</title><link href="http://localhost:4000/cache/redis-management/" rel="alternate" type="text/html" title="Redis 시작하기 - Redis 관리" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/cache/redis-management</id><content type="html" xml:base="http://localhost:4000/cache/redis-management/"><![CDATA[<h2 id="redis-관리-tips">Redis 관리 Tips</h2>
<p>프로덕션에서 Redis를 구성하고 관리할때 아래의 사항들을 고려하십시요.</p>

<h2 id="redis-setup-tips">Redis setup tips</h2>
<h4 id="linux">Linux</h4>
<ul>
  <li>Linux 운영 체제를 사용하여 Redis를 배포합니다. Redis는 OS X에서도 테스트되며 FreeBSD 및 OpenBSD 시스템에서도 수시로 테스트됩니다. 그러나 Linux는 대부분의 스트레스 테스트가 수행되고 대부분의 프로덕션 배포가 실행되는 곳입니다.</li>
  <li>Linux 커널 오버 커밋 메모리 설정을 1로 설정합니다.. vm.overcommit_memory = 1을 /etc/sysctl.conf에  추가합니다.
 그런 다음 재부팅하거나 <br />
sysctl vm.overcommit_memory=1 명령을 실행하여  설정을 활성화합니다.</li>
  <li>Linux 커널 기능인 Transparent Huge Pages가 Redis 메모리 사용량 및 대기 시간에 영향을 주지 않도록 하려면 다음 명령을 사용합니다:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo </span>never <span class="o">&gt;</span> /sys/kernel/mm/transparent_hugepage/enabled 
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="memory">Memory</h4>
<ul>
  <li>스왑이 활성화되어 있고 스왑 파일 크기가 시스템의 메모리 양과 같은지 확인했습니다. Linux에 스왑이 설정되어 있지 않고 Redis 인스턴스가 실수로 너무 많은 메모리를 사용하는 경우 메모리가 부족할 때 Redis가 충돌하거나 Linux 커널 OOM 킬러가 Redis 프로세스를 종료할 수 있습니다. 스와핑이 활성화되면 지연 시간 급증을 감지하고 이에 대한 조치를 취할 수 있습니다.</li>
  <li>인스턴스에서 명시적 maxmemory 옵션 제한을 설정하여 시스템 메모리 제한에 거의 도달했을 때 실패하는 대신 오류를 보고하도록 합니다. maxmemory는  데이터 이외의 Redis에 대한 오버헤드와 조각화 오버헤드를 계산하여 설정해야 합니다. 따라서 사용 가능한 메모리가 10GB라고 생각되면 8 또는 9로 설정하십시오.</li>
  <li>쓰기 중심의 애플리케이션에서 Redis를 사용하는 경우 RDB 파일을 디스크에 저장하거나 AOF 로그를 다시 쓰는 동안 Redis는 일반적으로 사용되는 메모리의 최대 2배를 사용할 수 있습니다. 사용되는 추가 메모리는 저장 프로세스 중에 쓰기에 의해 수정된 메모리 페이지 수에 비례하므로 이 시간 동안 터치된 키(또는 집계 유형 항목)의 수에 비례하는 경우가 많습니다. 그에 따라 메모리 크기를 조정해야 합니다.</li>
  <li>문제 해결에 도움이 되는 LATENCY DOCTOR  및 MEMORY DOCTOR 명령을 참조하십시오.</li>
</ul>

<h2 id="imaging">Imaging</h2>
<ul>
  <li>daemontools에서 실행하는 경우, use daemonize no.</li>
</ul>

<h2 id="replication">Replication</h2>
<ul>
  <li>Redis가 사용하는 메모리 양에 비례하여 중요한 복제 백로그를 설정합니다. 백로그를 사용하면 복제본을 기본(마스터) 인스턴스와 훨씬 더 쉽게 동기화할 수 있습니다.</li>
  <li>복제를 사용하는 경우 Redis는 지속성이 비활성화된 경우에도 RDB 저장을 수행합니다. (디스크 없는 복제에는 적용되지 않습니다.) 마스터에 디스크 사용량이 없는 경우 디스크 없는 복제를 사용하도록 설정합니다.</li>
  <li>복제를 사용하는 경우 마스터가 지속성을 사용하도록 설정되어 있는지 또는 충돌 시 자동으로 다시 시작되지 않는지 확인합니다. 복제본은 마스터의 정확한 복사본을 유지하려고 하므로 마스터가 빈 데이터 세트로 다시 시작되면 복제본도 지워집니다.</li>
</ul>

<h2 id="security">Security</h2>
<ul>
  <li>기본적으로 Redis는 인증이 필요하지 않으며 모든 네트워크 인터페이스를 수신 대기합니다. Redis를 인터넷이나 공격자가 접근할 수 있는 다른 장소에 노출된 상태로 두면 큰 보안 문제가 됩니다. 예를 들어 이 공격이 얼마나 위험한지 확인하십시오.  Redis를 보호하는 방법에 대한 자세한 내용은 보안 페이지 및 빠른 시작을 확인하세요.</li>
</ul>

<h2 id="running-redis-on-ec2">Running Redis on EC2</h2>
<ul>
  <li>PV 기반 인스턴스가 아닌 HVM 기반 인스턴스 사용.</li>
  <li>이전 인스턴스 패밀리를 사용하지 마십시오. 
예를 들어 PV와 함께 m1.medium 대신 HVM과 함께 m3.medium을 사용합니다.</li>
  <li>EC2 EBS 볼륨에서 Redis 지속성을 사용하는 것은 EBS 볼륨의 지연 시간이 긴 특성을 갖는 경우가 있으므로 주의해서 처리해야 합니다.</li>
  <li>복제본이 마스터와 동기화될 때 문제가 있는 경우 새 디스크 없는 복제를 시도할 수 있습니다.<br />
가동 중지 시간 없이 Redis 인스턴스 업그레이드 또는 다시 시작
Redis는 서버에서 장기 실행 프로세스로 설계되었습니다. CONFIG SET 명령을 사용하여 다시 시작하지 않고도 많은 구성 옵션을 수정할 수 있습니다. Redis를 다시 시작하지 않고도 AOF에서 RDB 스냅샷 지속성으로 전환하거나 그 반대로 전환할 수도 있습니다.  자세한 내용은 CONFIG GET * 명령의 출력을 확인하십시오.
예를 들어 Redis 프로세스를 최신 버전으로 업그레이드하거나 현재 CONFIG 명령에서 지원하지 않는 구성 매개 변수를 수정해야 하는 경우 다시 시작해야 합니다.</li>
</ul>

<h2 id="가동-중지-시간을-방지하려면-다음-단계를-따르십시오">가동 중지 시간을 방지하려면 다음 단계를 따르십시오</h2>
<ul>
  <li>새 Redis 인스턴스를 현재 Redis 인스턴스의 복제본으로 설정합니다. 이렇게 하려면 다른 서버 또는 두 개의 Redis 인스턴스를 동시에 실행할 수 있는 충분한 RAM이 있는 서버가 필요합니다.</li>
  <li>단일 서버를 사용하는 경우 복제본이 마스터 인스턴스와 다른 포트에서 시작되었는지 확인하고, 그렇지 않으면 복제본을 시작할 수 없습니다.</li>
  <li>복제 초기 동기화가 완료될 때까지 기다립니다. 복제본의 로그 파일 확인.</li>
  <li>INFO를 사용하여 마스터와 복제본의 키 수가 동일한지 확인합니다. redis-cli를 사용하여 복제본이 예상대로 작동하고 명령에 응답하는지 확인합니다.</li>
  <li>CONFIG SET slave-read-only no를 사용하여 복제본에 쓰기 허용.</li>
  <li>새 인스턴스(복제본)를 사용하도록 모든 클라이언트를 구성합니다. CLIENT PAUSE 명령을 사용하여 전환 중에 클라이언트가 이전 마스터에 쓸 수 없도록 할 수 있습니다.</li>
  <li>마스터가 더 이상 쿼리를 수신하지 않는 것을 확인하면(MONITOR 명령을 사용하여 이를 확인할 수 있음) REPLICAOF NO ONE 명령을 사용하여 마스터할 복제본을 선택한  다음 마스터를 종료합니다.</li>
</ul>

<p>Redis Sentinel 또는 Redis Cluster를 사용하는 경우 최신 버전으로 업그레이드하는 가장 간단한 방법은 복제본을 하나씩 업그레이드하는 것입니다. 그런 다음 수동 장애 조치(failover)를 수행하여 업그레이드된 복제본 중 하나를 마스터로 승격하고 마지막으로 마지막 복제본을 승격할 수 있습니다</p>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><summary type="html"><![CDATA[Redis 관리 Tips 프로덕션에서 Redis를 구성하고 관리할때 아래의 사항들을 고려하십시요.]]></summary></entry><entry><title type="html">Redis 시작하기 - Redis configuration 예시(redis.conf)</title><link href="http://localhost:4000/cache/redis-config-example/" rel="alternate" type="text/html" title="Redis 시작하기 - Redis configuration 예시(redis.conf)" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/cache/redis%20config%20example</id><content type="html" xml:base="http://localhost:4000/cache/redis-config-example/"><![CDATA[<h2 id="redisconf-파일">redis.conf 파일</h2>
<p>모든 버전과 함께 제공되는 자체 문서화 된 redis.conf 파일</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Redis configuration file example.</span>
<span class="c">#</span>
<span class="c"># Note that in order to read the configuration file, Redis must be</span>
<span class="c"># started with the file path as first argument:</span>
<span class="c">#</span>
<span class="c"># ./redis-server /path/to/redis.conf</span>

<span class="c"># Note on units: when memory size is needed, it is possible to specify</span>
<span class="c"># it in the usual form of 1k 5GB 4M and so forth:</span>
<span class="c">#</span>
<span class="c"># 1k =&gt; 1000 bytes</span>
<span class="c"># 1kb =&gt; 1024 bytes</span>
<span class="c"># 1m =&gt; 1000000 bytes</span>
<span class="c"># 1mb =&gt; 1024*1024 bytes</span>
<span class="c"># 1g =&gt; 1000000000 bytes</span>
<span class="c"># 1gb =&gt; 1024*1024*1024 bytes</span>
<span class="c">#</span>
<span class="c"># units are case insensitive so 1GB 1Gb 1gB are all the same.</span>

<span class="c">################################## INCLUDES ###################################</span>

<span class="c"># Include one or more other config files here.  This is useful if you</span>
<span class="c"># have a standard template that goes to all Redis servers but also need</span>
<span class="c"># to customize a few per-server settings.  Include files can include</span>
<span class="c"># other files, so use this wisely.</span>
<span class="c">#</span>
<span class="c"># Note that option "include" won't be rewritten by command "CONFIG REWRITE"</span>
<span class="c"># from admin or Redis Sentinel. Since Redis always uses the last processed</span>
<span class="c"># line as value of a configuration directive, you'd better put includes</span>
<span class="c"># at the beginning of this file to avoid overwriting config change at runtime.</span>
<span class="c">#</span>
<span class="c"># If instead you are interested in using includes to override configuration</span>
<span class="c"># options, it is better to use include as the last line.</span>
<span class="c">#</span>
<span class="c"># Included paths may contain wildcards. All files matching the wildcards will</span>
<span class="c"># be included in alphabetical order.</span>
<span class="c"># Note that if an include path contains a wildcards but no files match it when</span>
<span class="c"># the server is started, the include statement will be ignored and no error will</span>
<span class="c"># be emitted.  It is safe, therefore, to include wildcard files from empty</span>
<span class="c"># directories.</span>
<span class="c">#</span>
<span class="c"># include /path/to/local.conf</span>
<span class="c"># include /path/to/other.conf</span>
<span class="c"># include /path/to/fragments/*.conf</span>
<span class="c">#</span>

<span class="c">################################## MODULES #####################################</span>

<span class="c"># Load modules at startup. If the server is not able to load modules</span>
<span class="c"># it will abort. It is possible to use multiple loadmodule directives.</span>
<span class="c">#</span>
<span class="c"># loadmodule /path/to/my_module.so</span>
<span class="c"># loadmodule /path/to/other_module.so</span>

<span class="c">################################## NETWORK #####################################</span>

<span class="c"># By default, if no "bind" configuration directive is specified, Redis listens</span>
<span class="c"># for connections from all available network interfaces on the host machine.</span>
<span class="c"># It is possible to listen to just one or multiple selected interfaces using</span>
<span class="c"># the "bind" configuration directive, followed by one or more IP addresses.</span>
<span class="c"># Each address can be prefixed by "-", which means that redis will not fail to</span>
<span class="c"># start if the address is not available. Being not available only refers to</span>
<span class="c"># addresses that does not correspond to any network interface. Addresses that</span>
<span class="c"># are already in use will always fail, and unsupported protocols will always BE</span>
<span class="c"># silently skipped.</span>
<span class="c">#</span>
<span class="c"># Examples:</span>
<span class="c">#</span>
<span class="c"># bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses</span>
<span class="c"># bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6</span>
<span class="c"># bind * -::*                     # like the default, all available interfaces</span>
<span class="c">#</span>
<span class="c"># ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the</span>
<span class="c"># internet, binding to all the interfaces is dangerous and will expose the</span>
<span class="c"># instance to everybody on the internet. So by default we uncomment the</span>
<span class="c"># following bind directive, that will force Redis to listen only on the</span>
<span class="c"># IPv4 and IPv6 (if available) loopback interface addresses (this means Redis</span>
<span class="c"># will only be able to accept client connections from the same host that it is</span>
<span class="c"># running on).</span>
<span class="c">#</span>
<span class="c"># IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES</span>
<span class="c"># COMMENT OUT THE FOLLOWING LINE.</span>
<span class="c">#</span>
<span class="c"># You will also need to set a password unless you explicitly disable protected</span>
<span class="c"># mode.</span>
<span class="c"># ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="nb">bind </span>127.0.0.1 -::1

<span class="c"># By default, outgoing connections (from replica to master, from Sentinel to</span>
<span class="c"># instances, cluster bus, etc.) are not bound to a specific local address. In</span>
<span class="c"># most cases, this means the operating system will handle that based on routing</span>
<span class="c"># and the interface through which the connection goes out.</span>
<span class="c">#</span>
<span class="c"># Using bind-source-addr it is possible to configure a specific address to bind</span>
<span class="c"># to, which may also affect how the connection gets routed.</span>
<span class="c">#</span>
<span class="c"># Example:</span>
<span class="c">#</span>
<span class="c"># bind-source-addr 10.0.0.1</span>

<span class="c"># Protected mode is a layer of security protection, in order to avoid that</span>
<span class="c"># Redis instances left open on the internet are accessed and exploited.</span>
<span class="c">#</span>
<span class="c"># When protected mode is on and the default user has no password, the server</span>
<span class="c"># only accepts local connections from the IPv4 address (127.0.0.1), IPv6 address</span>
<span class="c"># (::1) or Unix domain sockets.</span>
<span class="c">#</span>
<span class="c"># By default protected mode is enabled. You should disable it only if</span>
<span class="c"># you are sure you want clients from other hosts to connect to Redis</span>
<span class="c"># even if no authentication is configured.</span>
protected-mode <span class="nb">yes</span>

<span class="c"># Redis uses default hardened security configuration directives to reduce the</span>
<span class="c"># attack surface on innocent users. Therefore, several sensitive configuration</span>
<span class="c"># directives are immutable, and some potentially-dangerous commands are blocked.</span>
<span class="c">#</span>
<span class="c"># Configuration directives that control files that Redis writes to (e.g., 'dir'</span>
<span class="c"># and 'dbfilename') and that aren't usually modified during runtime</span>
<span class="c"># are protected by making them immutable.</span>
<span class="c">#</span>
<span class="c"># Commands that can increase the attack surface of Redis and that aren't usually</span>
<span class="c"># called by users are blocked by default.</span>
<span class="c">#</span>
<span class="c"># These can be exposed to either all connections or just local ones by setting</span>
<span class="c"># each of the configs listed below to either of these values:</span>
<span class="c">#</span>
<span class="c"># no    - Block for any connection (remain immutable)</span>
<span class="c"># yes   - Allow for any connection (no protection)</span>
<span class="c"># local - Allow only for local connections. Ones originating from the</span>
<span class="c">#         IPv4 address (127.0.0.1), IPv6 address (::1) or Unix domain sockets.</span>
<span class="c">#</span>
<span class="c"># enable-protected-configs no</span>
<span class="c"># enable-debug-command no</span>
<span class="c"># enable-module-command no</span>

<span class="c"># Accept connections on the specified port, default is 6379 (IANA #815344).</span>
<span class="c"># If port 0 is specified Redis will not listen on a TCP socket.</span>
port 6379

<span class="c"># TCP listen() backlog.</span>
<span class="c">#</span>
<span class="c"># In high requests-per-second environments you need a high backlog in order</span>
<span class="c"># to avoid slow clients connection issues. Note that the Linux kernel</span>
<span class="c"># will silently truncate it to the value of /proc/sys/net/core/somaxconn so</span>
<span class="c"># make sure to raise both the value of somaxconn and tcp_max_syn_backlog</span>
<span class="c"># in order to get the desired effect.</span>
tcp-backlog 511

<span class="c"># Unix socket.</span>
<span class="c">#</span>
<span class="c"># Specify the path for the Unix socket that will be used to listen for</span>
<span class="c"># incoming connections. There is no default, so Redis will not listen</span>
<span class="c"># on a unix socket when not specified.</span>
<span class="c">#</span>
<span class="c"># unixsocket /run/redis.sock</span>
<span class="c"># unixsocketperm 700</span>

<span class="c"># Close the connection after a client is idle for N seconds (0 to disable)</span>
<span class="nb">timeout </span>0

<span class="c"># TCP keepalive.</span>
<span class="c">#</span>
<span class="c"># If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence</span>
<span class="c"># of communication. This is useful for two reasons:</span>
<span class="c">#</span>
<span class="c"># 1) Detect dead peers.</span>
<span class="c"># 2) Force network equipment in the middle to consider the connection to be</span>
<span class="c">#    alive.</span>
<span class="c">#</span>
<span class="c"># On Linux, the specified value (in seconds) is the period used to send ACKs.</span>
<span class="c"># Note that to close the connection the double of the time is needed.</span>
<span class="c"># On other kernels the period depends on the kernel configuration.</span>
<span class="c">#</span>
<span class="c"># A reasonable value for this option is 300 seconds, which is the new</span>
<span class="c"># Redis default starting with Redis 3.2.1.</span>
tcp-keepalive 300

<span class="c"># Apply OS-specific mechanism to mark the listening socket with the specified</span>
<span class="c"># ID, to support advanced routing and filtering capabilities.</span>
<span class="c">#</span>
<span class="c"># On Linux, the ID represents a connection mark.</span>
<span class="c"># On FreeBSD, the ID represents a socket cookie ID.</span>
<span class="c"># On OpenBSD, the ID represents a route table ID.</span>
<span class="c">#</span>
<span class="c"># The default value is 0, which implies no marking is required.</span>
<span class="c"># socket-mark-id 0</span>

<span class="c">################################# TLS/SSL #####################################</span>

<span class="c"># By default, TLS/SSL is disabled. To enable it, the "tls-port" configuration</span>
<span class="c"># directive can be used to define TLS-listening ports. To enable TLS on the</span>
<span class="c"># default port, use:</span>
<span class="c">#</span>
<span class="c"># port 0</span>
<span class="c"># tls-port 6379</span>

<span class="c"># Configure a X.509 certificate and private key to use for authenticating the</span>
<span class="c"># server to connected clients, masters or cluster peers.  These files should be</span>
<span class="c"># PEM formatted.</span>
<span class="c">#</span>
<span class="c"># tls-cert-file redis.crt</span>
<span class="c"># tls-key-file redis.key</span>
<span class="c">#</span>
<span class="c"># If the key file is encrypted using a passphrase, it can be included here</span>
<span class="c"># as well.</span>
<span class="c">#</span>
<span class="c"># tls-key-file-pass secret</span>

<span class="c"># Normally Redis uses the same certificate for both server functions (accepting</span>
<span class="c"># connections) and client functions (replicating from a master, establishing</span>
<span class="c"># cluster bus connections, etc.).</span>
<span class="c">#</span>
<span class="c"># Sometimes certificates are issued with attributes that designate them as</span>
<span class="c"># client-only or server-only certificates. In that case it may be desired to use</span>
<span class="c"># different certificates for incoming (server) and outgoing (client)</span>
<span class="c"># connections. To do that, use the following directives:</span>
<span class="c">#</span>
<span class="c"># tls-client-cert-file client.crt</span>
<span class="c"># tls-client-key-file client.key</span>
<span class="c">#</span>
<span class="c"># If the key file is encrypted using a passphrase, it can be included here</span>
<span class="c"># as well.</span>
<span class="c">#</span>
<span class="c"># tls-client-key-file-pass secret</span>

<span class="c"># Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange,</span>
<span class="c"># required by older versions of OpenSSL (&lt;3.0). Newer versions do not require</span>
<span class="c"># this configuration and recommend against it.</span>
<span class="c">#</span>
<span class="c"># tls-dh-params-file redis.dh</span>

<span class="c"># Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL</span>
<span class="c"># clients and peers.  Redis requires an explicit configuration of at least one</span>
<span class="c"># of these, and will not implicitly use the system wide configuration.</span>
<span class="c">#</span>
<span class="c"># tls-ca-cert-file ca.crt</span>
<span class="c"># tls-ca-cert-dir /etc/ssl/certs</span>

<span class="c"># By default, clients (including replica servers) on a TLS port are required</span>
<span class="c"># to authenticate using valid client side certificates.</span>
<span class="c">#</span>
<span class="c"># If "no" is specified, client certificates are not required and not accepted.</span>
<span class="c"># If "optional" is specified, client certificates are accepted and must be</span>
<span class="c"># valid if provided, but are not required.</span>
<span class="c">#</span>
<span class="c"># tls-auth-clients no</span>
<span class="c"># tls-auth-clients optional</span>

<span class="c"># By default, a Redis replica does not attempt to establish a TLS connection</span>
<span class="c"># with its master.</span>
<span class="c">#</span>
<span class="c"># Use the following directive to enable TLS on replication links.</span>
<span class="c">#</span>
<span class="c"># tls-replication yes</span>

<span class="c"># By default, the Redis Cluster bus uses a plain TCP connection. To enable</span>
<span class="c"># TLS for the bus protocol, use the following directive:</span>
<span class="c">#</span>
<span class="c"># tls-cluster yes</span>

<span class="c"># By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended</span>
<span class="c"># that older formally deprecated versions are kept disabled to reduce the attack surface.</span>
<span class="c"># You can explicitly specify TLS versions to support.</span>
<span class="c"># Allowed values are case insensitive and include "TLSv1", "TLSv1.1", "TLSv1.2",</span>
<span class="c"># "TLSv1.3" (OpenSSL &gt;= 1.1.1) or any combination.</span>
<span class="c"># To enable only TLSv1.2 and TLSv1.3, use:</span>
<span class="c">#</span>
<span class="c"># tls-protocols "TLSv1.2 TLSv1.3"</span>

<span class="c"># Configure allowed ciphers.  See the ciphers(1ssl) manpage for more information</span>
<span class="c"># about the syntax of this string.</span>
<span class="c">#</span>
<span class="c"># Note: this configuration applies only to &lt;= TLSv1.2.</span>
<span class="c">#</span>
<span class="c"># tls-ciphers DEFAULT:!MEDIUM</span>

<span class="c"># Configure allowed TLSv1.3 ciphersuites.  See the ciphers(1ssl) manpage for more</span>
<span class="c"># information about the syntax of this string, and specifically for TLSv1.3</span>
<span class="c"># ciphersuites.</span>
<span class="c">#</span>
<span class="c"># tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256</span>

<span class="c"># When choosing a cipher, use the server's preference instead of the client</span>
<span class="c"># preference. By default, the server follows the client's preference.</span>
<span class="c">#</span>
<span class="c"># tls-prefer-server-ciphers yes</span>

<span class="c"># By default, TLS session caching is enabled to allow faster and less expensive</span>
<span class="c"># reconnections by clients that support it. Use the following directive to disable</span>
<span class="c"># caching.</span>
<span class="c">#</span>
<span class="c"># tls-session-caching no</span>

<span class="c"># Change the default number of TLS sessions cached. A zero value sets the cache</span>
<span class="c"># to unlimited size. The default size is 20480.</span>
<span class="c">#</span>
<span class="c"># tls-session-cache-size 5000</span>

<span class="c"># Change the default timeout of cached TLS sessions. The default timeout is 300</span>
<span class="c"># seconds.</span>
<span class="c">#</span>
<span class="c"># tls-session-cache-timeout 60</span>

<span class="c">################################# GENERAL #####################################</span>

<span class="c"># By default Redis does not run as a daemon. Use 'yes' if you need it.</span>
<span class="c"># Note that Redis will write a pid file in /var/run/redis.pid when daemonized.</span>
<span class="c"># When Redis is supervised by upstart or systemd, this parameter has no impact.</span>
daemonize no

<span class="c"># If you run Redis from upstart or systemd, Redis can interact with your</span>
<span class="c"># supervision tree. Options:</span>
<span class="c">#   supervised no      - no supervision interaction</span>
<span class="c">#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode</span>
<span class="c">#                        requires "expect stop" in your upstart job config</span>
<span class="c">#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET</span>
<span class="c">#                        on startup, and updating Redis status on a regular</span>
<span class="c">#                        basis.</span>
<span class="c">#   supervised auto    - detect upstart or systemd method based on</span>
<span class="c">#                        UPSTART_JOB or NOTIFY_SOCKET environment variables</span>
<span class="c"># Note: these supervision methods only signal "process is ready."</span>
<span class="c">#       They do not enable continuous pings back to your supervisor.</span>
<span class="c">#</span>
<span class="c"># The default is "no". To run under upstart/systemd, you can simply uncomment</span>
<span class="c"># the line below:</span>
<span class="c">#</span>
<span class="c"># supervised auto</span>

<span class="c"># If a pid file is specified, Redis writes it where specified at startup</span>
<span class="c"># and removes it at exit.</span>
<span class="c">#</span>
<span class="c"># When the server runs non daemonized, no pid file is created if none is</span>
<span class="c"># specified in the configuration. When the server is daemonized, the pid file</span>
<span class="c"># is used even if not specified, defaulting to "/var/run/redis.pid".</span>
<span class="c">#</span>
<span class="c"># Creating a pid file is best effort: if Redis is not able to create it</span>
<span class="c"># nothing bad happens, the server will start and run normally.</span>
<span class="c">#</span>
<span class="c"># Note that on modern Linux systems "/run/redis.pid" is more conforming</span>
<span class="c"># and should be used instead.</span>
pidfile /var/run/redis_6379.pid

<span class="c"># Specify the server verbosity level.</span>
<span class="c"># This can be one of:</span>
<span class="c"># debug (a lot of information, useful for development/testing)</span>
<span class="c"># verbose (many rarely useful info, but not a mess like the debug level)</span>
<span class="c"># notice (moderately verbose, what you want in production probably)</span>
<span class="c"># warning (only very important / critical messages are logged)</span>
loglevel notice

<span class="c"># Specify the log file name. Also the empty string can be used to force</span>
<span class="c"># Redis to log on the standard output. Note that if you use standard</span>
<span class="c"># output for logging but daemonize, logs will be sent to /dev/null</span>
logfile <span class="s2">""</span>

<span class="c"># To enable logging to the system logger, just set 'syslog-enabled' to yes,</span>
<span class="c"># and optionally update the other syslog parameters to suit your needs.</span>
<span class="c"># syslog-enabled no</span>

<span class="c"># Specify the syslog identity.</span>
<span class="c"># syslog-ident redis</span>

<span class="c"># Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.</span>
<span class="c"># syslog-facility local0</span>

<span class="c"># To disable the built in crash log, which will possibly produce cleaner core</span>
<span class="c"># dumps when they are needed, uncomment the following:</span>
<span class="c">#</span>
<span class="c"># crash-log-enabled no</span>

<span class="c"># To disable the fast memory check that's run as part of the crash log, which</span>
<span class="c"># will possibly let redis terminate sooner, uncomment the following:</span>
<span class="c">#</span>
<span class="c"># crash-memcheck-enabled no</span>

<span class="c"># Set the number of databases. The default database is DB 0, you can select</span>
<span class="c"># a different one on a per-connection basis using SELECT &lt;dbid&gt; where</span>
<span class="c"># dbid is a number between 0 and 'databases'-1</span>
databases 16

<span class="c"># By default Redis shows an ASCII art logo only when started to log to the</span>
<span class="c"># standard output and if the standard output is a TTY and syslog logging is</span>
<span class="c"># disabled. Basically this means that normally a logo is displayed only in</span>
<span class="c"># interactive sessions.</span>
<span class="c">#</span>
<span class="c"># However it is possible to force the pre-4.0 behavior and always show a</span>
<span class="c"># ASCII art logo in startup logs by setting the following option to yes.</span>
always-show-logo no

<span class="c"># By default, Redis modifies the process title (as seen in 'top' and 'ps') to</span>
<span class="c"># provide some runtime information. It is possible to disable this and leave</span>
<span class="c"># the process name as executed by setting the following to no.</span>
set-proc-title <span class="nb">yes</span>

<span class="c"># When changing the process title, Redis uses the following template to construct</span>
<span class="c"># the modified title.</span>
<span class="c">#</span>
<span class="c"># Template variables are specified in curly brackets. The following variables are</span>
<span class="c"># supported:</span>
<span class="c">#</span>
<span class="c"># {title}           Name of process as executed if parent, or type of child process.</span>
<span class="c"># {listen-addr}     Bind address or '*' followed by TCP or TLS port listening on, or</span>
<span class="c">#                   Unix socket if only that's available.</span>
<span class="c"># {server-mode}     Special mode, i.e. "[sentinel]" or "[cluster]".</span>
<span class="c"># {port}            TCP port listening on, or 0.</span>
<span class="c"># {tls-port}        TLS port listening on, or 0.</span>
<span class="c"># {unixsocket}      Unix domain socket listening on, or "".</span>
<span class="c"># {config-file}     Name of configuration file used.</span>
<span class="c">#</span>
proc-title-template <span class="s2">"{title} {listen-addr} {server-mode}"</span>

<span class="c"># Set the local environment which is used for string comparison operations, and </span>
<span class="c"># also affect the performance of Lua scripts. Empty String indicates the locale </span>
<span class="c"># is derived from the environment variables.</span>
locale-collate <span class="s2">""</span>

<span class="c">################################ SNAPSHOTTING  ################################</span>

<span class="c"># Save the DB to disk.</span>
<span class="c">#</span>
<span class="c"># save &lt;seconds&gt; &lt;changes&gt; [&lt;seconds&gt; &lt;changes&gt; ...]</span>
<span class="c">#</span>
<span class="c"># Redis will save the DB if the given number of seconds elapsed and it</span>
<span class="c"># surpassed the given number of write operations against the DB.</span>
<span class="c">#</span>
<span class="c"># Snapshotting can be completely disabled with a single empty string argument</span>
<span class="c"># as in following example:</span>
<span class="c">#</span>
<span class="c"># save ""</span>
<span class="c">#</span>
<span class="c"># Unless specified otherwise, by default Redis will save the DB:</span>
<span class="c">#   * After 3600 seconds (an hour) if at least 1 change was performed</span>
<span class="c">#   * After 300 seconds (5 minutes) if at least 100 changes were performed</span>
<span class="c">#   * After 60 seconds if at least 10000 changes were performed</span>
<span class="c">#</span>
<span class="c"># You can set these explicitly by uncommenting the following line.</span>
<span class="c">#</span>
<span class="c"># save 3600 1 300 100 60 10000</span>

<span class="c"># By default Redis will stop accepting writes if RDB snapshots are enabled</span>
<span class="c"># (at least one save point) and the latest background save failed.</span>
<span class="c"># This will make the user aware (in a hard way) that data is not persisting</span>
<span class="c"># on disk properly, otherwise chances are that no one will notice and some</span>
<span class="c"># disaster will happen.</span>
<span class="c">#</span>
<span class="c"># If the background saving process will start working again Redis will</span>
<span class="c"># automatically allow writes again.</span>
<span class="c">#</span>
<span class="c"># However if you have setup your proper monitoring of the Redis server</span>
<span class="c"># and persistence, you may want to disable this feature so that Redis will</span>
<span class="c"># continue to work as usual even if there are problems with disk,</span>
<span class="c"># permissions, and so forth.</span>
stop-writes-on-bgsave-error <span class="nb">yes</span>

<span class="c"># Compress string objects using LZF when dump .rdb databases?</span>
<span class="c"># By default compression is enabled as it's almost always a win.</span>
<span class="c"># If you want to save some CPU in the saving child set it to 'no' but</span>
<span class="c"># the dataset will likely be bigger if you have compressible values or keys.</span>
rdbcompression <span class="nb">yes</span>

<span class="c"># Since version 5 of RDB a CRC64 checksum is placed at the end of the file.</span>
<span class="c"># This makes the format more resistant to corruption but there is a performance</span>
<span class="c"># hit to pay (around 10%) when saving and loading RDB files, so you can disable it</span>
<span class="c"># for maximum performances.</span>
<span class="c">#</span>
<span class="c"># RDB files created with checksum disabled have a checksum of zero that will</span>
<span class="c"># tell the loading code to skip the check.</span>
rdbchecksum <span class="nb">yes</span>

<span class="c"># Enables or disables full sanitization checks for ziplist and listpack etc when</span>
<span class="c"># loading an RDB or RESTORE payload. This reduces the chances of a assertion or</span>
<span class="c"># crash later on while processing commands.</span>
<span class="c"># Options:</span>
<span class="c">#   no         - Never perform full sanitization</span>
<span class="c">#   yes        - Always perform full sanitization</span>
<span class="c">#   clients    - Perform full sanitization only for user connections.</span>
<span class="c">#                Excludes: RDB files, RESTORE commands received from the master</span>
<span class="c">#                connection, and client connections which have the</span>
<span class="c">#                skip-sanitize-payload ACL flag.</span>
<span class="c"># The default should be 'clients' but since it currently affects cluster</span>
<span class="c"># resharding via MIGRATE, it is temporarily set to 'no' by default.</span>
<span class="c">#</span>
<span class="c"># sanitize-dump-payload no</span>

<span class="c"># The filename where to dump the DB</span>
dbfilename dump.rdb

<span class="c"># Remove RDB files used by replication in instances without persistence</span>
<span class="c"># enabled. By default this option is disabled, however there are environments</span>
<span class="c"># where for regulations or other security concerns, RDB files persisted on</span>
<span class="c"># disk by masters in order to feed replicas, or stored on disk by replicas</span>
<span class="c"># in order to load them for the initial synchronization, should be deleted</span>
<span class="c"># ASAP. Note that this option ONLY WORKS in instances that have both AOF</span>
<span class="c"># and RDB persistence disabled, otherwise is completely ignored.</span>
<span class="c">#</span>
<span class="c"># An alternative (and sometimes better) way to obtain the same effect is</span>
<span class="c"># to use diskless replication on both master and replicas instances. However</span>
<span class="c"># in the case of replicas, diskless is not always an option.</span>
rdb-del-sync-files no

<span class="c"># The working directory.</span>
<span class="c">#</span>
<span class="c"># The DB will be written inside this directory, with the filename specified</span>
<span class="c"># above using the 'dbfilename' configuration directive.</span>
<span class="c">#</span>
<span class="c"># The Append Only File will also be created inside this directory.</span>
<span class="c">#</span>
<span class="c"># Note that you must specify a directory here, not a file name.</span>
<span class="nb">dir</span> ./

<span class="c">################################# REPLICATION #################################</span>

<span class="c"># Master-Replica replication. Use replicaof to make a Redis instance a copy of</span>
<span class="c"># another Redis server. A few things to understand ASAP about Redis replication.</span>
<span class="c">#</span>
<span class="c">#   +------------------+      +---------------+</span>
<span class="c">#   |      Master      | ---&gt; |    Replica    |</span>
<span class="c">#   | (receive writes) |      |  (exact copy) |</span>
<span class="c">#   +------------------+      +---------------+</span>
<span class="c">#</span>
<span class="c"># 1) Redis replication is asynchronous, but you can configure a master to</span>
<span class="c">#    stop accepting writes if it appears to be not connected with at least</span>
<span class="c">#    a given number of replicas.</span>
<span class="c"># 2) Redis replicas are able to perform a partial resynchronization with the</span>
<span class="c">#    master if the replication link is lost for a relatively small amount of</span>
<span class="c">#    time. You may want to configure the replication backlog size (see the next</span>
<span class="c">#    sections of this file) with a sensible value depending on your needs.</span>
<span class="c"># 3) Replication is automatic and does not need user intervention. After a</span>
<span class="c">#    network partition replicas automatically try to reconnect to masters</span>
<span class="c">#    and resynchronize with them.</span>
<span class="c">#</span>
<span class="c"># replicaof &lt;masterip&gt; &lt;masterport&gt;</span>

<span class="c"># If the master is password protected (using the "requirepass" configuration</span>
<span class="c"># directive below) it is possible to tell the replica to authenticate before</span>
<span class="c"># starting the replication synchronization process, otherwise the master will</span>
<span class="c"># refuse the replica request.</span>
<span class="c">#</span>
<span class="c"># masterauth &lt;master-password&gt;</span>
<span class="c">#</span>
<span class="c"># However this is not enough if you are using Redis ACLs (for Redis version</span>
<span class="c"># 6 or greater), and the default user is not capable of running the PSYNC</span>
<span class="c"># command and/or other commands needed for replication. In this case it's</span>
<span class="c"># better to configure a special user to use with replication, and specify the</span>
<span class="c"># masteruser configuration as such:</span>
<span class="c">#</span>
<span class="c"># masteruser &lt;username&gt;</span>
<span class="c">#</span>
<span class="c"># When masteruser is specified, the replica will authenticate against its</span>
<span class="c"># master using the new AUTH form: AUTH &lt;username&gt; &lt;password&gt;.</span>

<span class="c"># When a replica loses its connection with the master, or when the replication</span>
<span class="c"># is still in progress, the replica can act in two different ways:</span>
<span class="c">#</span>
<span class="c"># 1) if replica-serve-stale-data is set to 'yes' (the default) the replica will</span>
<span class="c">#    still reply to client requests, possibly with out of date data, or the</span>
<span class="c">#    data set may just be empty if this is the first synchronization.</span>
<span class="c">#</span>
<span class="c"># 2) If replica-serve-stale-data is set to 'no' the replica will reply with error</span>
<span class="c">#    "MASTERDOWN Link with MASTER is down and replica-serve-stale-data is set to 'no'"</span>
<span class="c">#    to all data access commands, excluding commands such as:</span>
<span class="c">#    INFO, REPLICAOF, AUTH, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE,</span>
<span class="c">#    UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST,</span>
<span class="c">#    HOST and LATENCY.</span>
<span class="c">#</span>
replica-serve-stale-data <span class="nb">yes</span>

<span class="c"># You can configure a replica instance to accept writes or not. Writing against</span>
<span class="c"># a replica instance may be useful to store some ephemeral data (because data</span>
<span class="c"># written on a replica will be easily deleted after resync with the master) but</span>
<span class="c"># may also cause problems if clients are writing to it because of a</span>
<span class="c"># misconfiguration.</span>
<span class="c">#</span>
<span class="c"># Since Redis 2.6 by default replicas are read-only.</span>
<span class="c">#</span>
<span class="c"># Note: read only replicas are not designed to be exposed to untrusted clients</span>
<span class="c"># on the internet. It's just a protection layer against misuse of the instance.</span>
<span class="c"># Still a read only replica exports by default all the administrative commands</span>
<span class="c"># such as CONFIG, DEBUG, and so forth. To a limited extent you can improve</span>
<span class="c"># security of read only replicas using 'rename-command' to shadow all the</span>
<span class="c"># administrative / dangerous commands.</span>
replica-read-only <span class="nb">yes</span>

<span class="c"># Replication SYNC strategy: disk or socket.</span>
<span class="c">#</span>
<span class="c"># New replicas and reconnecting replicas that are not able to continue the</span>
<span class="c"># replication process just receiving differences, need to do what is called a</span>
<span class="c"># "full synchronization". An RDB file is transmitted from the master to the</span>
<span class="c"># replicas.</span>
<span class="c">#</span>
<span class="c"># The transmission can happen in two different ways:</span>
<span class="c">#</span>
<span class="c"># 1) Disk-backed: The Redis master creates a new process that writes the RDB</span>
<span class="c">#                 file on disk. Later the file is transferred by the parent</span>
<span class="c">#                 process to the replicas incrementally.</span>
<span class="c"># 2) Diskless: The Redis master creates a new process that directly writes the</span>
<span class="c">#              RDB file to replica sockets, without touching the disk at all.</span>
<span class="c">#</span>
<span class="c"># With disk-backed replication, while the RDB file is generated, more replicas</span>
<span class="c"># can be queued and served with the RDB file as soon as the current child</span>
<span class="c"># producing the RDB file finishes its work. With diskless replication instead</span>
<span class="c"># once the transfer starts, new replicas arriving will be queued and a new</span>
<span class="c"># transfer will start when the current one terminates.</span>
<span class="c">#</span>
<span class="c"># When diskless replication is used, the master waits a configurable amount of</span>
<span class="c"># time (in seconds) before starting the transfer in the hope that multiple</span>
<span class="c"># replicas will arrive and the transfer can be parallelized.</span>
<span class="c">#</span>
<span class="c"># With slow disks and fast (large bandwidth) networks, diskless replication</span>
<span class="c"># works better.</span>
repl-diskless-sync <span class="nb">yes</span>

<span class="c"># When diskless replication is enabled, it is possible to configure the delay</span>
<span class="c"># the server waits in order to spawn the child that transfers the RDB via socket</span>
<span class="c"># to the replicas.</span>
<span class="c">#</span>
<span class="c"># This is important since once the transfer starts, it is not possible to serve</span>
<span class="c"># new replicas arriving, that will be queued for the next RDB transfer, so the</span>
<span class="c"># server waits a delay in order to let more replicas arrive.</span>
<span class="c">#</span>
<span class="c"># The delay is specified in seconds, and by default is 5 seconds. To disable</span>
<span class="c"># it entirely just set it to 0 seconds and the transfer will start ASAP.</span>
repl-diskless-sync-delay 5

<span class="c"># When diskless replication is enabled with a delay, it is possible to let</span>
<span class="c"># the replication start before the maximum delay is reached if the maximum</span>
<span class="c"># number of replicas expected have connected. Default of 0 means that the</span>
<span class="c"># maximum is not defined and Redis will wait the full delay.</span>
repl-diskless-sync-max-replicas 0

<span class="c"># -----------------------------------------------------------------------------</span>
<span class="c"># WARNING: Since in this setup the replica does not immediately store an RDB on</span>
<span class="c"># disk, it may cause data loss during failovers. RDB diskless load + Redis</span>
<span class="c"># modules not handling I/O reads may cause Redis to abort in case of I/O errors</span>
<span class="c"># during the initial synchronization stage with the master.</span>
<span class="c"># -----------------------------------------------------------------------------</span>
<span class="c">#</span>
<span class="c"># Replica can load the RDB it reads from the replication link directly from the</span>
<span class="c"># socket, or store the RDB to a file and read that file after it was completely</span>
<span class="c"># received from the master.</span>
<span class="c">#</span>
<span class="c"># In many cases the disk is slower than the network, and storing and loading</span>
<span class="c"># the RDB file may increase replication time (and even increase the master's</span>
<span class="c"># Copy on Write memory and replica buffers).</span>
<span class="c"># However, when parsing the RDB file directly from the socket, in order to avoid</span>
<span class="c"># data loss it's only safe to flush the current dataset when the new dataset is</span>
<span class="c"># fully loaded in memory, resulting in higher memory usage.</span>
<span class="c"># For this reason we have the following options:</span>
<span class="c">#</span>
<span class="c"># "disabled"    - Don't use diskless load (store the rdb file to the disk first)</span>
<span class="c"># "swapdb"      - Keep current db contents in RAM while parsing the data directly</span>
<span class="c">#                 from the socket. Replicas in this mode can keep serving current</span>
<span class="c">#                 dataset while replication is in progress, except for cases where</span>
<span class="c">#                 they can't recognize master as having a data set from same</span>
<span class="c">#                 replication history.</span>
<span class="c">#                 Note that this requires sufficient memory, if you don't have it,</span>
<span class="c">#                 you risk an OOM kill.</span>
<span class="c"># "on-empty-db" - Use diskless load only when current dataset is empty. This is </span>
<span class="c">#                 safer and avoid having old and new dataset loaded side by side</span>
<span class="c">#                 during replication.</span>
repl-diskless-load disabled

<span class="c"># Master send PINGs to its replicas in a predefined interval. It's possible to</span>
<span class="c"># change this interval with the repl_ping_replica_period option. The default</span>
<span class="c"># value is 10 seconds.</span>
<span class="c">#</span>
<span class="c"># repl-ping-replica-period 10</span>

<span class="c"># The following option sets the replication timeout for:</span>
<span class="c">#</span>
<span class="c"># 1) Bulk transfer I/O during SYNC, from the point of view of replica.</span>
<span class="c"># 2) Master timeout from the point of view of replicas (data, pings).</span>
<span class="c"># 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).</span>
<span class="c">#</span>
<span class="c"># It is important to make sure that this value is greater than the value</span>
<span class="c"># specified for repl-ping-replica-period otherwise a timeout will be detected</span>
<span class="c"># every time there is low traffic between the master and the replica. The default</span>
<span class="c"># value is 60 seconds.</span>
<span class="c">#</span>
<span class="c"># repl-timeout 60</span>

<span class="c"># Disable TCP_NODELAY on the replica socket after SYNC?</span>
<span class="c">#</span>
<span class="c"># If you select "yes" Redis will use a smaller number of TCP packets and</span>
<span class="c"># less bandwidth to send data to replicas. But this can add a delay for</span>
<span class="c"># the data to appear on the replica side, up to 40 milliseconds with</span>
<span class="c"># Linux kernels using a default configuration.</span>
<span class="c">#</span>
<span class="c"># If you select "no" the delay for data to appear on the replica side will</span>
<span class="c"># be reduced but more bandwidth will be used for replication.</span>
<span class="c">#</span>
<span class="c"># By default we optimize for low latency, but in very high traffic conditions</span>
<span class="c"># or when the master and replicas are many hops away, turning this to "yes" may</span>
<span class="c"># be a good idea.</span>
repl-disable-tcp-nodelay no

<span class="c"># Set the replication backlog size. The backlog is a buffer that accumulates</span>
<span class="c"># replica data when replicas are disconnected for some time, so that when a</span>
<span class="c"># replica wants to reconnect again, often a full resync is not needed, but a</span>
<span class="c"># partial resync is enough, just passing the portion of data the replica</span>
<span class="c"># missed while disconnected.</span>
<span class="c">#</span>
<span class="c"># The bigger the replication backlog, the longer the replica can endure the</span>
<span class="c"># disconnect and later be able to perform a partial resynchronization.</span>
<span class="c">#</span>
<span class="c"># The backlog is only allocated if there is at least one replica connected.</span>
<span class="c">#</span>
<span class="c"># repl-backlog-size 1mb</span>

<span class="c"># After a master has no connected replicas for some time, the backlog will be</span>
<span class="c"># freed. The following option configures the amount of seconds that need to</span>
<span class="c"># elapse, starting from the time the last replica disconnected, for the backlog</span>
<span class="c"># buffer to be freed.</span>
<span class="c">#</span>
<span class="c"># Note that replicas never free the backlog for timeout, since they may be</span>
<span class="c"># promoted to masters later, and should be able to correctly "partially</span>
<span class="c"># resynchronize" with other replicas: hence they should always accumulate backlog.</span>
<span class="c">#</span>
<span class="c"># A value of 0 means to never release the backlog.</span>
<span class="c">#</span>
<span class="c"># repl-backlog-ttl 3600</span>

<span class="c"># The replica priority is an integer number published by Redis in the INFO</span>
<span class="c"># output. It is used by Redis Sentinel in order to select a replica to promote</span>
<span class="c"># into a master if the master is no longer working correctly.</span>
<span class="c">#</span>
<span class="c"># A replica with a low priority number is considered better for promotion, so</span>
<span class="c"># for instance if there are three replicas with priority 10, 100, 25 Sentinel</span>
<span class="c"># will pick the one with priority 10, that is the lowest.</span>
<span class="c">#</span>
<span class="c"># However a special priority of 0 marks the replica as not able to perform the</span>
<span class="c"># role of master, so a replica with priority of 0 will never be selected by</span>
<span class="c"># Redis Sentinel for promotion.</span>
<span class="c">#</span>
<span class="c"># By default the priority is 100.</span>
replica-priority 100

<span class="c"># The propagation error behavior controls how Redis will behave when it is</span>
<span class="c"># unable to handle a command being processed in the replication stream from a master</span>
<span class="c"># or processed while reading from an AOF file. Errors that occur during propagation</span>
<span class="c"># are unexpected, and can cause data inconsistency. However, there are edge cases</span>
<span class="c"># in earlier versions of Redis where it was possible for the server to replicate or persist</span>
<span class="c"># commands that would fail on future versions. For this reason the default behavior</span>
<span class="c"># is to ignore such errors and continue processing commands.</span>
<span class="c">#</span>
<span class="c"># If an application wants to ensure there is no data divergence, this configuration</span>
<span class="c"># should be set to 'panic' instead. The value can also be set to 'panic-on-replicas'</span>
<span class="c"># to only panic when a replica encounters an error on the replication stream. One of</span>
<span class="c"># these two panic values will become the default value in the future once there are</span>
<span class="c"># sufficient safety mechanisms in place to prevent false positive crashes.</span>
<span class="c">#</span>
<span class="c"># propagation-error-behavior ignore</span>

<span class="c"># Replica ignore disk write errors controls the behavior of a replica when it is</span>
<span class="c"># unable to persist a write command received from its master to disk. By default,</span>
<span class="c"># this configuration is set to 'no' and will crash the replica in this condition.</span>
<span class="c"># It is not recommended to change this default, however in order to be compatible</span>
<span class="c"># with older versions of Redis this config can be toggled to 'yes' which will just</span>
<span class="c"># log a warning and execute the write command it got from the master.</span>
<span class="c">#</span>
<span class="c"># replica-ignore-disk-write-errors no</span>

<span class="c"># -----------------------------------------------------------------------------</span>
<span class="c"># By default, Redis Sentinel includes all replicas in its reports. A replica</span>
<span class="c"># can be excluded from Redis Sentinel's announcements. An unannounced replica</span>
<span class="c"># will be ignored by the 'sentinel replicas &lt;master&gt;' command and won't be</span>
<span class="c"># exposed to Redis Sentinel's clients.</span>
<span class="c">#</span>
<span class="c"># This option does not change the behavior of replica-priority. Even with</span>
<span class="c"># replica-announced set to 'no', the replica can be promoted to master. To</span>
<span class="c"># prevent this behavior, set replica-priority to 0.</span>
<span class="c">#</span>
<span class="c"># replica-announced yes</span>

<span class="c"># It is possible for a master to stop accepting writes if there are less than</span>
<span class="c"># N replicas connected, having a lag less or equal than M seconds.</span>
<span class="c">#</span>
<span class="c"># The N replicas need to be in "online" state.</span>
<span class="c">#</span>
<span class="c"># The lag in seconds, that must be &lt;= the specified value, is calculated from</span>
<span class="c"># the last ping received from the replica, that is usually sent every second.</span>
<span class="c">#</span>
<span class="c"># This option does not GUARANTEE that N replicas will accept the write, but</span>
<span class="c"># will limit the window of exposure for lost writes in case not enough replicas</span>
<span class="c"># are available, to the specified number of seconds.</span>
<span class="c">#</span>
<span class="c"># For example to require at least 3 replicas with a lag &lt;= 10 seconds use:</span>
<span class="c">#</span>
<span class="c"># min-replicas-to-write 3</span>
<span class="c"># min-replicas-max-lag 10</span>
<span class="c">#</span>
<span class="c"># Setting one or the other to 0 disables the feature.</span>
<span class="c">#</span>
<span class="c"># By default min-replicas-to-write is set to 0 (feature disabled) and</span>
<span class="c"># min-replicas-max-lag is set to 10.</span>

<span class="c"># A Redis master is able to list the address and port of the attached</span>
<span class="c"># replicas in different ways. For example the "INFO replication" section</span>
<span class="c"># offers this information, which is used, among other tools, by</span>
<span class="c"># Redis Sentinel in order to discover replica instances.</span>
<span class="c"># Another place where this info is available is in the output of the</span>
<span class="c"># "ROLE" command of a master.</span>
<span class="c">#</span>
<span class="c"># The listed IP address and port normally reported by a replica is</span>
<span class="c"># obtained in the following way:</span>
<span class="c">#</span>
<span class="c">#   IP: The address is auto detected by checking the peer address</span>
<span class="c">#   of the socket used by the replica to connect with the master.</span>
<span class="c">#</span>
<span class="c">#   Port: The port is communicated by the replica during the replication</span>
<span class="c">#   handshake, and is normally the port that the replica is using to</span>
<span class="c">#   listen for connections.</span>
<span class="c">#</span>
<span class="c"># However when port forwarding or Network Address Translation (NAT) is</span>
<span class="c"># used, the replica may actually be reachable via different IP and port</span>
<span class="c"># pairs. The following two options can be used by a replica in order to</span>
<span class="c"># report to its master a specific set of IP and port, so that both INFO</span>
<span class="c"># and ROLE will report those values.</span>
<span class="c">#</span>
<span class="c"># There is no need to use both the options if you need to override just</span>
<span class="c"># the port or the IP address.</span>
<span class="c">#</span>
<span class="c"># replica-announce-ip 5.5.5.5</span>
<span class="c"># replica-announce-port 1234</span>

<span class="c">############################### KEYS TRACKING #################################</span>

<span class="c"># Redis implements server assisted support for client side caching of values.</span>
<span class="c"># This is implemented using an invalidation table that remembers, using</span>
<span class="c"># a radix key indexed by key name, what clients have which keys. In turn</span>
<span class="c"># this is used in order to send invalidation messages to clients. Please</span>
<span class="c"># check this page to understand more about the feature:</span>
<span class="c">#</span>
<span class="c">#   https://redis.io/topics/client-side-caching</span>
<span class="c">#</span>
<span class="c"># When tracking is enabled for a client, all the read only queries are assumed</span>
<span class="c"># to be cached: this will force Redis to store information in the invalidation</span>
<span class="c"># table. When keys are modified, such information is flushed away, and</span>
<span class="c"># invalidation messages are sent to the clients. However if the workload is</span>
<span class="c"># heavily dominated by reads, Redis could use more and more memory in order</span>
<span class="c"># to track the keys fetched by many clients.</span>
<span class="c">#</span>
<span class="c"># For this reason it is possible to configure a maximum fill value for the</span>
<span class="c"># invalidation table. By default it is set to 1M of keys, and once this limit</span>
<span class="c"># is reached, Redis will start to evict keys in the invalidation table</span>
<span class="c"># even if they were not modified, just to reclaim memory: this will in turn</span>
<span class="c"># force the clients to invalidate the cached values. Basically the table</span>
<span class="c"># maximum size is a trade off between the memory you want to spend server</span>
<span class="c"># side to track information about who cached what, and the ability of clients</span>
<span class="c"># to retain cached objects in memory.</span>
<span class="c">#</span>
<span class="c"># If you set the value to 0, it means there are no limits, and Redis will</span>
<span class="c"># retain as many keys as needed in the invalidation table.</span>
<span class="c"># In the "stats" INFO section, you can find information about the number of</span>
<span class="c"># keys in the invalidation table at every given moment.</span>
<span class="c">#</span>
<span class="c"># Note: when key tracking is used in broadcasting mode, no memory is used</span>
<span class="c"># in the server side so this setting is useless.</span>
<span class="c">#</span>
<span class="c"># tracking-table-max-keys 1000000</span>

<span class="c">################################## SECURITY ###################################</span>

<span class="c"># Warning: since Redis is pretty fast, an outside user can try up to</span>
<span class="c"># 1 million passwords per second against a modern box. This means that you</span>
<span class="c"># should use very strong passwords, otherwise they will be very easy to break.</span>
<span class="c"># Note that because the password is really a shared secret between the client</span>
<span class="c"># and the server, and should not be memorized by any human, the password</span>
<span class="c"># can be easily a long string from /dev/urandom or whatever, so by using a</span>
<span class="c"># long and unguessable password no brute force attack will be possible.</span>

<span class="c"># Redis ACL users are defined in the following format:</span>
<span class="c">#</span>
<span class="c">#   user &lt;username&gt; ... acl rules ...</span>
<span class="c">#</span>
<span class="c"># For example:</span>
<span class="c">#</span>
<span class="c">#   user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99</span>
<span class="c">#</span>
<span class="c"># The special username "default" is used for new connections. If this user</span>
<span class="c"># has the "nopass" rule, then new connections will be immediately authenticated</span>
<span class="c"># as the "default" user without the need of any password provided via the</span>
<span class="c"># AUTH command. Otherwise if the "default" user is not flagged with "nopass"</span>
<span class="c"># the connections will start in not authenticated state, and will require</span>
<span class="c"># AUTH (or the HELLO command AUTH option) in order to be authenticated and</span>
<span class="c"># start to work.</span>
<span class="c">#</span>
<span class="c"># The ACL rules that describe what a user can do are the following:</span>
<span class="c">#</span>
<span class="c">#  on           Enable the user: it is possible to authenticate as this user.</span>
<span class="c">#  off          Disable the user: it's no longer possible to authenticate</span>
<span class="c">#               with this user, however the already authenticated connections</span>
<span class="c">#               will still work.</span>
<span class="c">#  skip-sanitize-payload    RESTORE dump-payload sanitization is skipped.</span>
<span class="c">#  sanitize-payload         RESTORE dump-payload is sanitized (default).</span>
<span class="c">#  +&lt;command&gt;   Allow the execution of that command.</span>
<span class="c">#               May be used with `|` for allowing subcommands (e.g "+config|get")</span>
<span class="c">#  -&lt;command&gt;   Disallow the execution of that command.</span>
<span class="c">#               May be used with `|` for blocking subcommands (e.g "-config|set")</span>
<span class="c">#  +@&lt;category&gt; Allow the execution of all the commands in such category</span>
<span class="c">#               with valid categories are like @admin, @set, @sortedset, ...</span>
<span class="c">#               and so forth, see the full list in the server.c file where</span>
<span class="c">#               the Redis command table is described and defined.</span>
<span class="c">#               The special category @all means all the commands, but currently</span>
<span class="c">#               present in the server, and that will be loaded in the future</span>
<span class="c">#               via modules.</span>
<span class="c">#  +&lt;command&gt;|first-arg  Allow a specific first argument of an otherwise</span>
<span class="c">#                        disabled command. It is only supported on commands with</span>
<span class="c">#                        no sub-commands, and is not allowed as negative form</span>
<span class="c">#                        like -SELECT|1, only additive starting with "+". This</span>
<span class="c">#                        feature is deprecated and may be removed in the future.</span>
<span class="c">#  allcommands  Alias for +@all. Note that it implies the ability to execute</span>
<span class="c">#               all the future commands loaded via the modules system.</span>
<span class="c">#  nocommands   Alias for -@all.</span>
<span class="c">#  ~&lt;pattern&gt;   Add a pattern of keys that can be mentioned as part of</span>
<span class="c">#               commands. For instance ~* allows all the keys. The pattern</span>
<span class="c">#               is a glob-style pattern like the one of KEYS.</span>
<span class="c">#               It is possible to specify multiple patterns.</span>
<span class="c"># %R~&lt;pattern&gt;  Add key read pattern that specifies which keys can be read </span>
<span class="c">#               from.</span>
<span class="c"># %W~&lt;pattern&gt;  Add key write pattern that specifies which keys can be</span>
<span class="c">#               written to. </span>
<span class="c">#  allkeys      Alias for ~*</span>
<span class="c">#  resetkeys    Flush the list of allowed keys patterns.</span>
<span class="c">#  &amp;&lt;pattern&gt;   Add a glob-style pattern of Pub/Sub channels that can be</span>
<span class="c">#               accessed by the user. It is possible to specify multiple channel</span>
<span class="c">#               patterns.</span>
<span class="c">#  allchannels  Alias for &amp;*</span>
<span class="c">#  resetchannels            Flush the list of allowed channel patterns.</span>
<span class="c">#  &gt;&lt;password&gt;  Add this password to the list of valid password for the user.</span>
<span class="c">#               For example &gt;mypass will add "mypass" to the list.</span>
<span class="c">#               This directive clears the "nopass" flag (see later).</span>
<span class="c">#  &lt;&lt;password&gt;  Remove this password from the list of valid passwords.</span>
<span class="c">#  nopass       All the set passwords of the user are removed, and the user</span>
<span class="c">#               is flagged as requiring no password: it means that every</span>
<span class="c">#               password will work against this user. If this directive is</span>
<span class="c">#               used for the default user, every new connection will be</span>
<span class="c">#               immediately authenticated with the default user without</span>
<span class="c">#               any explicit AUTH command required. Note that the "resetpass"</span>
<span class="c">#               directive will clear this condition.</span>
<span class="c">#  resetpass    Flush the list of allowed passwords. Moreover removes the</span>
<span class="c">#               "nopass" status. After "resetpass" the user has no associated</span>
<span class="c">#               passwords and there is no way to authenticate without adding</span>
<span class="c">#               some password (or setting it as "nopass" later).</span>
<span class="c">#  reset        Performs the following actions: resetpass, resetkeys, resetchannels,</span>
<span class="c">#               allchannels (if acl-pubsub-default is set), off, clearselectors, -@all.</span>
<span class="c">#               The user returns to the same state it has immediately after its creation.</span>
<span class="c"># (&lt;options&gt;)   Create a new selector with the options specified within the</span>
<span class="c">#               parentheses and attach it to the user. Each option should be </span>
<span class="c">#               space separated. The first character must be ( and the last </span>
<span class="c">#               character must be ).</span>
<span class="c"># clearselectors            Remove all of the currently attached selectors. </span>
<span class="c">#                           Note this does not change the "root" user permissions,</span>
<span class="c">#                           which are the permissions directly applied onto the</span>
<span class="c">#                           user (outside the parentheses).</span>
<span class="c">#</span>
<span class="c"># ACL rules can be specified in any order: for instance you can start with</span>
<span class="c"># passwords, then flags, or key patterns. However note that the additive</span>
<span class="c"># and subtractive rules will CHANGE MEANING depending on the ordering.</span>
<span class="c"># For instance see the following example:</span>
<span class="c">#</span>
<span class="c">#   user alice on +@all -DEBUG ~* &gt;somepassword</span>
<span class="c">#</span>
<span class="c"># This will allow "alice" to use all the commands with the exception of the</span>
<span class="c"># DEBUG command, since +@all added all the commands to the set of the commands</span>
<span class="c"># alice can use, and later DEBUG was removed. However if we invert the order</span>
<span class="c"># of two ACL rules the result will be different:</span>
<span class="c">#</span>
<span class="c">#   user alice on -DEBUG +@all ~* &gt;somepassword</span>
<span class="c">#</span>
<span class="c"># Now DEBUG was removed when alice had yet no commands in the set of allowed</span>
<span class="c"># commands, later all the commands are added, so the user will be able to</span>
<span class="c"># execute everything.</span>
<span class="c">#</span>
<span class="c"># Basically ACL rules are processed left-to-right.</span>
<span class="c">#</span>
<span class="c"># The following is a list of command categories and their meanings:</span>
<span class="c"># * keyspace - Writing or reading from keys, databases, or their metadata </span>
<span class="c">#     in a type agnostic way. Includes DEL, RESTORE, DUMP, RENAME, EXISTS, DBSIZE,</span>
<span class="c">#     KEYS, EXPIRE, TTL, FLUSHALL, etc. Commands that may modify the keyspace,</span>
<span class="c">#     key or metadata will also have `write` category. Commands that only read</span>
<span class="c">#     the keyspace, key or metadata will have the `read` category.</span>
<span class="c"># * read - Reading from keys (values or metadata). Note that commands that don't</span>
<span class="c">#     interact with keys, will not have either `read` or `write`.</span>
<span class="c"># * write - Writing to keys (values or metadata)</span>
<span class="c"># * admin - Administrative commands. Normal applications will never need to use</span>
<span class="c">#     these. Includes REPLICAOF, CONFIG, DEBUG, SAVE, MONITOR, ACL, SHUTDOWN, etc.</span>
<span class="c"># * dangerous - Potentially dangerous (each should be considered with care for</span>
<span class="c">#     various reasons). This includes FLUSHALL, MIGRATE, RESTORE, SORT, KEYS,</span>
<span class="c">#     CLIENT, DEBUG, INFO, CONFIG, SAVE, REPLICAOF, etc.</span>
<span class="c"># * connection - Commands affecting the connection or other connections.</span>
<span class="c">#     This includes AUTH, SELECT, COMMAND, CLIENT, ECHO, PING, etc.</span>
<span class="c"># * blocking - Potentially blocking the connection until released by another</span>
<span class="c">#     command.</span>
<span class="c"># * fast - Fast O(1) commands. May loop on the number of arguments, but not the</span>
<span class="c">#     number of elements in the key.</span>
<span class="c"># * slow - All commands that are not Fast.</span>
<span class="c"># * pubsub - PUBLISH / SUBSCRIBE related</span>
<span class="c"># * transaction - WATCH / MULTI / EXEC related commands.</span>
<span class="c"># * scripting - Scripting related.</span>
<span class="c"># * set - Data type: sets related.</span>
<span class="c"># * sortedset - Data type: zsets related.</span>
<span class="c"># * list - Data type: lists related.</span>
<span class="c"># * hash - Data type: hashes related.</span>
<span class="c"># * string - Data type: strings related.</span>
<span class="c"># * bitmap - Data type: bitmaps related.</span>
<span class="c"># * hyperloglog - Data type: hyperloglog related.</span>
<span class="c"># * geo - Data type: geo related.</span>
<span class="c"># * stream - Data type: streams related.</span>
<span class="c">#</span>
<span class="c"># For more information about ACL configuration please refer to</span>
<span class="c"># the Redis web site at https://redis.io/topics/acl</span>

<span class="c"># ACL LOG</span>
<span class="c">#</span>
<span class="c"># The ACL Log tracks failed commands and authentication events associated</span>
<span class="c"># with ACLs. The ACL Log is useful to troubleshoot failed commands blocked</span>
<span class="c"># by ACLs. The ACL Log is stored in memory. You can reclaim memory with</span>
<span class="c"># ACL LOG RESET. Define the maximum entry length of the ACL Log below.</span>
acllog-max-len 128

<span class="c"># Using an external ACL file</span>
<span class="c">#</span>
<span class="c"># Instead of configuring users here in this file, it is possible to use</span>
<span class="c"># a stand-alone file just listing users. The two methods cannot be mixed:</span>
<span class="c"># if you configure users here and at the same time you activate the external</span>
<span class="c"># ACL file, the server will refuse to start.</span>
<span class="c">#</span>
<span class="c"># The format of the external ACL user file is exactly the same as the</span>
<span class="c"># format that is used inside redis.conf to describe users.</span>
<span class="c">#</span>
<span class="c"># aclfile /etc/redis/users.acl</span>

<span class="c"># IMPORTANT NOTE: starting with Redis 6 "requirepass" is just a compatibility</span>
<span class="c"># layer on top of the new ACL system. The option effect will be just setting</span>
<span class="c"># the password for the default user. Clients will still authenticate using</span>
<span class="c"># AUTH &lt;password&gt; as usually, or more explicitly with AUTH default &lt;password&gt;</span>
<span class="c"># if they follow the new protocol: both will work.</span>
<span class="c">#</span>
<span class="c"># The requirepass is not compatible with aclfile option and the ACL LOAD</span>
<span class="c"># command, these will cause requirepass to be ignored.</span>
<span class="c">#</span>
<span class="c"># requirepass foobared</span>

<span class="c"># New users are initialized with restrictive permissions by default, via the</span>
<span class="c"># equivalent of this ACL rule 'off resetkeys -@all'. Starting with Redis 6.2, it</span>
<span class="c"># is possible to manage access to Pub/Sub channels with ACL rules as well. The</span>
<span class="c"># default Pub/Sub channels permission if new users is controlled by the</span>
<span class="c"># acl-pubsub-default configuration directive, which accepts one of these values:</span>
<span class="c">#</span>
<span class="c"># allchannels: grants access to all Pub/Sub channels</span>
<span class="c"># resetchannels: revokes access to all Pub/Sub channels</span>
<span class="c">#</span>
<span class="c"># From Redis 7.0, acl-pubsub-default defaults to 'resetchannels' permission.</span>
<span class="c">#</span>
<span class="c"># acl-pubsub-default resetchannels</span>

<span class="c"># Command renaming (DEPRECATED).</span>
<span class="c">#</span>
<span class="c"># ------------------------------------------------------------------------</span>
<span class="c"># WARNING: avoid using this option if possible. Instead use ACLs to remove</span>
<span class="c"># commands from the default user, and put them only in some admin user you</span>
<span class="c"># create for administrative purposes.</span>
<span class="c"># ------------------------------------------------------------------------</span>
<span class="c">#</span>
<span class="c"># It is possible to change the name of dangerous commands in a shared</span>
<span class="c"># environment. For instance the CONFIG command may be renamed into something</span>
<span class="c"># hard to guess so that it will still be available for internal-use tools</span>
<span class="c"># but not available for general clients.</span>
<span class="c">#</span>
<span class="c"># Example:</span>
<span class="c">#</span>
<span class="c"># rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52</span>
<span class="c">#</span>
<span class="c"># It is also possible to completely kill a command by renaming it into</span>
<span class="c"># an empty string:</span>
<span class="c">#</span>
<span class="c"># rename-command CONFIG ""</span>
<span class="c">#</span>
<span class="c"># Please note that changing the name of commands that are logged into the</span>
<span class="c"># AOF file or transmitted to replicas may cause problems.</span>

<span class="c">################################### CLIENTS ####################################</span>

<span class="c"># Set the max number of connected clients at the same time. By default</span>
<span class="c"># this limit is set to 10000 clients, however if the Redis server is not</span>
<span class="c"># able to configure the process file limit to allow for the specified limit</span>
<span class="c"># the max number of allowed clients is set to the current file limit</span>
<span class="c"># minus 32 (as Redis reserves a few file descriptors for internal uses).</span>
<span class="c">#</span>
<span class="c"># Once the limit is reached Redis will close all the new connections sending</span>
<span class="c"># an error 'max number of clients reached'.</span>
<span class="c">#</span>
<span class="c"># IMPORTANT: When Redis Cluster is used, the max number of connections is also</span>
<span class="c"># shared with the cluster bus: every node in the cluster will use two</span>
<span class="c"># connections, one incoming and another outgoing. It is important to size the</span>
<span class="c"># limit accordingly in case of very large clusters.</span>
<span class="c">#</span>
<span class="c"># maxclients 10000</span>

<span class="c">############################## MEMORY MANAGEMENT ################################</span>

<span class="c"># Set a memory usage limit to the specified amount of bytes.</span>
<span class="c"># When the memory limit is reached Redis will try to remove keys</span>
<span class="c"># according to the eviction policy selected (see maxmemory-policy).</span>
<span class="c">#</span>
<span class="c"># If Redis can't remove keys according to the policy, or if the policy is</span>
<span class="c"># set to 'noeviction', Redis will start to reply with errors to commands</span>
<span class="c"># that would use more memory, like SET, LPUSH, and so on, and will continue</span>
<span class="c"># to reply to read-only commands like GET.</span>
<span class="c">#</span>
<span class="c"># This option is usually useful when using Redis as an LRU or LFU cache, or to</span>
<span class="c"># set a hard memory limit for an instance (using the 'noeviction' policy).</span>
<span class="c">#</span>
<span class="c"># WARNING: If you have replicas attached to an instance with maxmemory on,</span>
<span class="c"># the size of the output buffers needed to feed the replicas are subtracted</span>
<span class="c"># from the used memory count, so that network problems / resyncs will</span>
<span class="c"># not trigger a loop where keys are evicted, and in turn the output</span>
<span class="c"># buffer of replicas is full with DELs of keys evicted triggering the deletion</span>
<span class="c"># of more keys, and so forth until the database is completely emptied.</span>
<span class="c">#</span>
<span class="c"># In short... if you have replicas attached it is suggested that you set a lower</span>
<span class="c"># limit for maxmemory so that there is some free RAM on the system for replica</span>
<span class="c"># output buffers (but this is not needed if the policy is 'noeviction').</span>
<span class="c">#</span>
<span class="c"># maxmemory &lt;bytes&gt;</span>

<span class="c"># MAXMEMORY POLICY: how Redis will select what to remove when maxmemory</span>
<span class="c"># is reached. You can select one from the following behaviors:</span>
<span class="c">#</span>
<span class="c"># volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set.</span>
<span class="c"># allkeys-lru -&gt; Evict any key using approximated LRU.</span>
<span class="c"># volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set.</span>
<span class="c"># allkeys-lfu -&gt; Evict any key using approximated LFU.</span>
<span class="c"># volatile-random -&gt; Remove a random key having an expire set.</span>
<span class="c"># allkeys-random -&gt; Remove a random key, any key.</span>
<span class="c"># volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)</span>
<span class="c"># noeviction -&gt; Don't evict anything, just return an error on write operations.</span>
<span class="c">#</span>
<span class="c"># LRU means Least Recently Used</span>
<span class="c"># LFU means Least Frequently Used</span>
<span class="c">#</span>
<span class="c"># Both LRU, LFU and volatile-ttl are implemented using approximated</span>
<span class="c"># randomized algorithms.</span>
<span class="c">#</span>
<span class="c"># Note: with any of the above policies, when there are no suitable keys for</span>
<span class="c"># eviction, Redis will return an error on write operations that require</span>
<span class="c"># more memory. These are usually commands that create new keys, add data or</span>
<span class="c"># modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE,</span>
<span class="c"># SORT (due to the STORE argument), and EXEC (if the transaction includes any</span>
<span class="c"># command that requires memory).</span>
<span class="c">#</span>
<span class="c"># The default is:</span>
<span class="c">#</span>
<span class="c"># maxmemory-policy noeviction</span>

<span class="c"># LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated</span>
<span class="c"># algorithms (in order to save memory), so you can tune it for speed or</span>
<span class="c"># accuracy. By default Redis will check five keys and pick the one that was</span>
<span class="c"># used least recently, you can change the sample size using the following</span>
<span class="c"># configuration directive.</span>
<span class="c">#</span>
<span class="c"># The default of 5 produces good enough results. 10 Approximates very closely</span>
<span class="c"># true LRU but costs more CPU. 3 is faster but not very accurate.</span>
<span class="c">#</span>
<span class="c"># maxmemory-samples 5</span>

<span class="c"># Eviction processing is designed to function well with the default setting.</span>
<span class="c"># If there is an unusually large amount of write traffic, this value may need to</span>
<span class="c"># be increased.  Decreasing this value may reduce latency at the risk of</span>
<span class="c"># eviction processing effectiveness</span>
<span class="c">#   0 = minimum latency, 10 = default, 100 = process without regard to latency</span>
<span class="c">#</span>
<span class="c"># maxmemory-eviction-tenacity 10</span>

<span class="c"># Starting from Redis 5, by default a replica will ignore its maxmemory setting</span>
<span class="c"># (unless it is promoted to master after a failover or manually). It means</span>
<span class="c"># that the eviction of keys will be just handled by the master, sending the</span>
<span class="c"># DEL commands to the replica as keys evict in the master side.</span>
<span class="c">#</span>
<span class="c"># This behavior ensures that masters and replicas stay consistent, and is usually</span>
<span class="c"># what you want, however if your replica is writable, or you want the replica</span>
<span class="c"># to have a different memory setting, and you are sure all the writes performed</span>
<span class="c"># to the replica are idempotent, then you may change this default (but be sure</span>
<span class="c"># to understand what you are doing).</span>
<span class="c">#</span>
<span class="c"># Note that since the replica by default does not evict, it may end using more</span>
<span class="c"># memory than the one set via maxmemory (there are certain buffers that may</span>
<span class="c"># be larger on the replica, or data structures may sometimes take more memory</span>
<span class="c"># and so forth). So make sure you monitor your replicas and make sure they</span>
<span class="c"># have enough memory to never hit a real out-of-memory condition before the</span>
<span class="c"># master hits the configured maxmemory setting.</span>
<span class="c">#</span>
<span class="c"># replica-ignore-maxmemory yes</span>

<span class="c"># Redis reclaims expired keys in two ways: upon access when those keys are</span>
<span class="c"># found to be expired, and also in background, in what is called the</span>
<span class="c"># "active expire key". The key space is slowly and interactively scanned</span>
<span class="c"># looking for expired keys to reclaim, so that it is possible to free memory</span>
<span class="c"># of keys that are expired and will never be accessed again in a short time.</span>
<span class="c">#</span>
<span class="c"># The default effort of the expire cycle will try to avoid having more than</span>
<span class="c"># ten percent of expired keys still in memory, and will try to avoid consuming</span>
<span class="c"># more than 25% of total memory and to add latency to the system. However</span>
<span class="c"># it is possible to increase the expire "effort" that is normally set to</span>
<span class="c"># "1", to a greater value, up to the value "10". At its maximum value the</span>
<span class="c"># system will use more CPU, longer cycles (and technically may introduce</span>
<span class="c"># more latency), and will tolerate less already expired keys still present</span>
<span class="c"># in the system. It's a tradeoff between memory, CPU and latency.</span>
<span class="c">#</span>
<span class="c"># active-expire-effort 1</span>

<span class="c">############################# LAZY FREEING ####################################</span>

<span class="c"># Redis has two primitives to delete keys. One is called DEL and is a blocking</span>
<span class="c"># deletion of the object. It means that the server stops processing new commands</span>
<span class="c"># in order to reclaim all the memory associated with an object in a synchronous</span>
<span class="c"># way. If the key deleted is associated with a small object, the time needed</span>
<span class="c"># in order to execute the DEL command is very small and comparable to most other</span>
<span class="c"># O(1) or O(log_N) commands in Redis. However if the key is associated with an</span>
<span class="c"># aggregated value containing millions of elements, the server can block for</span>
<span class="c"># a long time (even seconds) in order to complete the operation.</span>
<span class="c">#</span>
<span class="c"># For the above reasons Redis also offers non blocking deletion primitives</span>
<span class="c"># such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and</span>
<span class="c"># FLUSHDB commands, in order to reclaim memory in background. Those commands</span>
<span class="c"># are executed in constant time. Another thread will incrementally free the</span>
<span class="c"># object in the background as fast as possible.</span>
<span class="c">#</span>
<span class="c"># DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.</span>
<span class="c"># It's up to the design of the application to understand when it is a good</span>
<span class="c"># idea to use one or the other. However the Redis server sometimes has to</span>
<span class="c"># delete keys or flush the whole database as a side effect of other operations.</span>
<span class="c"># Specifically Redis deletes objects independently of a user call in the</span>
<span class="c"># following scenarios:</span>
<span class="c">#</span>
<span class="c"># 1) On eviction, because of the maxmemory and maxmemory policy configurations,</span>
<span class="c">#    in order to make room for new data, without going over the specified</span>
<span class="c">#    memory limit.</span>
<span class="c"># 2) Because of expire: when a key with an associated time to live (see the</span>
<span class="c">#    EXPIRE command) must be deleted from memory.</span>
<span class="c"># 3) Because of a side effect of a command that stores data on a key that may</span>
<span class="c">#    already exist. For example the RENAME command may delete the old key</span>
<span class="c">#    content when it is replaced with another one. Similarly SUNIONSTORE</span>
<span class="c">#    or SORT with STORE option may delete existing keys. The SET command</span>
<span class="c">#    itself removes any old content of the specified key in order to replace</span>
<span class="c">#    it with the specified string.</span>
<span class="c"># 4) During replication, when a replica performs a full resynchronization with</span>
<span class="c">#    its master, the content of the whole database is removed in order to</span>
<span class="c">#    load the RDB file just transferred.</span>
<span class="c">#</span>
<span class="c"># In all the above cases the default is to delete objects in a blocking way,</span>
<span class="c"># like if DEL was called. However you can configure each case specifically</span>
<span class="c"># in order to instead release memory in a non-blocking way like if UNLINK</span>
<span class="c"># was called, using the following configuration directives.</span>

lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no

<span class="c"># It is also possible, for the case when to replace the user code DEL calls</span>
<span class="c"># with UNLINK calls is not easy, to modify the default behavior of the DEL</span>
<span class="c"># command to act exactly like UNLINK, using the following configuration</span>
<span class="c"># directive:</span>

lazyfree-lazy-user-del no

<span class="c"># FLUSHDB, FLUSHALL, SCRIPT FLUSH and FUNCTION FLUSH support both asynchronous and synchronous</span>
<span class="c"># deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the</span>
<span class="c"># commands. When neither flag is passed, this directive will be used to determine</span>
<span class="c"># if the data should be deleted asynchronously.</span>

lazyfree-lazy-user-flush no

<span class="c">################################ THREADED I/O #################################</span>

<span class="c"># Redis is mostly single threaded, however there are certain threaded</span>
<span class="c"># operations such as UNLINK, slow I/O accesses and other things that are</span>
<span class="c"># performed on side threads.</span>
<span class="c">#</span>
<span class="c"># Now it is also possible to handle Redis clients socket reads and writes</span>
<span class="c"># in different I/O threads. Since especially writing is so slow, normally</span>
<span class="c"># Redis users use pipelining in order to speed up the Redis performances per</span>
<span class="c"># core, and spawn multiple instances in order to scale more. Using I/O</span>
<span class="c"># threads it is possible to easily speedup two times Redis without resorting</span>
<span class="c"># to pipelining nor sharding of the instance.</span>
<span class="c">#</span>
<span class="c"># By default threading is disabled, we suggest enabling it only in machines</span>
<span class="c"># that have at least 4 or more cores, leaving at least one spare core.</span>
<span class="c"># Using more than 8 threads is unlikely to help much. We also recommend using</span>
<span class="c"># threaded I/O only if you actually have performance problems, with Redis</span>
<span class="c"># instances being able to use a quite big percentage of CPU time, otherwise</span>
<span class="c"># there is no point in using this feature.</span>
<span class="c">#</span>
<span class="c"># So for instance if you have a four cores boxes, try to use 2 or 3 I/O</span>
<span class="c"># threads, if you have a 8 cores, try to use 6 threads. In order to</span>
<span class="c"># enable I/O threads use the following configuration directive:</span>
<span class="c">#</span>
<span class="c"># io-threads 4</span>
<span class="c">#</span>
<span class="c"># Setting io-threads to 1 will just use the main thread as usual.</span>
<span class="c"># When I/O threads are enabled, we only use threads for writes, that is</span>
<span class="c"># to thread the write(2) syscall and transfer the client buffers to the</span>
<span class="c"># socket. However it is also possible to enable threading of reads and</span>
<span class="c"># protocol parsing using the following configuration directive, by setting</span>
<span class="c"># it to yes:</span>
<span class="c">#</span>
<span class="c"># io-threads-do-reads no</span>
<span class="c">#</span>
<span class="c"># Usually threading reads doesn't help much.</span>
<span class="c">#</span>
<span class="c"># NOTE 1: This configuration directive cannot be changed at runtime via</span>
<span class="c"># CONFIG SET. Also, this feature currently does not work when SSL is</span>
<span class="c"># enabled.</span>
<span class="c">#</span>
<span class="c"># NOTE 2: If you want to test the Redis speedup using redis-benchmark, make</span>
<span class="c"># sure you also run the benchmark itself in threaded mode, using the</span>
<span class="c"># --threads option to match the number of Redis threads, otherwise you'll not</span>
<span class="c"># be able to notice the improvements.</span>

<span class="c">############################ KERNEL OOM CONTROL ##############################</span>

<span class="c"># On Linux, it is possible to hint the kernel OOM killer on what processes</span>
<span class="c"># should be killed first when out of memory.</span>
<span class="c">#</span>
<span class="c"># Enabling this feature makes Redis actively control the oom_score_adj value</span>
<span class="c"># for all its processes, depending on their role. The default scores will</span>
<span class="c"># attempt to have background child processes killed before all others, and</span>
<span class="c"># replicas killed before masters.</span>
<span class="c">#</span>
<span class="c"># Redis supports these options:</span>
<span class="c">#</span>
<span class="c"># no:       Don't make changes to oom-score-adj (default).</span>
<span class="c"># yes:      Alias to "relative" see below.</span>
<span class="c"># absolute: Values in oom-score-adj-values are written as is to the kernel.</span>
<span class="c"># relative: Values are used relative to the initial value of oom_score_adj when</span>
<span class="c">#           the server starts and are then clamped to a range of -1000 to 1000.</span>
<span class="c">#           Because typically the initial value is 0, they will often match the</span>
<span class="c">#           absolute values.</span>
oom-score-adj no

<span class="c"># When oom-score-adj is used, this directive controls the specific values used</span>
<span class="c"># for master, replica and background child processes. Values range -2000 to</span>
<span class="c"># 2000 (higher means more likely to be killed).</span>
<span class="c">#</span>
<span class="c"># Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities)</span>
<span class="c"># can freely increase their value, but not decrease it below its initial</span>
<span class="c"># settings. This means that setting oom-score-adj to "relative" and setting the</span>
<span class="c"># oom-score-adj-values to positive values will always succeed.</span>
oom-score-adj-values 0 200 800


<span class="c">#################### KERNEL transparent hugepage CONTROL ######################</span>

<span class="c"># Usually the kernel Transparent Huge Pages control is set to "madvise" or</span>
<span class="c"># or "never" by default (/sys/kernel/mm/transparent_hugepage/enabled), in which</span>
<span class="c"># case this config has no effect. On systems in which it is set to "always",</span>
<span class="c"># redis will attempt to disable it specifically for the redis process in order</span>
<span class="c"># to avoid latency problems specifically with fork(2) and CoW.</span>
<span class="c"># If for some reason you prefer to keep it enabled, you can set this config to</span>
<span class="c"># "no" and the kernel global to "always".</span>

disable-thp <span class="nb">yes</span>

<span class="c">############################## APPEND ONLY MODE ###############################</span>

<span class="c"># By default Redis asynchronously dumps the dataset on disk. This mode is</span>
<span class="c"># good enough in many applications, but an issue with the Redis process or</span>
<span class="c"># a power outage may result into a few minutes of writes lost (depending on</span>
<span class="c"># the configured save points).</span>
<span class="c">#</span>
<span class="c"># The Append Only File is an alternative persistence mode that provides</span>
<span class="c"># much better durability. For instance using the default data fsync policy</span>
<span class="c"># (see later in the config file) Redis can lose just one second of writes in a</span>
<span class="c"># dramatic event like a server power outage, or a single write if something</span>
<span class="c"># wrong with the Redis process itself happens, but the operating system is</span>
<span class="c"># still running correctly.</span>
<span class="c">#</span>
<span class="c"># AOF and RDB persistence can be enabled at the same time without problems.</span>
<span class="c"># If the AOF is enabled on startup Redis will load the AOF, that is the file</span>
<span class="c"># with the better durability guarantees.</span>
<span class="c">#</span>
<span class="c"># Please check https://redis.io/topics/persistence for more information.</span>

appendonly no

<span class="c"># The base name of the append only file.</span>
<span class="c">#</span>
<span class="c"># Redis 7 and newer use a set of append-only files to persist the dataset</span>
<span class="c"># and changes applied to it. There are two basic types of files in use:</span>
<span class="c">#</span>
<span class="c"># - Base files, which are a snapshot representing the complete state of the</span>
<span class="c">#   dataset at the time the file was created. Base files can be either in</span>
<span class="c">#   the form of RDB (binary serialized) or AOF (textual commands).</span>
<span class="c"># - Incremental files, which contain additional commands that were applied</span>
<span class="c">#   to the dataset following the previous file.</span>
<span class="c">#</span>
<span class="c"># In addition, manifest files are used to track the files and the order in</span>
<span class="c"># which they were created and should be applied.</span>
<span class="c">#</span>
<span class="c"># Append-only file names are created by Redis following a specific pattern.</span>
<span class="c"># The file name's prefix is based on the 'appendfilename' configuration</span>
<span class="c"># parameter, followed by additional information about the sequence and type.</span>
<span class="c">#</span>
<span class="c"># For example, if appendfilename is set to appendonly.aof, the following file</span>
<span class="c"># names could be derived:</span>
<span class="c">#</span>
<span class="c"># - appendonly.aof.1.base.rdb as a base file.</span>
<span class="c"># - appendonly.aof.1.incr.aof, appendonly.aof.2.incr.aof as incremental files.</span>
<span class="c"># - appendonly.aof.manifest as a manifest file.</span>

appendfilename <span class="s2">"appendonly.aof"</span>

<span class="c"># For convenience, Redis stores all persistent append-only files in a dedicated</span>
<span class="c"># directory. The name of the directory is determined by the appenddirname</span>
<span class="c"># configuration parameter.</span>

appenddirname <span class="s2">"appendonlydir"</span>

<span class="c"># The fsync() call tells the Operating System to actually write data on disk</span>
<span class="c"># instead of waiting for more data in the output buffer. Some OS will really flush</span>
<span class="c"># data on disk, some other OS will just try to do it ASAP.</span>
<span class="c">#</span>
<span class="c"># Redis supports three different modes:</span>
<span class="c">#</span>
<span class="c"># no: don't fsync, just let the OS flush the data when it wants. Faster.</span>
<span class="c"># always: fsync after every write to the append only log. Slow, Safest.</span>
<span class="c"># everysec: fsync only one time every second. Compromise.</span>
<span class="c">#</span>
<span class="c"># The default is "everysec", as that's usually the right compromise between</span>
<span class="c"># speed and data safety. It's up to you to understand if you can relax this to</span>
<span class="c"># "no" that will let the operating system flush the output buffer when</span>
<span class="c"># it wants, for better performances (but if you can live with the idea of</span>
<span class="c"># some data loss consider the default persistence mode that's snapshotting),</span>
<span class="c"># or on the contrary, use "always" that's very slow but a bit safer than</span>
<span class="c"># everysec.</span>
<span class="c">#</span>
<span class="c"># More details please check the following article:</span>
<span class="c"># http://antirez.com/post/redis-persistence-demystified.html</span>
<span class="c">#</span>
<span class="c"># If unsure, use "everysec".</span>

<span class="c"># appendfsync always</span>
appendfsync everysec
<span class="c"># appendfsync no</span>

<span class="c"># When the AOF fsync policy is set to always or everysec, and a background</span>
<span class="c"># saving process (a background save or AOF log background rewriting) is</span>
<span class="c"># performing a lot of I/O against the disk, in some Linux configurations</span>
<span class="c"># Redis may block too long on the fsync() call. Note that there is no fix for</span>
<span class="c"># this currently, as even performing fsync in a different thread will block</span>
<span class="c"># our synchronous write(2) call.</span>
<span class="c">#</span>
<span class="c"># In order to mitigate this problem it's possible to use the following option</span>
<span class="c"># that will prevent fsync() from being called in the main process while a</span>
<span class="c"># BGSAVE or BGREWRITEAOF is in progress.</span>
<span class="c">#</span>
<span class="c"># This means that while another child is saving, the durability of Redis is</span>
<span class="c"># the same as "appendfsync no". In practical terms, this means that it is</span>
<span class="c"># possible to lose up to 30 seconds of log in the worst scenario (with the</span>
<span class="c"># default Linux settings).</span>
<span class="c">#</span>
<span class="c"># If you have latency problems turn this to "yes". Otherwise leave it as</span>
<span class="c"># "no" that is the safest pick from the point of view of durability.</span>

no-appendfsync-on-rewrite no

<span class="c"># Automatic rewrite of the append only file.</span>
<span class="c"># Redis is able to automatically rewrite the log file implicitly calling</span>
<span class="c"># BGREWRITEAOF when the AOF log size grows by the specified percentage.</span>
<span class="c">#</span>
<span class="c"># This is how it works: Redis remembers the size of the AOF file after the</span>
<span class="c"># latest rewrite (if no rewrite has happened since the restart, the size of</span>
<span class="c"># the AOF at startup is used).</span>
<span class="c">#</span>
<span class="c"># This base size is compared to the current size. If the current size is</span>
<span class="c"># bigger than the specified percentage, the rewrite is triggered. Also</span>
<span class="c"># you need to specify a minimal size for the AOF file to be rewritten, this</span>
<span class="c"># is useful to avoid rewriting the AOF file even if the percentage increase</span>
<span class="c"># is reached but it is still pretty small.</span>
<span class="c">#</span>
<span class="c"># Specify a percentage of zero in order to disable the automatic AOF</span>
<span class="c"># rewrite feature.</span>

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

<span class="c"># An AOF file may be found to be truncated at the end during the Redis</span>
<span class="c"># startup process, when the AOF data gets loaded back into memory.</span>
<span class="c"># This may happen when the system where Redis is running</span>
<span class="c"># crashes, especially when an ext4 filesystem is mounted without the</span>
<span class="c"># data=ordered option (however this can't happen when Redis itself</span>
<span class="c"># crashes or aborts but the operating system still works correctly).</span>
<span class="c">#</span>
<span class="c"># Redis can either exit with an error when this happens, or load as much</span>
<span class="c"># data as possible (the default now) and start if the AOF file is found</span>
<span class="c"># to be truncated at the end. The following option controls this behavior.</span>
<span class="c">#</span>
<span class="c"># If aof-load-truncated is set to yes, a truncated AOF file is loaded and</span>
<span class="c"># the Redis server starts emitting a log to inform the user of the event.</span>
<span class="c"># Otherwise if the option is set to no, the server aborts with an error</span>
<span class="c"># and refuses to start. When the option is set to no, the user requires</span>
<span class="c"># to fix the AOF file using the "redis-check-aof" utility before to restart</span>
<span class="c"># the server.</span>
<span class="c">#</span>
<span class="c"># Note that if the AOF file will be found to be corrupted in the middle</span>
<span class="c"># the server will still exit with an error. This option only applies when</span>
<span class="c"># Redis will try to read more data from the AOF file but not enough bytes</span>
<span class="c"># will be found.</span>
aof-load-truncated <span class="nb">yes</span>

<span class="c"># Redis can create append-only base files in either RDB or AOF formats. Using</span>
<span class="c"># the RDB format is always faster and more efficient, and disabling it is only</span>
<span class="c"># supported for backward compatibility purposes.</span>
aof-use-rdb-preamble <span class="nb">yes</span>

<span class="c"># Redis supports recording timestamp annotations in the AOF to support restoring</span>
<span class="c"># the data from a specific point-in-time. However, using this capability changes</span>
<span class="c"># the AOF format in a way that may not be compatible with existing AOF parsers.</span>
aof-timestamp-enabled no

<span class="c">################################ SHUTDOWN #####################################</span>

<span class="c"># Maximum time to wait for replicas when shutting down, in seconds.</span>
<span class="c">#</span>
<span class="c"># During shut down, a grace period allows any lagging replicas to catch up with</span>
<span class="c"># the latest replication offset before the master exists. This period can</span>
<span class="c"># prevent data loss, especially for deployments without configured disk backups.</span>
<span class="c">#</span>
<span class="c"># The 'shutdown-timeout' value is the grace period's duration in seconds. It is</span>
<span class="c"># only applicable when the instance has replicas. To disable the feature, set</span>
<span class="c"># the value to 0.</span>
<span class="c">#</span>
<span class="c"># shutdown-timeout 10</span>

<span class="c"># When Redis receives a SIGINT or SIGTERM, shutdown is initiated and by default</span>
<span class="c"># an RDB snapshot is written to disk in a blocking operation if save points are configured.</span>
<span class="c"># The options used on signaled shutdown can include the following values:</span>
<span class="c"># default:  Saves RDB snapshot only if save points are configured.</span>
<span class="c">#           Waits for lagging replicas to catch up.</span>
<span class="c"># save:     Forces a DB saving operation even if no save points are configured.</span>
<span class="c"># nosave:   Prevents DB saving operation even if one or more save points are configured.</span>
<span class="c"># now:      Skips waiting for lagging replicas.</span>
<span class="c"># force:    Ignores any errors that would normally prevent the server from exiting.</span>
<span class="c">#</span>
<span class="c"># Any combination of values is allowed as long as "save" and "nosave" are not set simultaneously.</span>
<span class="c"># Example: "nosave force now"</span>
<span class="c">#</span>
<span class="c"># shutdown-on-sigint default</span>
<span class="c"># shutdown-on-sigterm default</span>

<span class="c">################ NON-DETERMINISTIC LONG BLOCKING COMMANDS #####################</span>

<span class="c"># Maximum time in milliseconds for EVAL scripts, functions and in some cases</span>
<span class="c"># modules' commands before Redis can start processing or rejecting other clients.</span>
<span class="c">#</span>
<span class="c"># If the maximum execution time is reached Redis will start to reply to most</span>
<span class="c"># commands with a BUSY error.</span>
<span class="c">#</span>
<span class="c"># In this state Redis will only allow a handful of commands to be executed.</span>
<span class="c"># For instance, SCRIPT KILL, FUNCTION KILL, SHUTDOWN NOSAVE and possibly some</span>
<span class="c"># module specific 'allow-busy' commands.</span>
<span class="c">#</span>
<span class="c"># SCRIPT KILL and FUNCTION KILL will only be able to stop a script that did not</span>
<span class="c"># yet call any write commands, so SHUTDOWN NOSAVE may be the only way to stop</span>
<span class="c"># the server in the case a write command was already issued by the script when</span>
<span class="c"># the user doesn't want to wait for the natural termination of the script.</span>
<span class="c">#</span>
<span class="c"># The default is 5 seconds. It is possible to set it to 0 or a negative value</span>
<span class="c"># to disable this mechanism (uninterrupted execution). Note that in the past</span>
<span class="c"># this config had a different name, which is now an alias, so both of these do</span>
<span class="c"># the same:</span>
<span class="c"># lua-time-limit 5000</span>
<span class="c"># busy-reply-threshold 5000</span>

<span class="c">################################ REDIS CLUSTER  ###############################</span>

<span class="c"># Normal Redis instances can't be part of a Redis Cluster; only nodes that are</span>
<span class="c"># started as cluster nodes can. In order to start a Redis instance as a</span>
<span class="c"># cluster node enable the cluster support uncommenting the following:</span>
<span class="c">#</span>
<span class="c"># cluster-enabled yes</span>

<span class="c"># Every cluster node has a cluster configuration file. This file is not</span>
<span class="c"># intended to be edited by hand. It is created and updated by Redis nodes.</span>
<span class="c"># Every Redis Cluster node requires a different cluster configuration file.</span>
<span class="c"># Make sure that instances running in the same system do not have</span>
<span class="c"># overlapping cluster configuration file names.</span>
<span class="c">#</span>
<span class="c"># cluster-config-file nodes-6379.conf</span>

<span class="c"># Cluster node timeout is the amount of milliseconds a node must be unreachable</span>
<span class="c"># for it to be considered in failure state.</span>
<span class="c"># Most other internal time limits are a multiple of the node timeout.</span>
<span class="c">#</span>
<span class="c"># cluster-node-timeout 15000</span>

<span class="c"># The cluster port is the port that the cluster bus will listen for inbound connections on. When set </span>
<span class="c"># to the default value, 0, it will be bound to the command port + 10000. Setting this value requires </span>
<span class="c"># you to specify the cluster bus port when executing cluster meet.</span>
<span class="c"># cluster-port 0</span>

<span class="c"># A replica of a failing master will avoid to start a failover if its data</span>
<span class="c"># looks too old.</span>
<span class="c">#</span>
<span class="c"># There is no simple way for a replica to actually have an exact measure of</span>
<span class="c"># its "data age", so the following two checks are performed:</span>
<span class="c">#</span>
<span class="c"># 1) If there are multiple replicas able to failover, they exchange messages</span>
<span class="c">#    in order to try to give an advantage to the replica with the best</span>
<span class="c">#    replication offset (more data from the master processed).</span>
<span class="c">#    Replicas will try to get their rank by offset, and apply to the start</span>
<span class="c">#    of the failover a delay proportional to their rank.</span>
<span class="c">#</span>
<span class="c"># 2) Every single replica computes the time of the last interaction with</span>
<span class="c">#    its master. This can be the last ping or command received (if the master</span>
<span class="c">#    is still in the "connected" state), or the time that elapsed since the</span>
<span class="c">#    disconnection with the master (if the replication link is currently down).</span>
<span class="c">#    If the last interaction is too old, the replica will not try to failover</span>
<span class="c">#    at all.</span>
<span class="c">#</span>
<span class="c"># The point "2" can be tuned by user. Specifically a replica will not perform</span>
<span class="c"># the failover if, since the last interaction with the master, the time</span>
<span class="c"># elapsed is greater than:</span>
<span class="c">#</span>
<span class="c">#   (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period</span>
<span class="c">#</span>
<span class="c"># So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor</span>
<span class="c"># is 10, and assuming a default repl-ping-replica-period of 10 seconds, the</span>
<span class="c"># replica will not try to failover if it was not able to talk with the master</span>
<span class="c"># for longer than 310 seconds.</span>
<span class="c">#</span>
<span class="c"># A large cluster-replica-validity-factor may allow replicas with too old data to failover</span>
<span class="c"># a master, while a too small value may prevent the cluster from being able to</span>
<span class="c"># elect a replica at all.</span>
<span class="c">#</span>
<span class="c"># For maximum availability, it is possible to set the cluster-replica-validity-factor</span>
<span class="c"># to a value of 0, which means, that replicas will always try to failover the</span>
<span class="c"># master regardless of the last time they interacted with the master.</span>
<span class="c"># (However they'll always try to apply a delay proportional to their</span>
<span class="c"># offset rank).</span>
<span class="c">#</span>
<span class="c"># Zero is the only value able to guarantee that when all the partitions heal</span>
<span class="c"># the cluster will always be able to continue.</span>
<span class="c">#</span>
<span class="c"># cluster-replica-validity-factor 10</span>

<span class="c"># Cluster replicas are able to migrate to orphaned masters, that are masters</span>
<span class="c"># that are left without working replicas. This improves the cluster ability</span>
<span class="c"># to resist to failures as otherwise an orphaned master can't be failed over</span>
<span class="c"># in case of failure if it has no working replicas.</span>
<span class="c">#</span>
<span class="c"># Replicas migrate to orphaned masters only if there are still at least a</span>
<span class="c"># given number of other working replicas for their old master. This number</span>
<span class="c"># is the "migration barrier". A migration barrier of 1 means that a replica</span>
<span class="c"># will migrate only if there is at least 1 other working replica for its master</span>
<span class="c"># and so forth. It usually reflects the number of replicas you want for every</span>
<span class="c"># master in your cluster.</span>
<span class="c">#</span>
<span class="c"># Default is 1 (replicas migrate only if their masters remain with at least</span>
<span class="c"># one replica). To disable migration just set it to a very large value or</span>
<span class="c"># set cluster-allow-replica-migration to 'no'.</span>
<span class="c"># A value of 0 can be set but is useful only for debugging and dangerous</span>
<span class="c"># in production.</span>
<span class="c">#</span>
<span class="c"># cluster-migration-barrier 1</span>

<span class="c"># Turning off this option allows to use less automatic cluster configuration.</span>
<span class="c"># It both disables migration to orphaned masters and migration from masters</span>
<span class="c"># that became empty.</span>
<span class="c">#</span>
<span class="c"># Default is 'yes' (allow automatic migrations).</span>
<span class="c">#</span>
<span class="c"># cluster-allow-replica-migration yes</span>

<span class="c"># By default Redis Cluster nodes stop accepting queries if they detect there</span>
<span class="c"># is at least a hash slot uncovered (no available node is serving it).</span>
<span class="c"># This way if the cluster is partially down (for example a range of hash slots</span>
<span class="c"># are no longer covered) all the cluster becomes, eventually, unavailable.</span>
<span class="c"># It automatically returns available as soon as all the slots are covered again.</span>
<span class="c">#</span>
<span class="c"># However sometimes you want the subset of the cluster which is working,</span>
<span class="c"># to continue to accept queries for the part of the key space that is still</span>
<span class="c"># covered. In order to do so, just set the cluster-require-full-coverage</span>
<span class="c"># option to no.</span>
<span class="c">#</span>
<span class="c"># cluster-require-full-coverage yes</span>

<span class="c"># This option, when set to yes, prevents replicas from trying to failover its</span>
<span class="c"># master during master failures. However the replica can still perform a</span>
<span class="c"># manual failover, if forced to do so.</span>
<span class="c">#</span>
<span class="c"># This is useful in different scenarios, especially in the case of multiple</span>
<span class="c"># data center operations, where we want one side to never be promoted if not</span>
<span class="c"># in the case of a total DC failure.</span>
<span class="c">#</span>
<span class="c"># cluster-replica-no-failover no</span>

<span class="c"># This option, when set to yes, allows nodes to serve read traffic while the</span>
<span class="c"># cluster is in a down state, as long as it believes it owns the slots.</span>
<span class="c">#</span>
<span class="c"># This is useful for two cases.  The first case is for when an application</span>
<span class="c"># doesn't require consistency of data during node failures or network partitions.</span>
<span class="c"># One example of this is a cache, where as long as the node has the data it</span>
<span class="c"># should be able to serve it.</span>
<span class="c">#</span>
<span class="c"># The second use case is for configurations that don't meet the recommended</span>
<span class="c"># three shards but want to enable cluster mode and scale later. A</span>
<span class="c"># master outage in a 1 or 2 shard configuration causes a read/write outage to the</span>
<span class="c"># entire cluster without this option set, with it set there is only a write outage.</span>
<span class="c"># Without a quorum of masters, slot ownership will not change automatically.</span>
<span class="c">#</span>
<span class="c"># cluster-allow-reads-when-down no</span>

<span class="c"># This option, when set to yes, allows nodes to serve pubsub shard traffic while</span>
<span class="c"># the cluster is in a down state, as long as it believes it owns the slots.</span>
<span class="c">#</span>
<span class="c"># This is useful if the application would like to use the pubsub feature even when</span>
<span class="c"># the cluster global stable state is not OK. If the application wants to make sure only</span>
<span class="c"># one shard is serving a given channel, this feature should be kept as yes.</span>
<span class="c">#</span>
<span class="c"># cluster-allow-pubsubshard-when-down yes</span>

<span class="c"># Cluster link send buffer limit is the limit on the memory usage of an individual</span>
<span class="c"># cluster bus link's send buffer in bytes. Cluster links would be freed if they exceed</span>
<span class="c"># this limit. This is to primarily prevent send buffers from growing unbounded on links</span>
<span class="c"># toward slow peers (E.g. PubSub messages being piled up).</span>
<span class="c"># This limit is disabled by default. Enable this limit when 'mem_cluster_links' INFO field</span>
<span class="c"># and/or 'send-buffer-allocated' entries in the 'CLUSTER LINKS` command output continuously increase.</span>
<span class="c"># Minimum limit of 1gb is recommended so that cluster link buffer can fit in at least a single</span>
<span class="c"># PubSub message by default. (client-query-buffer-limit default value is 1gb)</span>
<span class="c">#</span>
<span class="c"># cluster-link-sendbuf-limit 0</span>
 
<span class="c"># Clusters can configure their announced hostname using this config. This is a common use case for </span>
<span class="c"># applications that need to use TLS Server Name Indication (SNI) or dealing with DNS based</span>
<span class="c"># routing. By default this value is only shown as additional metadata in the CLUSTER SLOTS</span>
<span class="c"># command, but can be changed using 'cluster-preferred-endpoint-type' config. This value is </span>
<span class="c"># communicated along the clusterbus to all nodes, setting it to an empty string will remove </span>
<span class="c"># the hostname and also propagate the removal.</span>
<span class="c">#</span>
<span class="c"># cluster-announce-hostname ""</span>

<span class="c"># Clusters can advertise how clients should connect to them using either their IP address,</span>
<span class="c"># a user defined hostname, or by declaring they have no endpoint. Which endpoint is</span>
<span class="c"># shown as the preferred endpoint is set by using the cluster-preferred-endpoint-type</span>
<span class="c"># config with values 'ip', 'hostname', or 'unknown-endpoint'. This value controls how</span>
<span class="c"># the endpoint returned for MOVED/ASKING requests as well as the first field of CLUSTER SLOTS. </span>
<span class="c"># If the preferred endpoint type is set to hostname, but no announced hostname is set, a '?' </span>
<span class="c"># will be returned instead.</span>
<span class="c">#</span>
<span class="c"># When a cluster advertises itself as having an unknown endpoint, it's indicating that</span>
<span class="c"># the server doesn't know how clients can reach the cluster. This can happen in certain </span>
<span class="c"># networking situations where there are multiple possible routes to the node, and the </span>
<span class="c"># server doesn't know which one the client took. In this case, the server is expecting</span>
<span class="c"># the client to reach out on the same endpoint it used for making the last request, but use</span>
<span class="c"># the port provided in the response.</span>
<span class="c">#</span>
<span class="c"># cluster-preferred-endpoint-type ip</span>

<span class="c"># In order to setup your cluster make sure to read the documentation</span>
<span class="c"># available at https://redis.io web site.</span>

<span class="c">########################## CLUSTER DOCKER/NAT support  ########################</span>

<span class="c"># In certain deployments, Redis Cluster nodes address discovery fails, because</span>
<span class="c"># addresses are NAT-ted or because ports are forwarded (the typical case is</span>
<span class="c"># Docker and other containers).</span>
<span class="c">#</span>
<span class="c"># In order to make Redis Cluster working in such environments, a static</span>
<span class="c"># configuration where each node knows its public address is needed. The</span>
<span class="c"># following four options are used for this scope, and are:</span>
<span class="c">#</span>
<span class="c"># * cluster-announce-ip</span>
<span class="c"># * cluster-announce-port</span>
<span class="c"># * cluster-announce-tls-port</span>
<span class="c"># * cluster-announce-bus-port</span>
<span class="c">#</span>
<span class="c"># Each instructs the node about its address, client ports (for connections</span>
<span class="c"># without and with TLS) and cluster message bus port. The information is then</span>
<span class="c"># published in the header of the bus packets so that other nodes will be able to</span>
<span class="c"># correctly map the address of the node publishing the information.</span>
<span class="c">#</span>
<span class="c"># If tls-cluster is set to yes and cluster-announce-tls-port is omitted or set</span>
<span class="c"># to zero, then cluster-announce-port refers to the TLS port. Note also that</span>
<span class="c"># cluster-announce-tls-port has no effect if tls-cluster is set to no.</span>
<span class="c">#</span>
<span class="c"># If the above options are not used, the normal Redis Cluster auto-detection</span>
<span class="c"># will be used instead.</span>
<span class="c">#</span>
<span class="c"># Note that when remapped, the bus port may not be at the fixed offset of</span>
<span class="c"># clients port + 10000, so you can specify any port and bus-port depending</span>
<span class="c"># on how they get remapped. If the bus-port is not set, a fixed offset of</span>
<span class="c"># 10000 will be used as usual.</span>
<span class="c">#</span>
<span class="c"># Example:</span>
<span class="c">#</span>
<span class="c"># cluster-announce-ip 10.1.1.5</span>
<span class="c"># cluster-announce-tls-port 6379</span>
<span class="c"># cluster-announce-port 0</span>
<span class="c"># cluster-announce-bus-port 6380</span>

<span class="c">################################## SLOW LOG ###################################</span>

<span class="c"># The Redis Slow Log is a system to log queries that exceeded a specified</span>
<span class="c"># execution time. The execution time does not include the I/O operations</span>
<span class="c"># like talking with the client, sending the reply and so forth,</span>
<span class="c"># but just the time needed to actually execute the command (this is the only</span>
<span class="c"># stage of command execution where the thread is blocked and can not serve</span>
<span class="c"># other requests in the meantime).</span>
<span class="c">#</span>
<span class="c"># You can configure the slow log with two parameters: one tells Redis</span>
<span class="c"># what is the execution time, in microseconds, to exceed in order for the</span>
<span class="c"># command to get logged, and the other parameter is the length of the</span>
<span class="c"># slow log. When a new command is logged the oldest one is removed from the</span>
<span class="c"># queue of logged commands.</span>

<span class="c"># The following time is expressed in microseconds, so 1000000 is equivalent</span>
<span class="c"># to one second. Note that a negative number disables the slow log, while</span>
<span class="c"># a value of zero forces the logging of every command.</span>
slowlog-log-slower-than 10000

<span class="c"># There is no limit to this length. Just be aware that it will consume memory.</span>
<span class="c"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span>
slowlog-max-len 128

<span class="c">################################ LATENCY MONITOR ##############################</span>

<span class="c"># The Redis latency monitoring subsystem samples different operations</span>
<span class="c"># at runtime in order to collect data related to possible sources of</span>
<span class="c"># latency of a Redis instance.</span>
<span class="c">#</span>
<span class="c"># Via the LATENCY command this information is available to the user that can</span>
<span class="c"># print graphs and obtain reports.</span>
<span class="c">#</span>
<span class="c"># The system only logs operations that were performed in a time equal or</span>
<span class="c"># greater than the amount of milliseconds specified via the</span>
<span class="c"># latency-monitor-threshold configuration directive. When its value is set</span>
<span class="c"># to zero, the latency monitor is turned off.</span>
<span class="c">#</span>
<span class="c"># By default latency monitoring is disabled since it is mostly not needed</span>
<span class="c"># if you don't have latency issues, and collecting data has a performance</span>
<span class="c"># impact, that while very small, can be measured under big load. Latency</span>
<span class="c"># monitoring can easily be enabled at runtime using the command</span>
<span class="c"># "CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;" if needed.</span>
latency-monitor-threshold 0

<span class="c">################################ LATENCY TRACKING ##############################</span>

<span class="c"># The Redis extended latency monitoring tracks the per command latencies and enables</span>
<span class="c"># exporting the percentile distribution via the INFO latencystats command,</span>
<span class="c"># and cumulative latency distributions (histograms) via the LATENCY command.</span>
<span class="c">#</span>
<span class="c"># By default, the extended latency monitoring is enabled since the overhead</span>
<span class="c"># of keeping track of the command latency is very small.</span>
<span class="c"># latency-tracking yes</span>

<span class="c"># By default the exported latency percentiles via the INFO latencystats command</span>
<span class="c"># are the p50, p99, and p999.</span>
<span class="c"># latency-tracking-info-percentiles 50 99 99.9</span>

<span class="c">############################# EVENT NOTIFICATION ##############################</span>

<span class="c"># Redis can notify Pub/Sub clients about events happening in the key space.</span>
<span class="c"># This feature is documented at https://redis.io/topics/notifications</span>
<span class="c">#</span>
<span class="c"># For instance if keyspace events notification is enabled, and a client</span>
<span class="c"># performs a DEL operation on key "foo" stored in the Database 0, two</span>
<span class="c"># messages will be published via Pub/Sub:</span>
<span class="c">#</span>
<span class="c"># PUBLISH __keyspace@0__:foo del</span>
<span class="c"># PUBLISH __keyevent@0__:del foo</span>
<span class="c">#</span>
<span class="c"># It is possible to select the events that Redis will notify among a set</span>
<span class="c"># of classes. Every class is identified by a single character:</span>
<span class="c">#</span>
<span class="c">#  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.</span>
<span class="c">#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.</span>
<span class="c">#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...</span>
<span class="c">#  $     String commands</span>
<span class="c">#  l     List commands</span>
<span class="c">#  s     Set commands</span>
<span class="c">#  h     Hash commands</span>
<span class="c">#  z     Sorted set commands</span>
<span class="c">#  x     Expired events (events generated every time a key expires)</span>
<span class="c">#  e     Evicted events (events generated when a key is evicted for maxmemory)</span>
<span class="c">#  n     New key events (Note: not included in the 'A' class)</span>
<span class="c">#  t     Stream commands</span>
<span class="c">#  d     Module key type events</span>
<span class="c">#  m     Key-miss events (Note: It is not included in the 'A' class)</span>
<span class="c">#  A     Alias for g$lshzxetd, so that the "AKE" string means all the events</span>
<span class="c">#        (Except key-miss events which are excluded from 'A' due to their</span>
<span class="c">#         unique nature).</span>
<span class="c">#</span>
<span class="c">#  The "notify-keyspace-events" takes as argument a string that is composed</span>
<span class="c">#  of zero or multiple characters. The empty string means that notifications</span>
<span class="c">#  are disabled.</span>
<span class="c">#</span>
<span class="c">#  Example: to enable list and generic events, from the point of view of the</span>
<span class="c">#           event name, use:</span>
<span class="c">#</span>
<span class="c">#  notify-keyspace-events Elg</span>
<span class="c">#</span>
<span class="c">#  Example 2: to get the stream of the expired keys subscribing to channel</span>
<span class="c">#             name __keyevent@0__:expired use:</span>
<span class="c">#</span>
<span class="c">#  notify-keyspace-events Ex</span>
<span class="c">#</span>
<span class="c">#  By default all notifications are disabled because most users don't need</span>
<span class="c">#  this feature and the feature has some overhead. Note that if you don't</span>
<span class="c">#  specify at least one of K or E, no events will be delivered.</span>
notify-keyspace-events <span class="s2">""</span>

<span class="c">############################### ADVANCED CONFIG ###############################</span>

<span class="c"># Hashes are encoded using a memory efficient data structure when they have a</span>
<span class="c"># small number of entries, and the biggest entry does not exceed a given</span>
<span class="c"># threshold. These thresholds can be configured using the following directives.</span>
hash-max-listpack-entries 512
hash-max-listpack-value 64

<span class="c"># Lists are also encoded in a special way to save a lot of space.</span>
<span class="c"># The number of entries allowed per internal list node can be specified</span>
<span class="c"># as a fixed maximum size or a maximum number of elements.</span>
<span class="c"># For a fixed maximum size, use -5 through -1, meaning:</span>
<span class="c"># -5: max size: 64 Kb  &lt;-- not recommended for normal workloads</span>
<span class="c"># -4: max size: 32 Kb  &lt;-- not recommended</span>
<span class="c"># -3: max size: 16 Kb  &lt;-- probably not recommended</span>
<span class="c"># -2: max size: 8 Kb   &lt;-- good</span>
<span class="c"># -1: max size: 4 Kb   &lt;-- good</span>
<span class="c"># Positive numbers mean store up to _exactly_ that number of elements</span>
<span class="c"># per list node.</span>
<span class="c"># The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),</span>
<span class="c"># but if your use case is unique, adjust the settings as necessary.</span>
list-max-listpack-size <span class="nt">-2</span>

<span class="c"># Lists may also be compressed.</span>
<span class="c"># Compress depth is the number of quicklist ziplist nodes from *each* side of</span>
<span class="c"># the list to *exclude* from compression.  The head and tail of the list</span>
<span class="c"># are always uncompressed for fast push/pop operations.  Settings are:</span>
<span class="c"># 0: disable all list compression</span>
<span class="c"># 1: depth 1 means "don't start compressing until after 1 node into the list,</span>
<span class="c">#    going from either the head or tail"</span>
<span class="c">#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]</span>
<span class="c">#    [head], [tail] will always be uncompressed; inner nodes will compress.</span>
<span class="c"># 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]</span>
<span class="c">#    2 here means: don't compress head or head-&gt;next or tail-&gt;prev or tail,</span>
<span class="c">#    but compress all nodes between them.</span>
<span class="c"># 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]</span>
<span class="c"># etc.</span>
list-compress-depth 0

<span class="c"># Sets have a special encoding when a set is composed</span>
<span class="c"># of just strings that happen to be integers in radix 10 in the range</span>
<span class="c"># of 64 bit signed integers.</span>
<span class="c"># The following configuration setting sets the limit in the size of the</span>
<span class="c"># set in order to use this special memory saving encoding.</span>
set-max-intset-entries 512

<span class="c"># Sets containing non-integer values are also encoded using a memory efficient</span>
<span class="c"># data structure when they have a small number of entries, and the biggest entry</span>
<span class="c"># does not exceed a given threshold. These thresholds can be configured using</span>
<span class="c"># the following directives.</span>
set-max-listpack-entries 128
set-max-listpack-value 64

<span class="c"># Similarly to hashes and lists, sorted sets are also specially encoded in</span>
<span class="c"># order to save a lot of space. This encoding is only used when the length and</span>
<span class="c"># elements of a sorted set are below the following limits:</span>
zset-max-listpack-entries 128
zset-max-listpack-value 64

<span class="c"># HyperLogLog sparse representation bytes limit. The limit includes the</span>
<span class="c"># 16 bytes header. When a HyperLogLog using the sparse representation crosses</span>
<span class="c"># this limit, it is converted into the dense representation.</span>
<span class="c">#</span>
<span class="c"># A value greater than 16000 is totally useless, since at that point the</span>
<span class="c"># dense representation is more memory efficient.</span>
<span class="c">#</span>
<span class="c"># The suggested value is ~ 3000 in order to have the benefits of</span>
<span class="c"># the space efficient encoding without slowing down too much PFADD,</span>
<span class="c"># which is O(N) with the sparse encoding. The value can be raised to</span>
<span class="c"># ~ 10000 when CPU is not a concern, but space is, and the data set is</span>
<span class="c"># composed of many HyperLogLogs with cardinality in the 0 - 15000 range.</span>
hll-sparse-max-bytes 3000

<span class="c"># Streams macro node max size / items. The stream data structure is a radix</span>
<span class="c"># tree of big nodes that encode multiple items inside. Using this configuration</span>
<span class="c"># it is possible to configure how big a single node can be in bytes, and the</span>
<span class="c"># maximum number of items it may contain before switching to a new node when</span>
<span class="c"># appending new stream entries. If any of the following settings are set to</span>
<span class="c"># zero, the limit is ignored, so for instance it is possible to set just a</span>
<span class="c"># max entries limit by setting max-bytes to 0 and max-entries to the desired</span>
<span class="c"># value.</span>
stream-node-max-bytes 4096
stream-node-max-entries 100

<span class="c"># Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in</span>
<span class="c"># order to help rehashing the main Redis hash table (the one mapping top-level</span>
<span class="c"># keys to values). The hash table implementation Redis uses (see dict.c)</span>
<span class="c"># performs a lazy rehashing: the more operation you run into a hash table</span>
<span class="c"># that is rehashing, the more rehashing "steps" are performed, so if the</span>
<span class="c"># server is idle the rehashing is never complete and some more memory is used</span>
<span class="c"># by the hash table.</span>
<span class="c">#</span>
<span class="c"># The default is to use this millisecond 10 times every second in order to</span>
<span class="c"># actively rehash the main dictionaries, freeing memory when possible.</span>
<span class="c">#</span>
<span class="c"># If unsure:</span>
<span class="c"># use "activerehashing no" if you have hard latency requirements and it is</span>
<span class="c"># not a good thing in your environment that Redis can reply from time to time</span>
<span class="c"># to queries with 2 milliseconds delay.</span>
<span class="c">#</span>
<span class="c"># use "activerehashing yes" if you don't have such hard requirements but</span>
<span class="c"># want to free memory asap when possible.</span>
activerehashing <span class="nb">yes</span>

<span class="c"># The client output buffer limits can be used to force disconnection of clients</span>
<span class="c"># that are not reading data from the server fast enough for some reason (a</span>
<span class="c"># common reason is that a Pub/Sub client can't consume messages as fast as the</span>
<span class="c"># publisher can produce them).</span>
<span class="c">#</span>
<span class="c"># The limit can be set differently for the three different classes of clients:</span>
<span class="c">#</span>
<span class="c"># normal -&gt; normal clients including MONITOR clients</span>
<span class="c"># replica -&gt; replica clients</span>
<span class="c"># pubsub -&gt; clients subscribed to at least one pubsub channel or pattern</span>
<span class="c">#</span>
<span class="c"># The syntax of every client-output-buffer-limit directive is the following:</span>
<span class="c">#</span>
<span class="c"># client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;</span>
<span class="c">#</span>
<span class="c"># A client is immediately disconnected once the hard limit is reached, or if</span>
<span class="c"># the soft limit is reached and remains reached for the specified number of</span>
<span class="c"># seconds (continuously).</span>
<span class="c"># So for instance if the hard limit is 32 megabytes and the soft limit is</span>
<span class="c"># 16 megabytes / 10 seconds, the client will get disconnected immediately</span>
<span class="c"># if the size of the output buffers reach 32 megabytes, but will also get</span>
<span class="c"># disconnected if the client reaches 16 megabytes and continuously overcomes</span>
<span class="c"># the limit for 10 seconds.</span>
<span class="c">#</span>
<span class="c"># By default normal clients are not limited because they don't receive data</span>
<span class="c"># without asking (in a push way), but just after a request, so only</span>
<span class="c"># asynchronous clients may create a scenario where data is requested faster</span>
<span class="c"># than it can read.</span>
<span class="c">#</span>
<span class="c"># Instead there is a default limit for pubsub and replica clients, since</span>
<span class="c"># subscribers and replicas receive data in a push fashion.</span>
<span class="c">#</span>
<span class="c"># Note that it doesn't make sense to set the replica clients output buffer</span>
<span class="c"># limit lower than the repl-backlog-size config (partial sync will succeed</span>
<span class="c"># and then replica will get disconnected).</span>
<span class="c"># Such a configuration is ignored (the size of repl-backlog-size will be used).</span>
<span class="c"># This doesn't have memory consumption implications since the replica client</span>
<span class="c"># will share the backlog buffers memory.</span>
<span class="c">#</span>
<span class="c"># Both the hard or the soft limit can be disabled by setting them to zero.</span>
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

<span class="c"># Client query buffers accumulate new commands. They are limited to a fixed</span>
<span class="c"># amount by default in order to avoid that a protocol desynchronization (for</span>
<span class="c"># instance due to a bug in the client) will lead to unbound memory usage in</span>
<span class="c"># the query buffer. However you can configure it here if you have very special</span>
<span class="c"># needs, such us huge multi/exec requests or alike.</span>
<span class="c">#</span>
<span class="c"># client-query-buffer-limit 1gb</span>

<span class="c"># In some scenarios client connections can hog up memory leading to OOM</span>
<span class="c"># errors or data eviction. To avoid this we can cap the accumulated memory</span>
<span class="c"># used by all client connections (all pubsub and normal clients). Once we</span>
<span class="c"># reach that limit connections will be dropped by the server freeing up</span>
<span class="c"># memory. The server will attempt to drop the connections using the most </span>
<span class="c"># memory first. We call this mechanism "client eviction".</span>
<span class="c">#</span>
<span class="c"># Client eviction is configured using the maxmemory-clients setting as follows:</span>
<span class="c"># 0 - client eviction is disabled (default)</span>
<span class="c">#</span>
<span class="c"># A memory value can be used for the client eviction threshold,</span>
<span class="c"># for example:</span>
<span class="c"># maxmemory-clients 1g</span>
<span class="c">#</span>
<span class="c"># A percentage value (between 1% and 100%) means the client eviction threshold</span>
<span class="c"># is based on a percentage of the maxmemory setting. For example to set client</span>
<span class="c"># eviction at 5% of maxmemory:</span>
<span class="c"># maxmemory-clients 5%</span>

<span class="c"># In the Redis protocol, bulk requests, that are, elements representing single</span>
<span class="c"># strings, are normally limited to 512 mb. However you can change this limit</span>
<span class="c"># here, but must be 1mb or greater</span>
<span class="c">#</span>
<span class="c"># proto-max-bulk-len 512mb</span>

<span class="c"># Redis calls an internal function to perform many background tasks, like</span>
<span class="c"># closing connections of clients in timeout, purging expired keys that are</span>
<span class="c"># never requested, and so forth.</span>
<span class="c">#</span>
<span class="c"># Not all tasks are performed with the same frequency, but Redis checks for</span>
<span class="c"># tasks to perform according to the specified "hz" value.</span>
<span class="c">#</span>
<span class="c"># By default "hz" is set to 10. Raising the value will use more CPU when</span>
<span class="c"># Redis is idle, but at the same time will make Redis more responsive when</span>
<span class="c"># there are many keys expiring at the same time, and timeouts may be</span>
<span class="c"># handled with more precision.</span>
<span class="c">#</span>
<span class="c"># The range is between 1 and 500, however a value over 100 is usually not</span>
<span class="c"># a good idea. Most users should use the default of 10 and raise this up to</span>
<span class="c"># 100 only in environments where very low latency is required.</span>
hz 10

<span class="c"># Normally it is useful to have an HZ value which is proportional to the</span>
<span class="c"># number of clients connected. This is useful in order, for instance, to</span>
<span class="c"># avoid too many clients are processed for each background task invocation</span>
<span class="c"># in order to avoid latency spikes.</span>
<span class="c">#</span>
<span class="c"># Since the default HZ value by default is conservatively set to 10, Redis</span>
<span class="c"># offers, and enables by default, the ability to use an adaptive HZ value</span>
<span class="c"># which will temporarily raise when there are many connected clients.</span>
<span class="c">#</span>
<span class="c"># When dynamic HZ is enabled, the actual configured HZ will be used</span>
<span class="c"># as a baseline, but multiples of the configured HZ value will be actually</span>
<span class="c"># used as needed once more clients are connected. In this way an idle</span>
<span class="c"># instance will use very little CPU time while a busy instance will be</span>
<span class="c"># more responsive.</span>
dynamic-hz <span class="nb">yes</span>

<span class="c"># When a child rewrites the AOF file, if the following option is enabled</span>
<span class="c"># the file will be fsync-ed every 4 MB of data generated. This is useful</span>
<span class="c"># in order to commit the file to the disk more incrementally and avoid</span>
<span class="c"># big latency spikes.</span>
aof-rewrite-incremental-fsync <span class="nb">yes</span>

<span class="c"># When redis saves RDB file, if the following option is enabled</span>
<span class="c"># the file will be fsync-ed every 4 MB of data generated. This is useful</span>
<span class="c"># in order to commit the file to the disk more incrementally and avoid</span>
<span class="c"># big latency spikes.</span>
rdb-save-incremental-fsync <span class="nb">yes</span>

<span class="c"># Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good</span>
<span class="c"># idea to start with the default settings and only change them after investigating</span>
<span class="c"># how to improve the performances and how the keys LFU change over time, which</span>
<span class="c"># is possible to inspect via the OBJECT FREQ command.</span>
<span class="c">#</span>
<span class="c"># There are two tunable parameters in the Redis LFU implementation: the</span>
<span class="c"># counter logarithm factor and the counter decay time. It is important to</span>
<span class="c"># understand what the two parameters mean before changing them.</span>
<span class="c">#</span>
<span class="c"># The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis</span>
<span class="c"># uses a probabilistic increment with logarithmic behavior. Given the value</span>
<span class="c"># of the old counter, when a key is accessed, the counter is incremented in</span>
<span class="c"># this way:</span>
<span class="c">#</span>
<span class="c"># 1. A random number R between 0 and 1 is extracted.</span>
<span class="c"># 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).</span>
<span class="c"># 3. The counter is incremented only if R &lt; P.</span>
<span class="c">#</span>
<span class="c"># The default lfu-log-factor is 10. This is a table of how the frequency</span>
<span class="c"># counter changes with a different number of accesses with different</span>
<span class="c"># logarithmic factors:</span>
<span class="c">#</span>
<span class="c"># +--------+------------+------------+------------+------------+------------+</span>
<span class="c"># | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |</span>
<span class="c"># +--------+------------+------------+------------+------------+------------+</span>
<span class="c"># | 0      | 104        | 255        | 255        | 255        | 255        |</span>
<span class="c"># +--------+------------+------------+------------+------------+------------+</span>
<span class="c"># | 1      | 18         | 49         | 255        | 255        | 255        |</span>
<span class="c"># +--------+------------+------------+------------+------------+------------+</span>
<span class="c"># | 10     | 10         | 18         | 142        | 255        | 255        |</span>
<span class="c"># +--------+------------+------------+------------+------------+------------+</span>
<span class="c"># | 100    | 8          | 11         | 49         | 143        | 255        |</span>
<span class="c"># +--------+------------+------------+------------+------------+------------+</span>
<span class="c">#</span>
<span class="c"># NOTE: The above table was obtained by running the following commands:</span>
<span class="c">#</span>
<span class="c">#   redis-benchmark -n 1000000 incr foo</span>
<span class="c">#   redis-cli object freq foo</span>
<span class="c">#</span>
<span class="c"># NOTE 2: The counter initial value is 5 in order to give new objects a chance</span>
<span class="c"># to accumulate hits.</span>
<span class="c">#</span>
<span class="c"># The counter decay time is the time, in minutes, that must elapse in order</span>
<span class="c"># for the key counter to be decremented.</span>
<span class="c">#</span>
<span class="c"># The default value for the lfu-decay-time is 1. A special value of 0 means we</span>
<span class="c"># will never decay the counter.</span>
<span class="c">#</span>
<span class="c"># lfu-log-factor 10</span>
<span class="c"># lfu-decay-time 1</span>

<span class="c">########################### ACTIVE DEFRAGMENTATION #######################</span>
<span class="c">#</span>
<span class="c"># What is active defragmentation?</span>
<span class="c"># -------------------------------</span>
<span class="c">#</span>
<span class="c"># Active (online) defragmentation allows a Redis server to compact the</span>
<span class="c"># spaces left between small allocations and deallocations of data in memory,</span>
<span class="c"># thus allowing to reclaim back memory.</span>
<span class="c">#</span>
<span class="c"># Fragmentation is a natural process that happens with every allocator (but</span>
<span class="c"># less so with Jemalloc, fortunately) and certain workloads. Normally a server</span>
<span class="c"># restart is needed in order to lower the fragmentation, or at least to flush</span>
<span class="c"># away all the data and create it again. However thanks to this feature</span>
<span class="c"># implemented by Oran Agra for Redis 4.0 this process can happen at runtime</span>
<span class="c"># in a "hot" way, while the server is running.</span>
<span class="c">#</span>
<span class="c"># Basically when the fragmentation is over a certain level (see the</span>
<span class="c"># configuration options below) Redis will start to create new copies of the</span>
<span class="c"># values in contiguous memory regions by exploiting certain specific Jemalloc</span>
<span class="c"># features (in order to understand if an allocation is causing fragmentation</span>
<span class="c"># and to allocate it in a better place), and at the same time, will release the</span>
<span class="c"># old copies of the data. This process, repeated incrementally for all the keys</span>
<span class="c"># will cause the fragmentation to drop back to normal values.</span>
<span class="c">#</span>
<span class="c"># Important things to understand:</span>
<span class="c">#</span>
<span class="c"># 1. This feature is disabled by default, and only works if you compiled Redis</span>
<span class="c">#    to use the copy of Jemalloc we ship with the source code of Redis.</span>
<span class="c">#    This is the default with Linux builds.</span>
<span class="c">#</span>
<span class="c"># 2. You never need to enable this feature if you don't have fragmentation</span>
<span class="c">#    issues.</span>
<span class="c">#</span>
<span class="c"># 3. Once you experience fragmentation, you can enable this feature when</span>
<span class="c">#    needed with the command "CONFIG SET activedefrag yes".</span>
<span class="c">#</span>
<span class="c"># The configuration parameters are able to fine tune the behavior of the</span>
<span class="c"># defragmentation process. If you are not sure about what they mean it is</span>
<span class="c"># a good idea to leave the defaults untouched.</span>

<span class="c"># Active defragmentation is disabled by default</span>
<span class="c"># activedefrag no</span>

<span class="c"># Minimum amount of fragmentation waste to start active defrag</span>
<span class="c"># active-defrag-ignore-bytes 100mb</span>

<span class="c"># Minimum percentage of fragmentation to start active defrag</span>
<span class="c"># active-defrag-threshold-lower 10</span>

<span class="c"># Maximum percentage of fragmentation at which we use maximum effort</span>
<span class="c"># active-defrag-threshold-upper 100</span>

<span class="c"># Minimal effort for defrag in CPU percentage, to be used when the lower</span>
<span class="c"># threshold is reached</span>
<span class="c"># active-defrag-cycle-min 1</span>

<span class="c"># Maximal effort for defrag in CPU percentage, to be used when the upper</span>
<span class="c"># threshold is reached</span>
<span class="c"># active-defrag-cycle-max 25</span>

<span class="c"># Maximum number of set/hash/zset/list fields that will be processed from</span>
<span class="c"># the main dictionary scan</span>
<span class="c"># active-defrag-max-scan-fields 1000</span>

<span class="c"># Jemalloc background thread for purging will be enabled by default</span>
jemalloc-bg-thread <span class="nb">yes</span>

<span class="c"># It is possible to pin different threads and processes of Redis to specific</span>
<span class="c"># CPUs in your system, in order to maximize the performances of the server.</span>
<span class="c"># This is useful both in order to pin different Redis threads in different</span>
<span class="c"># CPUs, but also in order to make sure that multiple Redis instances running</span>
<span class="c"># in the same host will be pinned to different CPUs.</span>
<span class="c">#</span>
<span class="c"># Normally you can do this using the "taskset" command, however it is also</span>
<span class="c"># possible to this via Redis configuration directly, both in Linux and FreeBSD.</span>
<span class="c">#</span>
<span class="c"># You can pin the server/IO threads, bio threads, aof rewrite child process, and</span>
<span class="c"># the bgsave child process. The syntax to specify the cpu list is the same as</span>
<span class="c"># the taskset command:</span>
<span class="c">#</span>
<span class="c"># Set redis server/io threads to cpu affinity 0,2,4,6:</span>
<span class="c"># server_cpulist 0-7:2</span>
<span class="c">#</span>
<span class="c"># Set bio threads to cpu affinity 1,3:</span>
<span class="c"># bio_cpulist 1,3</span>
<span class="c">#</span>
<span class="c"># Set aof rewrite child process to cpu affinity 8,9,10,11:</span>
<span class="c"># aof_rewrite_cpulist 8-11</span>
<span class="c">#</span>
<span class="c"># Set bgsave child process to cpu affinity 1,10,11</span>
<span class="c"># bgsave_cpulist 1,10-11</span>

<span class="c"># In some cases redis will emit warnings and even refuse to start if it detects</span>
<span class="c"># that the system is in bad state, it is possible to suppress these warnings</span>
<span class="c"># by setting the following config which takes a space delimited list of warnings</span>
<span class="c"># to suppress</span>
<span class="c">#</span>
<span class="c"># ignore-warnings ARM64-COW-BUG</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><summary type="html"><![CDATA[redis.conf 파일 모든 버전과 함께 제공되는 자체 문서화 된 redis.conf 파일]]></summary></entry><entry><title type="html">Redis 시작하기 - Redis Sentinel 고가용성</title><link href="http://localhost:4000/cache/ha-sentinel/" rel="alternate" type="text/html" title="Redis 시작하기 - Redis Sentinel 고가용성" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/cache/ha-sentinel</id><content type="html" xml:base="http://localhost:4000/cache/ha-sentinel/"><![CDATA[<h2 id="redis-sentinel을-통한-고가용성">Redis Sentinel을 통한 고가용성</h2>
<p>클러스터되지 않은 Redis의 고가용성<br />
Redis Sentinel은 Redis Cluster를 사용하지 않을 때 Redis에 대한 고가용성을 제공합니다. Redis Sentinel은 모니터링, 알림과 같은 기타 부수적인 작업도 제공하고 클라이언트에 대한 구성 공급자 역할을 합니다.</p>

<p>다음은 거시적 수준(즉, big picture)에서 Sentinel 기능의 전체 목록입니다.</p>
<ul>
  <li>Monitoring. Sentinel은 마스터 및 복제본 인스턴스가 예상대로 작동하는지 지속적으로 확인합니다.</li>
  <li>Notification. Sentinel은 API를 통해 시스템 관리자 또는 기타 컴퓨터 프로그램에 모니터링되는 Redis 인스턴스 중 하나에 문제가 있음을 알릴 수 있습니다.</li>
  <li>Automatic failover. 마스터가 예상대로 작동하지 않는 경우 Sentinel은 복제본이 마스터로 승격되고, 다른 추가 복제본이 새 마스터를 사용하도록 다시 구성되며, Redis 서버를 사용하는 애플리케이션에 연결할 때 사용할 새 주소에 대한 알림을 받는 장애 조치 프로세스를 시작할 수 있습니다.</li>
  <li>Configuration provider. Sentinel은 클라이언트 서비스 검색을 위한 권한 소스 역할을 하며, 클라이언트는 지정된 서비스를 담당하는 현재 Redis 마스터의 주소를 요청하기 위해 Sentinels에 연결합니다. 장애 조치(failover)가 발생하면 Sentinels는 새 주소를 보고합니다.</li>
</ul>

<h2 id="분산-시스템으로서의-sentinel">분산 시스템으로서의 Sentinel</h2>
<p>Redis Sentinel은 분산 시스템입니다:<br />
Sentinel 자체는 여러 Sentinel 프로세스가 함께 협력하는 구성에서 실행되도록 설계되었습니다. 여러 Sentinel 프로세스가 협력할 경우 다음과 같은 이점이 있습니다:</p>
<ol>
  <li>오류 감지는 여러 Sentinel이 지정된 마스터를 더 이상 사용할 수 없다는 사실에 동의할 때 수행됩니다. 이렇게 하면 장애발생 확률이 낮아집니다.</li>
  <li>Sentinel은 모든 Sentinel 프로세스가 작동하지 않더라도 작동하므로 시스템이 오류에 대해 견고합니다. 그 자체로 단일 실패 지점인 장애 조치 시스템을 갖는 것은 장애에 대응이 취약합니다.</li>
</ol>

<p>Sentinel, Redis 인스턴스(마스터 및 복제본) 및 Sentinel 및 Redis에 연결하는 클라이언트의 합계도 특정 속성을 가진 더 큰 분산 시스템입니다. 이 문서에서는 Sentinel의 기본 속성을 이해하는 데 필요한 기본 정보부터 Sentinel의 작동 방식을 이해하기 위해 보다 복잡한 정보(선택 사항)에 이르기까지 개념을 점진적으로 소개합니다.</p>

<h2 id="sentinel-quick-start">Sentinel quick start</h2>
<h4 id="obtaining-sentinel">Obtaining Sentinel</h4>
<p>현재 버전의 Sentinel을 Sentinel 2라고 합니다. 더 강력하고 예측하기 쉬운 알고리즘(이 설명서에 설명되어 있음)을 사용하여 초기 Sentinel 구현을 다시 작성한 것입니다.<br />
Redis 2.8부터 Redis Sentinel의 안정적인 릴리스가 제공됩니다.<br />
새로운 개발은 불안정한 분기에서 수행  되며, 새로운 기능은 안정적인 것으로 간주되는 즉시 최신 안정 분기로 다시 이식되는 경우가 있습니다.
Redis 2.6과 함께 제공되는 Redis Sentinel 버전 1은 더 이상 사용되지 않으며 사용해서는 안 됩니다.</p>
<h4 id="running-sentinel">Running Sentinel</h4>
<p>redis-sentinel 실행 파일을 사용하는 경우  (또는 해당 이름의 redis-server 실행 파일에 대한 심볼릭 링크가 있는 경우  ) 다음 명령줄을 사용하여 Sentinel을 실행할 수 있습니다.:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>redis-sentinel /path/to/sentinel.conf
</code></pre></div></div>
<p>그렇지 않으면 redis-server 실행 파일을 직접 사용하여 Sentinel 모드에서 시작할 수 있습니다.:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>redis-server /path/to/sentinel.conf <span class="nt">--sentinel</span>
</code></pre></div></div>
<p>두 가지 방법 모두 동일하게 작동합니다.<br />
그러나  Sentinel을 실행할 때는 이 파일이 다시 시작될 경우 다시 로드될 현재 상태를 저장하기 위해 시스템에서 사용되므로 구성 파일을 사용해야 합니다. Sentinel은 구성 파일이 제공되지 않거나 구성 파일 경로를 쓸 수 없는 경우 시작을 거부합니다.<br />
Sentinel은 기본적으로 TCP 포트 26379에 대한 연결을 수신하므로 Sentinels가 작동하려면 서버의 포트 26379  가 열려 있어야 다른 Sentinel 인스턴스의 IP 주소에서 연결을 수신할 수 있습니다  . 그렇지 않으면 Sentinels가 대화할 수 없고 수행할 작업에 대해 동의할 수 없으므로 장애 조치(failover)가 수행되지 않습니다.</p>

<h4 id="배포하기-전에-sentinel에-대해-알아야-할-기본-사항">배포하기 전에 Sentinel에 대해 알아야 할 기본 사항</h4>
<ol>
  <li>강력한 배포를 위해 최소 3개의 Sentinel 인스턴스가 필요합니다.</li>
  <li>세 개의 Sentinel 인스턴스는 독립적인 방식으로 오류가 발생하는 것으로 여겨지는 컴퓨터 또는 가상 머신에 배치해야 합니다. 예를 들어 서로 다른 물리적 서버 또는 서로 다른 가용성 영역에서 실행되는 Virtual Machines는 다음과 같습니다..</li>
  <li>Sentinel + Redis 분산 시스템은 Redis가 비동기 복제를 사용하므로 오류 중에 승인된 쓰기가 유지되도록 보장하지 않습니다. 그러나 쓰기 손실 창을 특정 순간으로 제한하는 Sentinel을 배포하는 방법이 있지만 덜 안전한 다른 방법이 있습니다.</li>
  <li>클라이언트에서 Sentinel 지원이 필요합니다. 인기 있는 클라이언트 라이브러리는 Sentinel을 지원하지만 전부는 아닙니다.</li>
  <li>개발 환경에서 수시로 테스트하지 않는 경우 안전한 HA 설정이 없으며, 프로덕션 환경에서 작동하는 경우 가능한 경우 더 좋습니다. 너무 늦었을 때(마스터가 작동을 멈추는 새벽 3시)에만 분명해지는 잘못된 구성이 있을 수 있습니다.</li>
  <li>Sentinel, Docker 또는 다른 형태의 네트워크 주소 변환 또는 포트 매핑은 주의해서 혼합해야 합니다. Docker는 포트 다시 매핑을 수행하여 다른 Sentinel 프로세스의 Sentinel 자동 검색 및 마스터에 대한 복제본 목록을 중단합니다.  자세한 내용은 이 문서의 뒷부분에 있는 Sentinel 및 Docker에 대한 섹션을  확인하세요.</li>
</ol>

<h2 id="sentinel-구성하기">Sentinel 구성하기</h2>
<p>Redis 소스 배포에는  Sentinel을 구성하는 데 사용할 수 있는 자체 문서화된 예제 구성 파일인 sentinel.conf라는 파일이 포함되어 있지만 일반적인 최소 구성 파일은 다음과 같습니다 :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1

sentinel monitor resque 192.168.1.3 6380 4
sentinel down-after-milliseconds resque 10000
sentinel failover-timeout resque 180000
sentinel parallel-syncs resque 5
</code></pre></div></div>
<p>모니터링할 마스터를 지정하기만 하면 되며, 분리된 각 마스터(복제본 수에 제한이 없을 수 있음)에 다른 이름을 부여하면 됩니다. 자동 검색되는 복제본을 지정할 필요가 없습니다. Sentinel은 복제본에 대한 추가 정보로 구성을 자동으로 업데이트합니다(다시 시작할 경우 정보를 유지하기 위해). 또한 페일오버 중에 복제본이 마스터로 승격될 때마다, 그리고 새 Sentinel이 검색될 때마다 구성이 다시 작성됩니다.<br />
위의 예제 구성은 기본적으로 각각 마스터와 정의되지 않은 수의 복제본으로 구성된 두 개의 Redis 인스턴스 집합을 모니터링합니다. 한 인스턴스 집합을 mymaster라고 하고 다른  인스턴스 집합을 resque라고 합니다.</p>

<p>sentinel monitor 문의 인수의 의미  는 다음과 같습니다.:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;
</code></pre></div></div>
<p>명확성을 위해 구성 옵션이 의미하는 바를 한 줄씩 확인해 보겠습니다:<br />
첫 번째 줄은 주소 127.0.0.1 및 포트 6379(쿼럼 2)에 있는 mymaster라는 마스터를 모니터링하도록 Redis에 지시하는 데 사용됩니다.마지막 인수는 쿼럼 인수 입니다.:</p>
<ul>
  <li>쿼럼은 마스터를  실제로 실패로 표시하고 가능한 경우 장애 조치(failover) 절차를 시작하기 위해 마스터에 연결할 수 없다는 사실에 동의해야 하는 Sentinel의 수입니다.</li>
  <li>그러나 쿼럼은 오류를 감지하는 데만 사용됩니다. 실제로 장애 조치(failover)를 수행하려면 센티넬 중 하나가 장애 조치(failover)의 리더로 선출되고 계속 진행할 수 있는 권한을 부여받아야 합니다. 이것은 Sentinel 프로세스의 대다수의 투표에서만 발생합니다.
예를 들어 5개의 Sentinel 프로세스가 있고 지정된 마스터의 쿼럼이 값 2로 설정된 경우 다음과 같은 일이 발생합니다:</li>
  <li>두 센티넬이 동시에 마스터에 연결할 수 없다는 데 동의하면 둘 중 하나가 장애 조치를 시작하려고 시도합니다.</li>
  <li>총 3개 이상의 Sentinel에 연결할 수 있는 경우 장애 조치(failover)가 승인되고 실제로 시작됩니다.</li>
</ul>

<p>실제로 이는 대부분의 Sentinel 프로세스가 통신할 수 없는 경우  (즉, 소수 파티션에서 장애 조치 없음) 장애 발생 시 Sentinel이 장애 조치를 시작하지 않음을 의미합니다.</p>
<h2 id="sentinel-추가옵션">Sentinel 추가옵션</h2>
<p>다른 옵션은 거의 항상 다음과 같은 형식입니다.:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sentinel &lt;option_name&gt; &lt;master_name&gt; &lt;option_value&gt;
</code></pre></div></div>
<p>그리고 다음과 같은 목적으로 사용됩니다:</p>
<ul>
  <li>down-after-milliseconds는 Sentinel이 다운되었다고 생각하기 시작하는 인스턴스에 연결할 수 없어야 하는 시간(밀리초 단위)입니다(PING에 응답하지 않거나 오류로 응답함).</li>
  <li>parallel-syncs는 장애 조치 후 동시에 새 마스터를 사용하도록 재구성할 수 있는 복제본 수를 설정합니다. 숫자가 낮을수록 장애 조치(failover) 프로세스가 완료되는 데 더 많은 시간이 걸리지만 복제본이 이전 데이터를 제공하도록 구성된 경우 모든 복제본이 동시에 마스터와 다시 동기화되는 것을 원하지 않을 수 있습니다. 복제 프로세스는 대부분 복제본에 대해 차단되지 않지만 마스터에서 대량 데이터를 로드하기 위해 중지되는 순간이 있습니다. 이 옵션을 값 1로 설정하여 한 번에 하나의 복제본에만 연결할 수 없도록 할 수 있습니다.<br />
추가 옵션은 이 문서의 나머지 부분에 설명되어 있으며  Redis 배포와 함께 제공되는 예제 sentinel.conf 파일에 설명되어 있습니다.
구성 매개변수는 런타임에 수정할 수 있습니다:</li>
  <li>마스터별 구성 매개변수는 SENTINEL SET를 사용하여 수정됩니다.</li>
  <li>글로벌 구성 매개변수는 SENTINEL CONFIG SET를 사용하여 수정됩니다..</li>
</ul>

<p>자세한 내용은 <a href="https://redis.io/docs/management/sentinel/#reconfiguring-sentinel-at-runtime">Reconfiguring Sentinel at runtime</a> 섹션을 참조하십시오.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><summary type="html"><![CDATA[Redis Sentinel을 통한 고가용성 클러스터되지 않은 Redis의 고가용성 Redis Sentinel은 Redis Cluster를 사용하지 않을 때 Redis에 대한 고가용성을 제공합니다. Redis Sentinel은 모니터링, 알림과 같은 기타 부수적인 작업도 제공하고 클라이언트에 대한 구성 공급자 역할을 합니다.]]></summary></entry><entry><title type="html">Redis 시작하기 - Redis Sentinel 고가용성 예시</title><link href="http://localhost:4000/cache/ha-sentinel-example/" rel="alternate" type="text/html" title="Redis 시작하기 - Redis Sentinel 고가용성 예시" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/cache/ha-sentinel-example</id><content type="html" xml:base="http://localhost:4000/cache/ha-sentinel-example/"><![CDATA[<h2 id="sentinel-구성">Sentinel 구성</h2>
<p>이제 Sentinel에 대한 기본 정보를 알았으므로 Sentinel 프로세스를 어디에 배치해야 하는지, 얼마나 많은 Sentinel 프로세스가 필요한지 등이 궁금할 수 있습니다. 이 섹션에서는 몇 가지 배포 예를 보여 줍니다.
그래픽 형식의 구성 예를 보여주기 위해 ASCII 아트를 사용  하며, 이것이 다른 기호가 의미하는 바입니다</p>

<p><img src="/assets/images/cache/15-cache-box.png" alt=" sentinel box" /></p>

<p>box 안에 Redis Instance가 실행중인있 있씁니다:</p>

<p><img src="/assets/images/cache/16-cache-master-sentinel.png" alt=" sentinel box" /></p>

<p>서로 다른 Box는 선으로 연결되어 대화할 수 있음을 보여줍니다:</p>

<p><img src="/assets/images/cache/17-cache-s1-s1.png" alt=" sentinel box" /></p>

<p>네트워크 파티션은 슬래시를 사용하여 중단된 줄로 표시됩니다</p>

<p><img src="/assets/images/cache/18-cache-s1-s1-network.png" alt=" sentinel box" /></p>

<p>또한 다음 사항에 유의하십시오.</p>
<ul>
  <li>마스터는 M1, M2, M3, …, Mn이라고합니다.</li>
  <li>복제본은 R1, R2, R3, …, Rn(R은 복제본을 나타냄)이라고 합니다.</li>
  <li>센티넬은 S1, S2, S3, …, Sn이라고합니다.</li>
  <li>클라이언트는 C1, C2, C3, …, Cn이라고 합니다.</li>
  <li>Sentinel 작업으로 인해 인스턴스가 역할이 변경되면 대괄호 안에 넣으므로 [M1]은 Sentinel 개입으로 인해 이제 마스터가 된 인스턴스를 의미합니다.</li>
</ul>

<p>Sentinel은  장애 조치를 시작하기 위해 항상 대다수와 통신해야 하므로 두 개의 Sentinel만 사용되는 설정은 표기하지 않습니다.</p>

<h2 id="예시-1">예시 1:</h2>

<p><img src="/assets/images/cache/19-cache-m1s1-r1s2.png" alt=" sentinel box" /></p>

<p>구성: quorum = 1</p>
<ul>
  <li>이 설정에서 마스터 M1에 장애가 발생하면 두 Sentinel이 실패에 대한 합의에 도달할 수 있고(분명히 쿼럼이 1로 설정됨) 과반수가 2이기 때문에 장애 조치를 승인할 수 있으므로 R1이 승격됩니다. 따라서 표면적으로 작동할 수 있지만 다음 사항을 확인하여 이 설정이 손상된 이유를 확인하십시오.</li>
  <li>M1이 실행 중인 서버 H/W박스가 작동을 멈추면 S1도 작동을 멈춥니다. 다른 상자 S2에서 실행 중인 Sentinel은 장애 조치(failover)를 승인할 수 없으므로 시스템을 사용할 수 없게 됩니다.</li>
</ul>

<p>서로 다른 장애 조치(failover)를 정렬하고 나중에 최신 구성을 모든 Sentinel에 전파하려면 과반수가 필요합니다. 또한 합의 없이 위 설정의 한 쪽에서 장애 조치(failover)하는 기능은 매우 위험합니다:</p>

<p><img src="/assets/images/cache/20-cache-m1s1-m1s2.png" alt=" m1s1 box" /></p>

<p>위의 구성에서 우리는 완벽하게 대칭적인 방식으로 두 개의 마스터(S2가 권한 부여 없이 장애 조치(failover)할 수 있다고 가정)를 만들었습니다. 클라이언트는 양쪽에 무기한으로 쓸 수 있습니다. 그리고 영구적인 분할  단절 상태에서는 파티션의  구성이 올바른 구성으로 복원할  방법이 없습니다</p>

<p>따라서 항상 <strong>세 개의 다른 상자에 최소 세 명의 센티넬을 배치</strong>하십시오</p>

<h2 id="예시-2-3개의-박스에-기본-설정">예시 2: 3개의 박스에 기본 설정</h2>
<p>이것은 매우 간단한 설정으로, 추가 안전을 위해 간단하게 조정할 수 있다는 장점이 있습니다. 세 개의 상자를 기반으로 하며, 각 상자는 Redis 프로세스와 Sentinel 프로세스를 모두 실행합니다.</p>

<p><img src="/assets/images/cache/21-cache-m1s1-r2s2-r3s3.png" alt="m1s1-r1s2-r3s3" /><br />
구성: quorum = 2</p>

<p>마스터 M1에 장애가 발생하면 S2와 S3는 장애에 대해 동의하고 장애 조치를 승인할 수 있으므로 클라이언트가 계속할 수 있습니다.
모든 Sentinel 설정에서 Redis는 비동기 복제를 사용하므로 지정된 승인된 쓰기가 마스터로 승격된 복제본에 도달하지 못할 수 있기 때문에 일부 쓰기가 손실될 위험이 항상 있습니다. 그러나 위의 설정에서는 다음 그림과 같이 클라이언트가 이전 마스터로 분할되기 때문에 더 높은 위험이 있습니다:</p>

<p><img src="/assets/images/cache/22-cache-m1s1-m2s2-r3s3.png" alt="m1s1-r1s2-r3s3" /></p>

<p>이 경우 네트워크 파티션은 이전 마스터 M1을 분리하므로 복제본 R2가 마스터로 승격됩니다. 그러나 이전 마스터와 동일한 파티션에 있는 C1과 같은 클라이언트는 이전 마스터에 데이터를 계속 쓸 수 있습니다. 이 데이터는 파티션이 복구되면 마스터가 새 마스터의 복제본으로 재구성되어 데이터 세트를 버리기 때문에 영원히 손실됩니다.</p>

<p>이 문제는 마스터가 더 이상 지정된 수의 복제본으로 쓰기를 전송할 수 없음을 감지하는 경우 쓰기 수락을 중지할 수 있는 다음 Redis 복제 기능을 사용하여 완화할 수 있습니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>min-replicas-to-write 1
min-replicas-max-lag 10
</code></pre></div></div>

<p>위의 구성(자세한 내용은 Redis 배포판의 자체 주석 처리된 redis.conf 예제 참조)을 사용하면  마스터 역할을 할 때 Redis 인스턴스가 1개 이상의 복제본에 쓸 수 없는 경우 쓰기 수락을 중지합니다. 복제는 비동기식이므로  실제로 쓸 수 없다는 것은  복제본의 연결이 끊어 졌거나 지정된 최대 지연 시간(초) 이상 비동기 승인을 보내지 않음을 의미합니다 .</p>

<p>이 구성을 사용하면 위 예제의 이전 Redis 마스터 M1을 10초 후에 사용할 수 없게 됩니다. 파티션이 복구되면 Sentinel 구성이 새 구성으로 수렴되고 클라이언트 C1은 유효한 구성을 가져올 수 있으며 새 마스터를 계속 사용할 수 있습니다.</p>

<p>그러나 공짜는 없습니다. 이 구체화를 통해 두 복제본이 다운되면 마스터는 쓰기 수락을 중지합니다. 그것은 절충안입니다</p>

<h2 id="예시-3-클라이언트-상자의-sentinel">예시 3: 클라이언트 상자의 Sentinel</h2>

<p>때로는 마스터와 복제본에 대해 두 개의 Redis 상자만 사용할 수 있습니다. 이 경우 예제 2의 구성은 실행 가능하지 않으므로 클라이언트가 있는 위치에 Sentinels가 배치되는 다음 구성에 의존할 수 있습니다:</p>

<p><img src="/assets/images/cache/23-cache-m1-r1-c1s1-c2s2-c3s3.png" alt="m1s1-r1s2-r3s3" /></p>

<p>이 설정에서 관점 Sentinels는 클라이언트와 동일하며, 대부분의 클라이언트가 마스터에 연결할 수 있는 경우 괜찮습니다. 여기서 C1, C2, C3은 일반 클라이언트이며, C1이 Redis에 연결된 단일 클라이언트를 식별한다는 의미는 아닙니다. 응용 프로그램 서버, Rails 응용 프로그램 또는 이와 유사한 것일 가능성이 더 큽니다.</p>

<p>M1 및 S1이 실행 중인 상자에 오류가 발생하면 장애 조치(failover)가 문제 없이 발생하지만 다른 네트워크 파티션으로 인해 다른 동작이 발생한다는 것을 쉽게 알 수 있습니다. 예를 들어 Redis 마스터와 복제본을 모두 사용할 수 없으므로 클라이언트와 Redis 서버 간의 네트워크 연결이 끊어지면 Sentinel을 설정할 수 없습니다.</p>

<p>C3가 M1로 분할되는 경우(위에서 설명한 네트워크에서는 거의 불가능하지만 다른 레이아웃에서는 또는 소프트웨어 계층의 오류로 인해 가능할 가능성이 높음) 예제 2에서 설명한 것과 유사한 문제가 발생하지만 여기서는 복제본과 마스터만 있기 때문에 대칭을 깰 방법이 없다는 차이점이 있습니다.  따라서 마스터는 복제본과의 연결이 끊어지면 쿼리 수락을 중지할 수 없으며, 그렇지 않으면 복제본 오류 중에 마스터를 사용할 수 없습니다.</p>

<p>따라서 이것은 유효한 설정이지만 예제 2의 설정은 Redis 자체와 동일한 상자에서 실행되는 Redis의 HA 시스템과 같은 이점이 있어 관리가 더 간단할 수 있으며 소수 파티션의 마스터가 쓰기를 수신할 수 있는 시간에 제한을 두는 기능이 있습니다.</p>

<p>예시 4: 클라이언트가 3개 미만인 Sentinel 클라이언트</p>

<p>예제 3에 설명된 설정은 클라이언트 측에 3개 미만의 상자(예: 웹 서버 3개)가 있는 경우 사용할 수 없습니다. 이 경우 다음과 같은 혼합 설정에 의존해야 합니다.:</p>

<p><img src="/assets/images/cache/24-cache-m1s1-r1s2-c1s3-c2s4.png" alt="m1s1-r1s2-r3s3" /><br />
구성: quorum = 3</p>

<p>이는 예제 3의 설정과 유사하지만 여기서는 사용 가능한 4개의 상자에서 4개의 Sentinel을 실행합니다. 마스터 M1을 사용할 수 없게 되면 다른 세 명의 센티넬이 페일오버를 수행합니다.</p>

<p>이론적으로 이 설정은 C2 및 S4가 실행 중인 상자를 제거하고 쿼럼을 2로 설정하는 방식으로 작동합니다. 그러나 애플리케이션 계층에서 고가용성을 갖지 않고 Redis 측에서 HA를 원할 가능성은 거의 없습니다.</p>

<h2 id="sentinel-docker-nat-및-가능한-문제">Sentinel, Docker, NAT 및 가능한 문제</h2>

<p>도커는 포트 매핑이라는 기술을 사용합니다: 도커 컨테이너 내에서 실행되는 프로그램은 프로그램이 사용하는 것으로 생각되는 것과 다른 포트로 노출될 수 있습니다. 이는 동일한 서버에서 동시에 동일한 포트를 사용하여 여러 컨테이너를 실행하는 데 유용합니다.</p>

<p>Docker는 이러한 일이 발생하는 유일한 소프트웨어 시스템이 아니며 포트를 다시 매핑할 수 있는 다른 네트워크 주소 변환 설정이 있으며 때로는 포트가 아니라 IP 주소도 있습니다.</p>

<p>포트와 주소를 다시 매핑하면 두 가지 방법으로 Sentinel에 문제가 발생합니다.:</p>
<ol>
  <li>다른 Sentinel의 Sentinel 자동 검색은  각 Sentinel이 연결을 수신 대기 중인 포트 및 IP 주소를 알리는 hello 메시지를 기반으로 하기 때문에 더 이상 작동하지 않습니다. 그러나 Sentinel은 주소 또는 포트가 다시 매핑되었음을 이해할 수 있는 방법이 없으므로 다른 Sentinel이 연결하기에 올바르지 않은 정보를 출력합니다.</li>
  <li>복제본은 비슷한 방식으로 Redis 마스터의 INFO 출력에 나열됩니다  : 주소는 TCP 연결의 원격 피어를 확인하는 마스터에 의해 감지되는 반면, 포트는 핸드 셰이크 중에 복제본 자체에 의해 통지되지만 포트 포인트 1에 노출 된 것과 같은 이유로 잘못 될 수 있습니다.</li>
</ol>

<p>Sentinels는 마스터 INFO 출력 정보를 사용하여 복제본을 자동 감지하므로  감지된 복제본에 연결할 수 없으며 시스템 관점에서 좋은 복제본이 없기 때문에 Sentinel은 마스터를 장애 조치할 수 없습니다. 따라서 Docker에 포트 1:1을 매핑하도록 지시하지 않는 한 현재 Docker와 함께 배포된 마스터 및 복제본 인스턴스 집합을 Sentinel로 모니터링할 수 있는 방법이 없습니다.</p>

<p>첫 번째 문제의 경우, 전달된 포트(또는 포트가 다시 매핑되는 다른 NAT 설정)와 함께 Docker를 사용하여 Sentinel 인스턴스 집합을 실행하려는 경우 다음 두 가지 Sentinel 구성 지시문을 사용하여 Sentinel이 특정 IP 및 포트 집합을 표기하도록 강제할 수 있습니다:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sentinel announce-ip &lt;ip&gt;
sentinel announce-port &lt;port&gt;
</code></pre></div></div>

<p>Docker에는 호스트 네트워킹 모드에서 실행할 수 있는 기능이 있습니다  (  자세한 내용은 –net=host 옵션 확인). 이 설정에서 포트가 다시 매핑되지 않으므로 문제가 발생하지 않습니다.</p>

<h2 id="ip-주소-및-dns-이름">IP 주소 및 DNS 이름</h2>
<p>이전 버전의 Sentinel은 호스트 이름을 지원하지 않았으며 모든 곳에서 IP 주소를 지정해야 했습니다. 버전 6.2부터 Sentinel은  호스트 이름을 선택적으로 지원합니다</p>

<p><strong>이 기능은 기본적으로 비활성화되어 있습니다. DNS/호스트 이름 지원을 활성화하려는 경우 다음 사항에 유의하세요</strong>.:</p>
<ol>
  <li>Redis 및 Sentinel 노드의 이름 확인 구성은 안정적이어야 하며 주소를 빠르게 확인할 수 있어야 합니다. 주소 확인의 예기치 않은 지연은 Sentinel에 부정적인 영향을 미칠 수 있습니다.</li>
  <li>모든 곳에서 호스트 이름을 사용하고 호스트 이름과 IP 주소를 혼합하지 않아야 합니다. 이렇게 하려면  모든 Redis 및 Sentinel 인스턴스에 대해 각각 replica-announce-ip <hostname>  및 sentinel announce-ip <hostname>를 사용합니다.</hostname></hostname></li>
</ol>

<p>resolve-hostnames 글로벌 구성을 활성화하면 Sentinel이 호스트 이름을 수락할 수 있습니다:</p>

<ul>
  <li>sentinel monitor 명령의 일부로</li>
  <li>복제본 주소로, 복제본이 replica-announce-ip에 호스트 이름 값을 사용하는 경우</li>
</ul>

<p>Sentinel은 호스트 이름을 유효한 입력으로 받아들이고 확인하지만, 인스턴스를 발표하거나 구성 파일을 업데이트할 때 여전히 IP 주소를 참조합니다.</p>

<p>announce-hostnames 전역 구성을 활성화하면 Sentinel이 호스트 이름을 대신 사용합니다. 이는 클라이언트에 대한 응답, 구성 파일에 기록된 값, 복제본에 실행된 REPLICAOF 명령 등에 영향을 줍니다.</p>

<p>이 동작은 IP 주소를 명시적으로 예상할 수 있는 모든 Sentinel 클라이언트와 호환되지 않을 수 있습니다.
클라이언트가 TLS를 사용하여 인스턴스에 연결하고 인증서 ASN 일치를 수행하기 위해 IP 주소 대신 이름이 필요한 경우 호스트 이름을 사용하는 것이 유용할 수 있습니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><summary type="html"><![CDATA[Sentinel 구성 이제 Sentinel에 대한 기본 정보를 알았으므로 Sentinel 프로세스를 어디에 배치해야 하는지, 얼마나 많은 Sentinel 프로세스가 필요한지 등이 궁금할 수 있습니다. 이 섹션에서는 몇 가지 배포 예를 보여 줍니다. 그래픽 형식의 구성 예를 보여주기 위해 ASCII 아트를 사용 하며, 이것이 다른 기호가 의미하는 바입니다]]></summary></entry><entry><title type="html">Redis 시작하기 - Redis Functions 시작하기</title><link href="http://localhost:4000/cache/getting-start-functions/" rel="alternate" type="text/html" title="Redis 시작하기 - Redis Functions 시작하기" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/cache/getting-start-functions</id><content type="html" xml:base="http://localhost:4000/cache/getting-start-functions/"><![CDATA[<h2 id="redis-functions">Redis Functions</h2>
<p>Redis 버전 7.0에 추가된 가장 영향력 있는 기능은 모듈성, 재사용성 및 전반적인 개발자 환경 개선을  통해 스크립트를 개선하는 새로운 프로그래밍 옵션  인 Redis Functions입니다.</p>

<p>함수는 스크립트와 달리 .rdb 및 .aof 파일에 유지될 뿐만 아니라 모든 복제본에 자동으로 복제되므로 Redis의 일부 모듈이 됩니다.
Redis는 여러 실행 엔진을 지원할 수 있으므로 향후 릴리스 중 하나에서 Lua, Javascript 및 기타 언어로 Redis 함수를 작성할 수 있지만 현재(Redis v7.0) 지원되는 유일한 언어는 Lua입니다.</p>

<p>개발자의 일반적인 고충은 논리 스키마를 통해 데이터 엔터티에 대한 일관된 보기를 유지하는 것입니다. Redis Functions는 이 문제를 해결하는 데 이상적으로 적합하며 이 자습서에서는 두 가지 기능이 있는 라이브러리를 만듭니다. 첫 번째는 자동으로 할 수 있는지 확인합니다.  해시 키에 대한 타임스탬프  _created_at 및 _updated_at 설정두 번째는  다른 요소를 변경하지 않고 단순히 _updated_at 타임스탬프를 업데이트하여 “터치” Unix 기능을 시뮬레이션합니다. 시작합시다!</p>

<h2 id="environment-setup">Environment setup</h2>
<p>먼저 Redis 7로 작업 환경을 설정해 보겠습니다. 운영 체제에 따라 아래 가이드의 설치 지침을 따를 수 있습니다:</p>
<ul>
  <li><a href="https://redis.io/docs/getting-started/installation/install-redis-from-source/">Install Redis from Source</a></li>
  <li><a href="https://redis.io/docs/getting-started/installation/install-redis-on-linux/">Install Redis on Linux</a></li>
  <li><a href="https://redis.io/docs/getting-started/installation/install-redis-on-mac-os/">Install Redis on macOS</a></li>
  <li><a href="https://redis.io/docs/getting-started/installation/install-redis-on-windows/">Install Redis on Windows</a></li>
</ul>

<p>또는 Redis Stack을 사용하여 Docker 컨테이너를 스핀업할 수 있습니다:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>data
docker run <span class="nt">-p</span> 6379:6379 <span class="nt">--name</span> redis-7.0 <span class="nt">-it</span>  <span class="nt">-v</span> <span class="nv">$PWD</span>/data:/data redis/redis-stack:7.0.0-RC4
</code></pre></div></div>
<p>NOTE
이 자습서의 나머지 부분에서는 $ 문자를 사용하여 명령 프롬프트에서 명령을 실행해야 함을 나타내고&gt; redis-cli를 사용하여  redis-cli 프롬프트에 대해 동일한 명령을 나타냅니다.
Warm-Up
이제 Redis 서버가 실행 중이므로 mylib.lua라는 파일을 만들고  그 안에 명령줄에 매개 변수로 전달하는 키와 인수를 수신하는 hset이라는 함수를 만들  수 있습니다.
Redis의 함수는 항상 라이브러리의 일부이며 단일 라이브러리에는 여러 함수가 있을 수 있습니다.
우선 “Hello Redis 7.0”을 반환하는 간단한 함수를 만들어 data 폴더에 mylib.lua 파일을 저장합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!lua name=mylib</span>

<span class="nb">local </span><span class="k">function </span>hset<span class="o">(</span>keys, args<span class="o">)</span>
   <span class="k">return</span> <span class="s2">"Hello Redis 7.0"</span>
end
</code></pre></div></div>
<p>첫 번째 줄은 Lua 엔진을 사용하여 이 함수를 실행하고 해당 이름을 mylib로 지정합니다. 이름은 라이브러리 식별자이며 업데이트해야 할 때마다 사용합니다.
다음으로 Functions API를 통해 액세스할 수 있도록 이 함수를 등록해야 합니다. 등록에서 함수 hset을 my_hset라는  이름으로 호출할 수  있도록 지정합니다.:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>redis.register_function<span class="o">(</span><span class="s1">'my_hset'</span>, hset<span class="o">)</span>
</code></pre></div></div>
<p>지금까지의 전체 코드는 다음과 같습니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!lua name=mylib</span>
<span class="nb">local </span><span class="k">function </span>hset<span class="o">(</span>keys, args<span class="o">)</span>
   <span class="k">return</span> <span class="s2">"Hello Redis 7.0"</span>
end

redis.register_function<span class="o">(</span><span class="s1">'my_hset'</span>, hset<span class="o">)</span>
</code></pre></div></div>

<p>명령줄에서 함수를 호출하려면 먼저 Redis 서버에 로드하고 등록해야 합니다:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> /path/to/mylib.lua | redis-cli <span class="nt">-x</span> FUNCTION LOAD
</code></pre></div></div>

<p>docker 기반인 경우 다음과 같이 실행합니다</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">exec</span> <span class="nt">-it</span> redis-7.0 bash
<span class="c"># data</span>
<span class="nb">cd</span> /data
<span class="nb">cat</span> /path/to/mylib.lua | redis-cli <span class="nt">-x</span> FUNCTION LOAD
</code></pre></div></div>

<p>마지막으로 등록한 함수를 실행해 보겠습니다:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>redis-cli&gt; FCALL my_hset 1 foo
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="cache" /><category term="redis" /><category term="lua" /><summary type="html"><![CDATA[Redis Functions Redis 버전 7.0에 추가된 가장 영향력 있는 기능은 모듈성, 재사용성 및 전반적인 개발자 환경 개선을 통해 스크립트를 개선하는 새로운 프로그래밍 옵션 인 Redis Functions입니다.]]></summary></entry></feed>