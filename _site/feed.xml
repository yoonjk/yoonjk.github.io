<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-01-24T19:46:05+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Cloud Native Journey</title><subtitle>Software Engineer/Architect</subtitle><author><name>Jaeguk Yun</name></author><entry><title type="html">Install MiniKube</title><link href="http://localhost:4000/kubernetes/install-minikube/" rel="alternate" type="text/html" title="Install MiniKube" /><published>2023-01-24T00:00:00+09:00</published><updated>2023-01-24T00:00:00+09:00</updated><id>http://localhost:4000/kubernetes/install-minikube</id><content type="html" xml:base="http://localhost:4000/kubernetes/install-minikube/"><![CDATA[<h2 id="pre-requisites---install-docker">Pre-requisites - Install Docker</h2>

<p>yum utils을 설치합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> yum-utils
</code></pre></div></div>

<p>Docker repository 정보를 download 받습니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum-config-manager <span class="se">\</span>
<span class="nt">--add-repo</span> <span class="se">\</span>
https://download.docker.com/linux/centos/docker-ce.repo
</code></pre></div></div>

<p>최신 버전의 Docker Engine, containerd를 설치하거나 다음 단계로 이동하여 특정 버전을 설치합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> docker-ce docker-ce-cli containerd.io
</code></pre></div></div>

<p>docker를 시작합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl start docker
</code></pre></div></div>

<p>docker daemon이 정상 설치되었는지 hello-world docker image를 pull하기 위해 다음 명령어를 수행하여 확인합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull hello-world 
</code></pre></div></div>

<p>[수행결과]
<img src="/assets/images/jenkins/07-jenkins-docker-hello-world.png" alt="docker pull hello-world" /></p>

<p>docker images를 수행하여 아래와 같이 출력되는 확인합니다</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker images
</code></pre></div></div>

<p>[수행결과]
<img src="/assets/images/jenkins/08-jenkins-docker-images.png" alt="docker pull hello-world" /></p>

<h2 id="install-minikube">Install MiniKube</h2>

<p>minikube를 download 하고 minikube를 설치합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LO</span> https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
<span class="nb">tar </span>xvzf 
<span class="nb">sudo mv </span>minikube-linux-amd64 /usr/local/bin/minikube
<span class="nb">chmod</span> +x /usr/local/bin/minikube
</code></pre></div></div>

<p>minikube를 다음과 같이 시작합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube start <span class="nt">--driver</span><span class="o">=</span>docker <span class="nt">--force</span>
</code></pre></div></div>

<p>kubectl CLI download 합니다</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-L</span> <span class="s2">"https://dl.k8s.io/release/</span><span class="si">$(</span>curl <span class="nt">-L</span> <span class="nt">-s</span> https://dl.k8s.io/release/stable.txt<span class="si">)</span><span class="s2">/bin/linux/amd64/kubectl"</span> <span class="nt">-o</span> /usr/local/bin/kubectl

<span class="nb">chmod</span> +x /usr/local/bin/kubectl

kubectl get po <span class="nt">-A</span>
</code></pre></div></div>

<h2 id="configure-for-connecting-jenkins">Configure for connecting Jenkins</h2>

<p>jenkins에서 minikube에 접속하기 위해  Kubernetes 의 credentials 정보가 있는 $HOME/.kube/config 파일을 확인합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>less ~/.kube/config
</code></pre></div></div>

<p><img src="/assets/images/jenkins/09-jenkins-kube-config.png" alt="kube-config" /></p>

<p>위의 cluster CA 정보의 client 인증서 파일 경로를 데이터의 내용으로 변경 합니다
<img src="/assets/images/jenkins/10-jenkins-kube-config-2.png" alt="kube-config" /></p>

<p>아래의 명령어로 ca.crt, client.crt, client.key 파일의 내용을 다음의 명령어로 변환합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> /root/.minikube/ca.crt|base64 <span class="nt">-w0</span><span class="p">;</span><span class="nb">echo
cat</span> /root/.minikube/profiles/minikube/client.crt|base64 <span class="nt">-w0</span><span class="p">;</span><span class="nb">echo
cat</span> /root/.minikube/profiles/minikube/client.key|base64 <span class="nt">-w0</span><span class="p">;</span><span class="nb">echo</span>
</code></pre></div></div>

<p>certificate-authority =&gt; certificate-authority-data로 변경
client-certificate =&gt; client-certificate-data 로 변경
client-key =&gt; client-key-data 로 변경</p>

<p><img src="/assets/images/jenkins/11-jenkins-change-kube-config.png" alt="kube-config" /></p>

<p>default namespace의 pod 목록이 조회되는지 다음과 같이 확인합니다.</p>

<p>kubectl get pods</p>

<p>[수행결과]
No resources found in default namespace.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="kubernetes" /><category term="minikube" /><summary type="html"><![CDATA[Pre-requisites - Install Docker]]></summary></entry><entry><title type="html">Jenkins 설치 따라하기</title><link href="http://localhost:4000/devops/setup-jenkins/" rel="alternate" type="text/html" title="Jenkins 설치 따라하기" /><published>2023-01-24T00:00:00+09:00</published><updated>2023-01-24T00:00:00+09:00</updated><id>http://localhost:4000/devops/setup%20jenkins</id><content type="html" xml:base="http://localhost:4000/devops/setup-jenkins/"><![CDATA[<h2 id="jenkins-pipeline-이란">Jenkins Pipeline 이란?</h2>
<p>Jenkins Pipeline은 지속적인 업데이트 파이프라인을 구현하고 Jenkins에 통합하는 것을 지원하는 플러그인의 집합이다. 이 과정에서 소프트웨어를 빌드하고 여러 단계의 테스트, 배포를 진행한다. 
Pipeline은 Pipeline Domain Specific Language라는 문법을 통해 마치 코드를 작성하는 것과 같이 Pipeline을 통해 간단한 배포 파이프라인부터 복잡한 배포  파이프라인을 코드로 모델링하기 위한 확장 가능한 도구 집합을 제공합니다.
. 
Jenkins 파이프 라인의 정의는 프로젝트의 소스 제어 저장소에 commit될 수 있는 텍스트 파일 (Jenkinsfile이라고 함)에 저장합니다.</p>

<ul>
  <li><strong>Install Jenkins on Linux(Centos)</strong></li>
</ul>

<p>Jenkins를 설치하기 전에 사전에 JDK와 Maven을 설치합니다. 
상세한 설치 정보는 다음의 링크를 참조합니다.</p>

<p>https://www.jenkins.io/doc/book/installing/linux/</p>

<p>java-11-openjdk을 설치합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>dnf upgrade <span class="nt">-y</span>
<span class="nb">sudo </span>dnf <span class="nb">install</span> <span class="nt">-y</span> java-11-openjdk
</code></pre></div></div>

<p>다음의 링크를 접속하여 Maven 설치합니다.
https://maven.apache.org/download.cgi 에서 최근  maven 링크를 복사합니다</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/jenkins/01-jenkins-install-maven.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>설치하고자 하는 경로에 압축파일을 다운 받아 압축을 해제한 후, 해당 폴더가 위치한 곳을 MAVEN_HOME으로 설정합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://dlcdn.apache.org/maven/maven-3/3.8.7/binaries/apache-maven-3.8.7-bin.tar.gz

<span class="nb">tar </span>xvzf apache-maven-3.8.7-bin.tar.gz <span class="nt">-C</span> /usr/local
</code></pre></div></div>

<p>~/.bash_profile을 vi editor로 열어MAVEN_HOME 환경정보를 추가합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">MAVEN_HOME</span><span class="o">=</span>/usr/local/apache-maven-3.8.7 
<span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$MAVEN_HOME</span>/bin 

bash profile을 설정하고 저장하고, bash_profile을 최신으로 적용합니다.
<span class="nb">source</span> ~/.bash_profile 
</code></pre></div></div>

<p>maven 설정되었는지 다음의 명령어로 수행하여 아래의 내용이 출력되는지 확인합니다.</p>

<p>mvn</p>

<p>[수행결과]
<img src="/assets/images/jenkins/02-jenkins-mvn.png" alt="transparent black overlay" /></p>

<p>다음과 같이Git 설치합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>dnf <span class="nb">install</span> <span class="nt">-y</span> git
</code></pre></div></div>

<p>레포지터리에 젠킨스 레드햇 안정화 버전 레포지터리를 추가합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://pkg.jenkins.io/redhat-stable/jenkins.repo <span class="nt">-O</span> /etc/yum.repos.d/jenkins.repo 
</code></pre></div></div>

<p>rpm에 젠킨스를 추가합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>rpm <span class="nt">--import</span> https://pkg.jenkins.io/redhat-stable/jenkins.io.key
</code></pre></div></div>

<p>Jenkins 를 다음과 같이 설치합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>dnf <span class="nb">install</span> <span class="nt">-y</span> jenkins
</code></pre></div></div>

<p>OS 부팅 시 Jenkins 서비스가 시작되도록 설정합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl <span class="nb">enable </span>jenkins
</code></pre></div></div>

<p>다음 명령을 사용하여 Jenkins 서비스를 시작합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl start jenkins
</code></pre></div></div>

<p>다음 명령을 사용하여 Jenkins 서비스의 상태를 확인할 수 있습니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl status jenkins
</code></pre></div></div>

<p>docker container image 빌드를 위해 빌드 툴인 Podman을 설치합니다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>yum <span class="nb">install</span> <span class="nt">-y</span> podman 
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="jenkins" /><summary type="html"><![CDATA[Jenkins Pipeline 이란? Jenkins Pipeline은 지속적인 업데이트 파이프라인을 구현하고 Jenkins에 통합하는 것을 지원하는 플러그인의 집합이다. 이 과정에서 소프트웨어를 빌드하고 여러 단계의 테스트, 배포를 진행한다. Pipeline은 Pipeline Domain Specific Language라는 문법을 통해 마치 코드를 작성하는 것과 같이 Pipeline을 통해 간단한 배포 파이프라인부터 복잡한 배포 파이프라인을 코드로 모델링하기 위한 확장 가능한 도구 집합을 제공합니다. . Jenkins 파이프 라인의 정의는 프로젝트의 소스 제어 저장소에 commit될 수 있는 텍스트 파일 (Jenkinsfile이라고 함)에 저장합니다.]]></summary></entry><entry><title type="html">Jenkins Kubernetes Plugin 설치 및 환경구성</title><link href="http://localhost:4000/devops/install-kubernetes-plugin/" rel="alternate" type="text/html" title="Jenkins Kubernetes Plugin 설치 및 환경구성" /><published>2023-01-24T00:00:00+09:00</published><updated>2023-01-24T00:00:00+09:00</updated><id>http://localhost:4000/devops/install%20kubernetes%20plugin</id><content type="html" xml:base="http://localhost:4000/devops/install-kubernetes-plugin/"><![CDATA[<h2 id="jenkins-kubernetes-plugin-설치">Jenkins Kubernetes Plugin 설치</h2>
<p>Jenkins Agent로 Kubernetes에 실행하기 위해 Kubernetes Plugin을 Jenkins에 설치하여 환경을 구성합니다.</p>

<p>Jenkins UI에서 Manage Jenkins &gt; System Configuration &gt; Manage Plugins &gt;Available plugins 메뉴를 클릭합니다</p>

<p>Plugins 검색 입력 필드에서 Kubernetes 입력하고 다음과 같은 첫번째  Kubernetes [V] 선택, 왼쪽 하단에 Install without restart 버튼을 클릭합니다</p>

<p><img src="/assets/images/jenkins/12-jenkins-install-kubernetes-plugin.png" alt="Install Kubernetes Plugin" /></p>

<p>아래의 [v] “Restart Jenkins when installation is complete and no jobs are running” 버튼을 선택하여 jenkins를 재시작 합니다. admin 계정으로 로드인을 합니다</p>

<p>Manage Jenkins &gt; System Configuration &gt; Manage Nodes and Clouds를 선택합니다.</p>

<p>Configure Clouds를 선택하고, Combo 박스에서 Kubernetes를 선택합니다.</p>

<p><img src="/assets/images/jenkins/13-jenkins-add-new-cloud.png" alt="Install Kubernetes Plugin" /></p>

<p>Kubernetes 접속하기 위한 Credentials 정보를 입력하면이 다음과 같이 출력됩니다. Kubernetes Cloud details 버튼을 클릭하면 상세 입력창이 출력됩니다.</p>
<figure style="width: 5%; height: 20%; " class="align-center">
  <img src="http://localhost:4000/assets/images/jenkins/14-jenkins-configure-clouds.png " alt="" />
  <figcaption></figcaption>
</figure>

<p>Kubernetes Namespace section에 jenkins 를 입력합니다
<img src="/assets/images/jenkins/15-jenkins-kubernetes-namespace.png" alt="Kubernetes Namespace" /></p>

<p>Configure Clouds에서 Credentials &gt; Add 버튼을 클릭합니다
<img src="/assets/images/jenkins/16-jenkins-add-jenkins.png" alt="add jenkins in Credentials" /></p>

<p>Add Credentials 입력창에서 credentials 정보를 다음과 같이 입력합니다.<br />
File은 자신의 VM 서버의 root 계정의. $HOME/.kube/config 파일을 선택합니다.<br />
.kube/config 파일을 자신의 laptop에 download 받아서 choose file 버튼을 클릭하여 download 받은 config파일을 선택합니다.<br />
<img src="/assets/images/jenkins/17-jenkins-add-credentials.png" alt="add Credentials" /></p>

<p>Credentials Section 에서 위에서 입력한 mykubeconfig를 선택하고, Test Connection버튼을 클릭하여 minikube 연결을 테스트합니다. 다음의 메시지처럼 정상 출력되는지 확인합니다.
“Connected to Kubernetes v1.xx.x”로 표시 되는지 확인합니다</p>
<figure style="width: 50%; height: 20%; " class="align-center">
  <img src="http://localhost:4000/assets/images/jenkins/18-jenkins-connected.png " alt="" />
  <figcaption></figcaption>
</figure>

<p>WebSocket 항목을 선택합니다.<br />
[v] WebSocket</p>

<p>Pod Label Section에서key / value값을 다음과 같이 입력합니다.</p>

<figure style="width: 100%; height: 100%; " class="align-center">
  <img src="http://localhost:4000/assets/images/jenkins/19-jenkins-pod-labels.png " alt="" />
  <figcaption></figcaption>
</figure>

<p>Pod Templates Section 다음과 같이 입력합니다</p>
<figure style="width: 50%; height: 100%; " class="align-center">
  <img src="http://localhost:4000/assets/images/jenkins/20-jenkins-pod-templates.png " alt="" />
  <figcaption></figcaption>
</figure>

<p>Container Section은 다음과 같이 입력하고 저장버튼을 클릭합니다.<br />
Name : jnlp-slave<br />
Docker image : jenkinsci/jnlp-slave:latest<br />
Working directory : /home/jenkins/agent<br />
Command to run : /bin/sh -c .</p>

<figure style="width: 50%; height: 100%; " class="align-center">
  <img src="http://localhost:4000/assets/images/jenkins/21-jenkins-container-templates.png " alt="" />
  <figcaption></figcaption>
</figure>

<p>Jenkins agent가 실행할 jenkins namespace를 다음과 같이 생성합니다.</p>

<p>kubectl create ns jenkins</p>

<p>Jenkins Console Output 화면에서 다음과 같은 메시지가 출력되면 “Message: namespaces “jenkins” not found”  위 Jenkins namespace를 생성하지 않아서 발생하는 에러입니다.</p>

<p>터미널창에서 default namespace에 app을 설치할 수 있는 권한을 cluster-admin 권한으로 jenkins에 부여합니다.
kubectl create clusterrolebinding jenkins-admin  –clusterrole cluster-admin –serviceaccount jenkins:default</p>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="jenkins" /><summary type="html"><![CDATA[Jenkins Kubernetes Plugin 설치 Jenkins Agent로 Kubernetes에 실행하기 위해 Kubernetes Plugin을 Jenkins에 설치하여 환경을 구성합니다.]]></summary></entry><entry><title type="html">Jenkins 시작</title><link href="http://localhost:4000/devops/start-up-jenkins/" rel="alternate" type="text/html" title="Jenkins 시작" /><published>2023-01-24T00:00:00+09:00</published><updated>2023-01-24T00:00:00+09:00</updated><id>http://localhost:4000/devops/start-up%20jenkins</id><content type="html" xml:base="http://localhost:4000/devops/start-up-jenkins/"><![CDATA[<h2 id="start-up-jenkins">Start-up Jenkins</h2>
<p>Jenkins server에 접속하기 brower에서 해당 서버의 http://localhost:8080 포트 접속합니다.</p>

<p>Jenkins에 접속하면 Jenkins admin 초기 패스워드를 입력하는 화면이 출력됩니다</p>

<p>터미널에서 다음과 같이 명령을 수행하여 Jenkins  admin 초기 로그인 비밀번호를 확인하고, 초기 패스워드를 입력합니다.</p>

<p><img src="/assets/images/jenkins/03-jenkins-initial-admin.png" alt="Jenkins Getting started" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> /var/lib/jenkins/secrets/initialAdminPassword
</code></pre></div></div>

<p>[수행결과]
a0f289xxxxxxxxxcd8fbb7</p>

<p>Jenkins 패스워드 입력화면에 복사한 패스워드를 입력하고 Continue 버튼을 클릭하고, Install suggested plugins를 선택합니다</p>

<p><img src="/assets/images/jenkins/04-jenkins-getting-started.png" alt="Jenkins Getting started" /></p>

<p>Jenkins Plugins이 다음과 같이 설치됩니다</p>

<p><img src="/assets/images/jenkins/05-jenkins-install-plugins.png" alt="Install Jenkins Plugins" /></p>

<p>Jenkins Admin 계정을 생성합니다. Save and Continue 버튼을 클릭합니다</p>

<p><img src="/assets/images/jenkins/06-jenkins-create-admin.png" alt="Create Admin" /></p>

<p>Instance Configuration 확인하고, Save and Finish 버튼을 클릭하고, Start using Jenkins 버튼을 클릭합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="jenkins" /><summary type="html"><![CDATA[Start-up Jenkins Jenkins server에 접속하기 brower에서 해당 서버의 http://localhost:8080 포트 접속합니다.]]></summary></entry><entry><title type="html">Airflow Hooks - MySQL</title><link href="http://localhost:4000/workflow/Airflow-hooks-mysql/" rel="alternate" type="text/html" title="Airflow Hooks - MySQL" /><published>2022-12-18T00:00:00+09:00</published><updated>2022-12-18T00:00:00+09:00</updated><id>http://localhost:4000/workflow/Airflow%20hooks-mysql</id><content type="html" xml:base="http://localhost:4000/workflow/Airflow-hooks-mysql/"><![CDATA[<h2 id="airflow-hooks---mysql">Airflow Hooks - MySQL</h2>

<p>MySqlHook 예제입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.providers.mysql.hooks.mysql</span> <span class="kn">import</span> <span class="n">MySqlHook</span> 
<span class="c1"># utils
</span><span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">NamedTemporaryFile</span> 
<span class="kn">import</span> <span class="nn">csv</span><span class="p">,</span> <span class="n">logging</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="n">MYSQL_CONN_ID</span> <span class="o">=</span><span class="s">'mysql-conn'</span>

<span class="k">def</span> <span class="nf">export_db_to_dsv</span><span class="p">():</span>
  <span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Staring mysql_hook"</span><span class="p">)</span>
  <span class="n">hook</span> <span class="o">=</span> <span class="n">MySqlHook</span><span class="p">(</span><span class="n">conn_id</span> <span class="o">=</span> <span class="n">MYSQL_CONN_ID</span><span class="p">)</span>
  <span class="n">conn</span> <span class="o">=</span> <span class="n">hook</span><span class="p">.</span><span class="n">get_conn</span><span class="p">()</span> 
  <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">cursor</span><span class="p">()</span>
  <span class="n">cursor</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">'use demo'</span><span class="p">)</span>
  <span class="n">cursor</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">'select * from users'</span><span class="p">)</span>
  
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'/opt/airflow/data/employee.csv'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> 
    <span class="n">csv_writer</span> <span class="o">=</span> <span class="n">csv</span><span class="p">.</span><span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> 
    <span class="n">csv_writer</span><span class="p">.</span><span class="n">writerow</span><span class="p">([</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cursor</span><span class="p">.</span><span class="n">dscription</span><span class="p">])</span>
    <span class="n">csv_writer</span><span class="p">.</span><span class="n">writerows</span><span class="p">(</span><span class="n">cursor</span><span class="p">)</span>
    <span class="n">f</span><span class="p">.</span><span class="n">flush</span><span class="p">()</span>
    <span class="n">cursor</span><span class="p">.</span><span class="n">close</span><span class="p">()</span> 
    <span class="n">conn</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">'Saved data in csv file: %s'</span><span class="p">,</span> <span class="s">'/opt/airflow/data/employee.csv'</span><span class="p">)</span>
    
<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'mysql-hook-db-to-csv'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="s">'training'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">export_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="s">"mysql_to_csv"</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">export_db_to_dsv</span>
  <span class="p">)</span>
  
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'start'</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'end'</span><span class="p">)</span> 
  
  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="n">export_task</span> <span class="o">&gt;&gt;</span> <span class="n">end</span>  
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Hooks - MySQL]]></summary></entry><entry><title type="html">Airflow TaskGroup</title><link href="http://localhost:4000/workflow/Airflow-Task-Group/" rel="alternate" type="text/html" title="Airflow TaskGroup" /><published>2022-12-18T00:00:00+09:00</published><updated>2022-12-18T00:00:00+09:00</updated><id>http://localhost:4000/workflow/Airflow%20Task%20Group</id><content type="html" xml:base="http://localhost:4000/workflow/Airflow-Task-Group/"><![CDATA[<h2 id="airflow-taskgroup">Airflow TaskGroup</h2>
<p>작업 그룹은 그래프 보기에서 작업을 계층적 그룹으로 구성하는 데 사용할 수 있습니다. 반복되는 패턴을 만들고 시각적 혼란을 줄이는 데 유용합니다..</p>

<p><img src="https://airflow.apache.org/docs/apache-airflow/stable/_images/task_group.gif" alt="taskgroup decorator" /></p>

<h4 id="작업-그룹을-사용하려면-다음-import-문을-실행합니다">작업 그룹을 사용하려면 다음 import 문을 실행합니다.</h4>
<ul>
  <li>기존 방식 TaskGroup</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.utils.task_group</span> <span class="kn">import</span> <span class="n">TaskGroup</span>
</code></pre></div></div>

<ul>
  <li>decorator를 사용하는 경우</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">task_group</span><span class="p">,</span> <span class="n">task</span>
</code></pre></div></div>

<p>첫 번째 예에서는 with 문을  사용하여 작업 그룹을 인스턴스화하고 group_id 제공합니다. 작업 그룹 내에서 두 작업인 t1과 t2와 해당 종속성을 정의합니다.</p>

<p>개별 작업에서 사용할 수 있는 것과 동일한 방식으로 작업 그룹에서 종속성 연산자(« 및 »)를 사용할 수 있습니다. 작업 그룹에 적용된 종속성은 해당 작업 전체에 적용됩니다. 다음 코드에서는 start 및 end 에 대한 추가 종속성을 작업 그룹에 추가하여 t1 및 t2에  동일한 종속성을 자동으로 적용합니다. :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.task_group</span> <span class="kn">import</span> <span class="n">TaskGroup</span> 
<span class="c1"># Utils 
</span><span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> 
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span> <span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'taskgroup2'</span><span class="p">,</span>
  <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'start'</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'end'</span><span class="p">)</span>
  
  <span class="k">with</span> <span class="n">TaskGroup</span><span class="p">(</span><span class="n">group_id</span> <span class="o">=</span> <span class="s">'group1'</span><span class="p">)</span> <span class="k">as</span> <span class="n">group1</span><span class="p">:</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'task1'</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'task2'</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="n">t2</span> 
    
  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="n">group1</span> <span class="o">&gt;&gt;</span> <span class="n">end</span> 
</code></pre></div></div>

<h4 id="taskgroup에-데코레이터-사용">TaskGroup에 데코레이터 사용</h4>

<p>DAG에서 작업 그룹을 정의하는 또 다른 방법은 작업 그룹 데코레이터를 사용하는 것입니다. 작업 그룹 데코레이터는 Airflow 2.1 이상에서 사용할 수 있습니다. 작업 그룹 데코레이터는 다른 Airflow 데코레이터처럼 작동하며  TaskFlow API를 사용하여 작업 그룹을 정의할 수 있습니다. 작업 그룹 데코레이터를 사용해도 작업 그룹의 기능은 변경되지 않지만 DAG에서 이미 작업 그룹 데코레이터를 사용하고 있는 경우 작업 그룹의 코드 서식을 보다 일관되게 만들 수 있습니다.</p>

<p>데코레이터를 사용하려면  작업 그룹에 들어가야 하는 작업의 함수를 호출하는 Python 함수 앞에 @task_group 추가합니다. 예를 들어:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">task_group</span><span class="p">(</span><span class="n">group_id</span><span class="o">=</span><span class="s">"tasks"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_independent_tasks</span><span class="p">():</span>
    <span class="n">task_a</span><span class="p">()</span>
    <span class="n">task_b</span><span class="p">()</span>
    <span class="n">task_c</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">task_group</span><span class="p">(</span><span class="n">group_id</span><span class="o">=</span><span class="s">"tasks"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_dependent_tasks</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">task_a</span><span class="p">(</span><span class="n">task_b</span><span class="p">(</span><span class="n">task_c</span><span class="p">()))</span>
</code></pre></div></div>

<p>이 함수는 DAG의 다른 위치에 정의된 세 개의 독립적인 작업이 있는 작업 그룹을 만듭니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">task_group</span><span class="p">,</span> <span class="n">task</span>
<span class="c1"># Utils 
</span><span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> 
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span> <span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'taskgroup-decorator'</span><span class="p">,</span>
  <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="o">@</span><span class="n">task</span>
  <span class="k">def</span> <span class="nf">start</span><span class="p">():</span>
    <span class="k">pass</span>
  
  <span class="o">@</span><span class="n">task</span>
  <span class="k">def</span> <span class="nf">end</span><span class="p">():</span>
    <span class="k">pass</span>

  <span class="o">@</span><span class="n">task_group</span><span class="p">(</span><span class="n">group_id</span> <span class="o">=</span> <span class="s">'group1'</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">func_group</span><span class="p">():</span>
    <span class="o">@</span><span class="n">task</span>
    <span class="k">def</span> <span class="nf">task1</span><span class="p">():</span>
      <span class="k">pass</span>
  
    <span class="o">@</span><span class="n">task</span>
    <span class="k">def</span> <span class="nf">task2</span><span class="p">():</span>
      <span class="k">pass</span> 
    <span class="n">task1</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">task2</span><span class="p">()</span>
  <span class="n">group1</span> <span class="o">=</span> <span class="n">func_group</span><span class="p">()</span>  
  <span class="n">start</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">group1</span> <span class="o">&gt;&gt;</span> <span class="n">end</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="inner-taskgroup-decorator">inner taskgroup decorator</h4>

<p>좀더 복잡한 Inner TaskGroup 입니다.</p>

<p><img src="https://airflow.apache.org/docs/apache-airflow/stable/_images/task_group.gif" alt="taskgroup decorator" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span>
<span class="kn">from</span> <span class="nn">airflow.decorators</span> <span class="kn">import</span> <span class="n">task_group</span><span class="p">,</span> <span class="n">task</span>
<span class="c1"># Utils 
</span><span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> 
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span> <span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'taskgroup-decorator2'</span><span class="p">,</span>
  <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="o">@</span><span class="n">task</span>
  <span class="k">def</span> <span class="nf">start</span><span class="p">():</span>
    <span class="k">pass</span>
  
  <span class="o">@</span><span class="n">task</span>
  <span class="k">def</span> <span class="nf">end</span><span class="p">():</span>
    <span class="k">pass</span>

  <span class="o">@</span><span class="n">task_group</span><span class="p">(</span><span class="n">group_id</span> <span class="o">=</span> <span class="s">'section_1'</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">func_group1</span><span class="p">():</span>
    <span class="o">@</span><span class="n">task</span>
    <span class="k">def</span> <span class="nf">task_1</span><span class="p">():</span>
      <span class="k">pass</span>
  
    <span class="o">@</span><span class="n">task</span>
    <span class="k">def</span> <span class="nf">task_2</span><span class="p">():</span>
      <span class="k">pass</span> 

    <span class="o">@</span><span class="n">task</span>
    <span class="k">def</span> <span class="nf">task_3</span><span class="p">():</span>
      <span class="k">pass</span> 
    <span class="n">task_1</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="n">task_2</span><span class="p">(),</span> <span class="n">task_3</span><span class="p">()]</span>
    
  <span class="o">@</span><span class="n">task_group</span><span class="p">(</span><span class="n">group_id</span> <span class="o">=</span> <span class="s">'section_2'</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">func_group2</span><span class="p">():</span>
    <span class="o">@</span><span class="n">task</span>
    <span class="k">def</span> <span class="nf">task_1</span><span class="p">():</span>
      <span class="k">print</span><span class="p">(</span><span class="s">'task1 of group2'</span><span class="p">)</span>

    <span class="o">@</span><span class="n">task_group</span><span class="p">(</span><span class="n">group_id</span> <span class="o">=</span> <span class="s">'inner_section_2'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">func_inner_group2</span><span class="p">():</span>
      
      <span class="n">task2</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'task_2'</span><span class="p">)</span>
      <span class="n">task3</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'task_3'</span><span class="p">)</span>
      <span class="n">task4</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'task_4'</span><span class="p">)</span>
      
      <span class="k">return</span> <span class="p">[</span><span class="n">task2</span><span class="p">,</span><span class="n">task3</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">task4</span>

    <span class="n">inner_section_2</span> <span class="o">=</span> <span class="n">func_inner_group2</span><span class="p">()</span>
    <span class="n">task_1</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">inner_section_2</span>
    
  <span class="n">section_1</span> <span class="o">=</span> <span class="n">func_group1</span><span class="p">()</span>  
  <span class="n">section_2</span> <span class="o">=</span> <span class="n">func_group2</span><span class="p">()</span> 
  <span class="n">start</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">section_1</span> <span class="o">&gt;&gt;</span> <span class="n">section_2</span> <span class="o">&gt;&gt;</span> <span class="n">end</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow,TaskGroup" /><summary type="html"><![CDATA[Airflow TaskGroup 작업 그룹은 그래프 보기에서 작업을 계층적 그룹으로 구성하는 데 사용할 수 있습니다. 반복되는 패턴을 만들고 시각적 혼란을 줄이는 데 유용합니다..]]></summary></entry><entry><title type="html">Airflow Sensor</title><link href="http://localhost:4000/workflow/Airflow-Sensor/" rel="alternate" type="text/html" title="Airflow Sensor" /><published>2022-12-18T00:00:00+09:00</published><updated>2022-12-18T00:00:00+09:00</updated><id>http://localhost:4000/workflow/Airflow%20Sensor</id><content type="html" xml:base="http://localhost:4000/workflow/Airflow-Sensor/"><![CDATA[<h2 id="airflow-sensor">Airflow Sensor</h2>
<p>센서는 정확히 한 가지 일을 하도록 설계된 특별한 유형의 오퍼레이터입니다  - 무언가가 발생할 때까지 기다립니다. 시간 기반이거나 파일 또는 외부 이벤트를 기다리는 것일 수 있지만 어떤 일이 발생할 때까지 기다렸다가 해당조건을 만족하면  다운스트림 작업(이후 Task)을 실행할 수 있습니다.</p>

<p><a href="https://airflow.apache.org/docs/apache-airflow/2.2.3/_api/airflow/sensors/index.html">https://airflow.apache.org/docs/apache-airflow/2.2.3/_api/airflow/sensors/index.html</a></p>

<p>Sensor Task는 주기적으로 체크하면 다음 단계로 진행하지 못하고 대기모드로 유지되기 때문에 Airflow DAG에서의 Sensor는 Worker의 슬롯 한 개를 점유합니다. Sensor는 BaseSensorOperator를 상속하여 구현합니다. BaseSensorOperator는 다음의 옵션을 지원합니다.</p>

<table>
  <thead>
    <tr>
      <th>구분</th>
      <th>타입</th>
      <th>기본값</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>poke_interval</td>
      <td>float</td>
      <td>60</td>
      <td>조건 확인을 위한 재시도 주기이며 단위는 second</td>
    </tr>
    <tr>
      <td>timeout</td>
      <td>float</td>
      <td>60 * 60 * 24 * 7</td>
      <td>Sesnor의 조건 확인을 위해 대기하는 시간이며 단위는 Second</td>
    </tr>
    <tr>
      <td>mode</td>
      <td>str</td>
      <td>“poke”</td>
      <td>poke는 특정 조건을 만족할 때까지 worker 슬롯 점유 <br /> reschedule은 조건을 확인할때만 worker 슬롯 점유</td>
    </tr>
  </tbody>
</table>

<p>Sensor의 유형 중에 대표적인 Sensor는</p>

<ul>
  <li>FileSensor</li>
</ul>

<p>이며 그외 다음과 같은 Sensor들이 있습니다.</p>

<table>
  <thead>
    <tr>
      <th>구분</th>
      <th>모듈 경로</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BaseSensor</td>
      <td>airflow.sensors.bash</td>
      <td>조건 확인의 재시도 주기이며 단위는 Second</td>
    </tr>
    <tr>
      <td>DatetimeSensor<br />DateTimeSensorAsync</td>
      <td>airflow.sensors.date_time</td>
      <td>Sensor의 조건 확인 대기 시간이며 단위 Second</td>
    </tr>
    <tr>
      <td>ExternalTaskSensor</td>
      <td>airflow.sensors.external_task</td>
      <td>다른 DAG의 Task가 종료까지 대기하면서 모니터링하는 DAG의 external Task가 종료되면 ExternalTaskSensor가 실행</td>
    </tr>
  </tbody>
</table>

<h4 id="filesensor-예시">FileSensor 예시</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span>
<span class="kn">from</span> <span class="nn">airflow.sensors.filesystem</span> <span class="kn">import</span> <span class="n">FileSensor</span> 
<span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>  

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span> <span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> 
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span> <span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span><span class="s">'filesensor'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span> 
  <span class="n">schedule_interval</span><span class="o">=</span><span class="s">'@daily'</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'start'</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'end'</span><span class="p">)</span>
  
  <span class="n">sensor_task</span> <span class="o">=</span> <span class="n">FileSensor</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'file_sensor_task'</span><span class="p">,</span> 
    <span class="n">poke_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">fs_conn_id</span><span class="o">=</span><span class="s">'file-conn'</span><span class="p">,</span>
    <span class="n">filepath</span><span class="o">=</span><span class="s">'/opt/airflow/data/test1.csv'</span>
  <span class="p">)</span>
  
  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="n">sensor_task</span> <span class="o">&gt;&gt;</span> <span class="n">end</span> 
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Sensor 센서는 정확히 한 가지 일을 하도록 설계된 특별한 유형의 오퍼레이터입니다 - 무언가가 발생할 때까지 기다립니다. 시간 기반이거나 파일 또는 외부 이벤트를 기다리는 것일 수 있지만 어떤 일이 발생할 때까지 기다렸다가 해당조건을 만족하면 다운스트림 작업(이후 Task)을 실행할 수 있습니다.]]></summary></entry><entry><title type="html">Setup Apache Airflow on Docker</title><link href="http://localhost:4000/workflow/setup-apache-airflow-on-docker/" rel="alternate" type="text/html" title="Setup Apache Airflow on Docker" /><published>2022-12-18T00:00:00+09:00</published><updated>2022-12-18T00:00:00+09:00</updated><id>http://localhost:4000/workflow/setup%20apache%20airflow%20on-docker</id><content type="html" xml:base="http://localhost:4000/workflow/setup-apache-airflow-on-docker/"><![CDATA[<h2 id="setup-apache-airflow-on-docker">Setup Apache Airflow on Docker</h2>
<p>Apache Airflow를 실습하기 위해서 개발환경을 구성하기 위해 docker를 이용합니다.</p>

<p>laptop 이나 Server에 직접 설치하거나 방법도 있으나 학습의 목적으로 쉽고 이곳 저곳 설치하는 것 없이
docker를 이용하면 편리합니다.</p>

<ul>
  <li>docker 환경 구성</li>
  <li>docker-compose 설치</li>
  <li>airflow docker-compose.yaml 파일 downalod 및 환경 구성</li>
</ul>

<p>docker 환경구성을 위해 기본에는 Docker Desktop을 사용했으나 라이선스 이슈로 대체 솔루션을 구성해서 사용하고 있습니다.
그중에 rancher desktop을 추천합니다. docker 와 docker-compose를 기존과 동일하게 사용이 가능하는 장점이 있습니다.</p>

<p>Rancher Desktop은 아래 링크에서 자신의 laptop 환경에 맞는 것을 설치하시면 됩니다.</p>

<p><a href="https://rancherdesktop.io/">https://rancherdesktop.io/</a></p>

<p>Rancher Desktop을 설치하고 시작하고, 다음과 같이 설정해서 Docker Destop에서 사용했던 것 같이 동일하게 사용할 수 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/11-rancher-desktop.png" alt="" />
  <figcaption></figcaption>
</figure>

<h2 id="docker-composeyaml-다운로드">docker-compose.yaml 다운로드</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LfO</span> <span class="s1">'https://airflow.apache.org/docs/apache-airflow/2.5.0/docker-compose.yaml'</span>
</code></pre></div></div>

<h2 id="환경구성">환경구성</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> ./dags ./logs ./plugins
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"AIRFLOW_UID=</span><span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span><span class="s2">"</span> <span class="o">&gt;</span> .env
</code></pre></div></div>

<h2 id="initialize-the-database">Initialize the database</h2>

<p>Airflow example을 원하지 않는 경우 docker-compose.yaml 파일의 airflow-common의 AIRFLOW__CORE__LOAD_EXAMPLES: ‘false’ 추가합니다.</p>

<pre><code class="language-YAML">  environment:
      :
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
</code></pre>

<p>모든 운영 체제에서 데이터베이스 마이그레이션을 실행하고 첫 번째 사용자 계정을 만들어야합니다.이</p>

<p>다음과 같이 실행하십시오</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker compose up airflow-init
</code></pre></div></div>

<p>초기화가 완료되면 이와 같은 메시지가 표시됩니다</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow-init_1       | Upgrades <span class="k">done
</span>airflow-init_1       | Admin user airflow created
airflow-init_1       | 2.5.0
start_airflow-init_1 exited with code 0
</code></pre></div></div>
<h2 id="airflow-시작">Airflow 시작</h2>

<p>이제 모든 서비스를 시작하기 위해 다음과 같이 수행합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># foreground 로 수행</span>
docker-compose up

<span class="c"># 또는 </span>
<span class="c"># background 로 수행</span>

docker-compose up <span class="nt">-d</span>
</code></pre></div></div>

<h2 id="localhost8080-으로-접속">localhost:8080 으로 접속</h2>

<p><a href="http://localhost:8080">http://localhost:8080</a>으로 접속하여 default admin 계정/비밀번호 인 airflow/airflow로 접속합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Setup Apache Airflow on Docker Apache Airflow를 실습하기 위해서 개발환경을 구성하기 위해 docker를 이용합니다.]]></summary></entry><entry><title type="html">Airflow Operator</title><link href="http://localhost:4000/workflow/Airflow-operators/" rel="alternate" type="text/html" title="Airflow Operator" /><published>2022-12-17T00:00:00+09:00</published><updated>2022-12-17T00:00:00+09:00</updated><id>http://localhost:4000/workflow/Airflow%20operators</id><content type="html" xml:base="http://localhost:4000/workflow/Airflow-operators/"><![CDATA[<h2 id="airflow-operator">Airflow Operator</h2>
<p>DAG을 구성하는 작업을 Task라고 하며, DAG이 수행할 작업을 의미합니다. 한개 이상의 Task를 pipeline으로 연결해서 하나의 DAG을 완성해야 합니다.
Task에는</p>

<ul>
  <li>Operator</li>
  <li>Sensor</li>
  <li>Hook</li>
</ul>

<p>가 있습니다.<br />
Operator에서는 대표적인. Bash, Python, Empty 또는 이전버전 Dummy Operator가 있습니다. 
상세한 Operator 정보는 다음의 <a href="https://airflow.apache.org/docs/apache-airflow/2.2.3/operators-and-hooks-ref.html">링크</a>를 참고하세요</p>

<p><a href="https://airflow.apache.org/docs/apache-airflow/2.2.3/operators-and-hooks-ref.html">https://airflow.apache.org/docs/apache-airflow/2.2.3/operators-and-hooks-ref.html</a></p>

<p>Operator는</p>

<ul>
  <li>Action Operator</li>
  <li>Transfer Operator</li>
  <li>Sensor Operator</li>
</ul>

<p>로 구분됩니다. <br />
Action Operator 는 작업을 수행하거나 다른 작업을 수행하도록 trigger합니다.<br />
Transfer Operator는 특정 시스템에 다른 시스템으로 데이터를 이동합니다.<br />
Sensor Operator는 특정 조건에 일치할 때 까지 기다렸다가, 만족되면 이후 과정을 진행하도록 기다려는 Operator.</p>

<p>여기에서는 대표적인 Operator 를 알아보겠습니다.</p>
<ul>
  <li>EmptyOperator</li>
  <li>BashOperator</li>
  <li>PythonOperator</li>
</ul>

<p>기외 주요 Operator는 다음과 같습니다.</p>

<table>
  <thead>
    <tr>
      <th>구분</th>
      <th>클래스 경로</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BranchPythonOperator</td>
      <td>airflow.operators.branch</td>
      <td>파이션 실행결과에 따른 분기를 설정하는 Operator</td>
    </tr>
    <tr>
      <td>TriggerDagRunOperator</td>
      <td>airflow.operators.trigger_dagrun</td>
      <td>지정한 dag을 실행</td>
    </tr>
    <tr>
      <td>ShortCircuitOperator</td>
      <td>airflow.operators.python</td>
      <td>bool 조건에 맞을 때만 실행 <br /> bool 연산 로직은 python_callable로 전달</td>
    </tr>
    <tr>
      <td>EmailOperator</td>
      <td>airflow.operators.email</td>
      <td>이메일 전송</td>
    </tr>
  </tbody>
</table>

<p>그외 operator들은 다음의 <a href="https://airflow.apache.org/docs/apache-airflow/2.2.3/_api/airflow/operators/index.html">링크</a> 참고합니다.</p>

<p><a href="https://airflow.apache.org/docs/apache-airflow/2.2.3/_api/airflow/operators/index.html">https://airflow.apache.org/docs/apache-airflow/2.2.3/_api/airflow/operators/index.html</a></p>

<p>Bash Operator 예제</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>  
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'bash-op'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="s">'training'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span>
    <span class="n">task_id</span> <span class="o">=</span> <span class="s">'start'</span>
  <span class="p">)</span>
  
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span>
    <span class="n">task_id</span> <span class="o">=</span> <span class="s">'end'</span>
  <span class="p">)</span>
  
  <span class="n">bash_task</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"test_bash"</span><span class="p">,</span>
    <span class="n">bash_command</span> <span class="o">=</span> <span class="s">"echo 'This is the ds: </span><span class="se">\'</span><span class="s">$msg</span><span class="se">\'</span><span class="s">'"</span><span class="p">,</span>
    <span class="n">env</span> <span class="o">=</span> <span class="p">{</span> <span class="s">"msg"</span><span class="p">:</span> <span class="s">''</span><span class="p">}</span>
  <span class="p">)</span>
  
  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="n">bash_task</span> <span class="o">&gt;&gt;</span> <span class="n">end</span> 
</code></pre></div></div>

<p>Python Operator 예제</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span>  <span class="n">PythonOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span>

<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 

<span class="kn">import</span> <span class="nn">time</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'tags'</span><span class="p">:</span> <span class="p">[</span><span class="s">'training'</span><span class="p">],</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">_sleep_func</span><span class="p">(</span><span class="n">sleep_time</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">'Start sleep {sleep_time} seconds'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">sleep_time</span> <span class="o">=</span> <span class="n">sleep_time</span><span class="p">))</span>
  <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">sleep_time</span><span class="p">)</span> 

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'python-op'</span><span class="p">,</span>
  <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
  <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="s">'training'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span> <span class="p">:</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'start_task'</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'end_task'</span><span class="p">)</span>
  
  <span class="n">task1</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span> <span class="o">=</span> <span class="s">'python_callable_task1'</span><span class="p">,</span>
    <span class="n">python_callable</span> <span class="o">=</span> <span class="n">_sleep_func</span><span class="p">,</span>
    <span class="n">op_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">"sleep_time"</span> <span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
  <span class="p">)</span>
  
  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="n">task1</span> <span class="o">&gt;&gt;</span> <span class="n">end</span>  
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Operator DAG을 구성하는 작업을 Task라고 하며, DAG이 수행할 작업을 의미합니다. 한개 이상의 Task를 pipeline으로 연결해서 하나의 DAG을 완성해야 합니다. Task에는]]></summary></entry><entry><title type="html">Airflow Hooks</title><link href="http://localhost:4000/workflow/Airflow-hooks/" rel="alternate" type="text/html" title="Airflow Hooks" /><published>2022-12-17T00:00:00+09:00</published><updated>2022-12-17T00:00:00+09:00</updated><id>http://localhost:4000/workflow/Airflow%20hooks</id><content type="html" xml:base="http://localhost:4000/workflow/Airflow-hooks/"><![CDATA[<h2 id="airflow-hooks">Airflow Hooks</h2>
<p>Hook은 DB나 서비스 같은 외부 시스템(Database, Storage)과 통신하기 위한 인터페이스를 제공하여 연결상태를 유지하여 작업을 처리하기 위해 사용합니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/09-hooks-component-arch.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>Apache Airflow의 Hook에서csv to db를 또는 db to csv 작업을 할 때 대표적인 Hook은 다음과 같은 것이 있습니다.</p>

<ul>
  <li>PostgresHook</li>
  <li>MySqlHook</li>
  <li>S3</li>
  <li>HDFS</li>
</ul>

<h2 id="apache-airflow-hooks를-실행하는-방법">Apache Airflow Hooks를 실행하는 방법?</h2>

<p>Airflow Hook을 다음의 4단계로 작성합니다 .</p>

<ul>
  <li>Prepare your PostgreSQL Environment</li>
  <li>Create a CSV file using the format</li>
  <li>PostgreSQL 연결 설정 정보 작성</li>
  <li>Airflow PostgresHook DAG 작성</li>
</ul>

<p>Airflow가 제공 한 PostgreSQL Hooks를 사용하여 테이블의 내용을 CSV 파일로 추출합니다.</p>

<p>우선 PostgreSQL에서 테이블을 만들고 일부 데이터를 로드 합니다. 이렇게 하려면 PSQL 쉘로 가서 아래 명령을 실행합니다.</p>

<p>그리고 PostgresHook을 처리하는 DAG을 작성합니다.</p>

<h4 id="prepare-your-postgresql-environment">Prepare your PostgreSQL Environment</h4>

<p>우선 PostgreSQL에서 테이블을 만들고 일부 데이터를로드 해야합니다. 이렇게 하려면 PSQL 쉘에서  아래 명령을 실행합니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">customer</span><span class="p">(</span>
  <span class="n">id</span> <span class="nb">serial</span><span class="p">,</span>
  <span class="n">first_name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
  <span class="n">last_name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
  <span class="n">email</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="p">);</span>
</code></pre></div></div>

<p>여기에서는 4 개의 열 ID, First_Name, Last_name 및 email 이 있는 고객 테이블을 작성하고 있습니다</p>

<h4 id="create-a-csv-file-using-the-format">Create a CSV file using the format</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>serial,first_name,last_name,email
1,john,michael,john@gmail.com
2,mary,cooper,mcooper@gmail.com
3,sheldon,cooper,scopper@gmail.com
4,john,michael,john@gmail.com
5,mary,cooper,mcooper@gmail.com
6,sheldon,cooper,scopper@gmail.com
</code></pre></div></div>

<p>COPY CSV to POD into customer table</p>

<p>Kubernetes 환경인 경우 다음과 같이 customer.csv파일을 복사합니다.
POD에 customer.csv 파일을 복사합니다.</p>

<ul>
  <li>POSTGRES_POD=$(kubectl get pods -o jsonpath=’{.items[0].metadata.name}’)</li>
  <li>kubectl cp customer.csv $POSTGRES_POD:/tmp</li>
  <li>kubectl exec -it $POSTGRESPOD – bash</li>
</ul>

<p>postgres에 접속합니다.</p>

<p>psql -U postgres</p>

<p>COPY customer FROM ‘/tmp/customer.csv’ DELIMITER ‘,’ CSV HEADER;</p>

<h4 id="postgresql-연결-설정-정보-작성">PostgreSQL 연결 설정 정보 작성</h4>

<p>Airflow UI에서 Admin &gt; Connections 메뉴를 선택하고, Connection Type이 Postgres를 선택하고 Postgres 접속정보를 입력하고 저장합니다.</p>

<table>
  <thead>
    <tr>
      <th>Key</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Connection Type :</td>
      <td>Postgres</td>
    </tr>
    <tr>
      <td>Host</td>
      <td>ip address</td>
    </tr>
    <tr>
      <td>Schema</td>
      <td>database</td>
    </tr>
    <tr>
      <td>Login</td>
      <td>postgres account</td>
    </tr>
    <tr>
      <td>Password</td>
      <td>postgres password</td>
    </tr>
    <tr>
      <td>Port</td>
      <td>postgres port</td>
    </tr>
  </tbody>
</table>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/09-hooks-postgres-conn.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="airflow-postgreshook-dag-작성">Airflow PostgresHook DAG 작성</h4>

<p>PostgresHook을 다음과 같이 구현하고 테스트합니다</p>

<p>성공적으로 실행되면 파일 저장을 위해 구성된 디렉토리로 이동하면 출력 CSV 파일을 찾을 수 있습니다</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span>
<span class="kn">from</span> <span class="nn">airflow.providers.postgres.hooks.postgres</span> <span class="kn">import</span> <span class="n">PostgresHook</span> 

<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 

<span class="kn">import</span> <span class="nn">logging</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="n">POSTGRES_CONN_ID</span> <span class="o">=</span><span class="s">'postgres-conn'</span>

<span class="k">def</span> <span class="nf">export_db_to_csv</span><span class="p">(</span><span class="n">sql</span><span class="p">):</span>
  <span class="n">pg_hook</span> <span class="o">=</span> <span class="n">PostgresHook</span><span class="p">.</span><span class="n">get_hook</span><span class="p">(</span><span class="n">POSTGRES_CONN_ID</span><span class="p">)</span>
  <span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">'Exporting query to file:{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">sql</span><span class="p">))</span>
  <span class="n">pg_hook</span><span class="p">.</span><span class="n">copy_expert</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">'/opt/airflow/data/customer.csv'</span><span class="p">)</span>
  
<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'postgres-hook-db-to-csv'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s">'training'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'start'</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'end'</span><span class="p">)</span> 
  <span class="n">export_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span> <span class="o">=</span> <span class="s">'export-task'</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">export_db_to_csv</span><span class="p">,</span>
    <span class="n">op_kwargs</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s">'sql'</span><span class="p">:</span> <span class="s">"COPY (SELECT * FROM CUSTOMER WHERE first_name = 'john' ) TO STDOUT WITH CSV HEADER"</span>
    <span class="p">}</span>
  <span class="p">)</span>
  
  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="n">export_task</span> <span class="o">&gt;&gt;</span> <span class="n">end</span> 
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Hooks Hook은 DB나 서비스 같은 외부 시스템(Database, Storage)과 통신하기 위한 인터페이스를 제공하여 연결상태를 유지하여 작업을 처리하기 위해 사용합니다.]]></summary></entry></feed>