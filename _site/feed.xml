<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-11-27T13:27:51+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Cloud Native Journey</title><subtitle>Software Engineer/Architect</subtitle><author><name>Jaeguk Yun</name></author><entry><title type="html">Install local storage class to kubernetes</title><link href="http://localhost:4000/kubernetes/local-storage-class-on-ks/" rel="alternate" type="text/html" title="Install local storage class to kubernetes" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/kubernetes/local-storage-class-on-ks</id><content type="html" xml:base="http://localhost:4000/kubernetes/local-storage-class-on-ks/"><![CDATA[<p>kubernetes 에서 storage class가 없는 경우 실습을 목적으로 
local-storage를 설치하여 실습을 목적으로 하는 경우 사용해 볼 수 있는 provisioner 입니다로</p>
<h2 id="install-local-storage-class-to-kubernetes">Install local-storage-class to kubernetes</h2>
<p>Kubernetes에 local-storage 를 사용하고자 하는 경우 다음의 설정을 하면 storage class를 사용할 수 있습니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Namespace</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-role</span>
<span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">nodes"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">persistentvolumeclaims"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">configmaps"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">get"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">list"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">watch"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">endpoints"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">persistentvolumes"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">pods"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">*"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">events"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">create"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">patch"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">storage.k8s.io"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">storageclasses"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">get"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">list"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">watch"</span> <span class="pi">]</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRoleBinding</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-bind</span>
<span class="na">roleRef</span><span class="pi">:</span>
  <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-role</span>
<span class="na">subjects</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
    <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">serviceAccountName</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">rancher/local-path-provisioner:v0.0.22</span>
          <span class="na">imagePullPolicy</span><span class="pi">:</span> <span class="s">IfNotPresent</span>
          <span class="na">command</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="s">local-path-provisioner</span>
            <span class="pi">-</span> <span class="s">--debug</span>
            <span class="pi">-</span> <span class="s">start</span>
            <span class="pi">-</span> <span class="s">--config</span>
            <span class="pi">-</span> <span class="s">/etc/config/config.json</span>
          <span class="na">volumeMounts</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-volume</span>
              <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/etc/config/</span>
          <span class="na">env</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">POD_NAMESPACE</span>
              <span class="na">valueFrom</span><span class="pi">:</span>
                <span class="na">fieldRef</span><span class="pi">:</span>
                  <span class="na">fieldPath</span><span class="pi">:</span> <span class="s">metadata.namespace</span>
      <span class="na">volumes</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-volume</span>
          <span class="na">configMap</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-config</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">standard</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">rancher.io/local-path</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">WaitForFirstConsumer</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>

<span class="nn">---</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-config</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">config.json</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">{</span>
            <span class="s">"nodePathMap":[</span>
            <span class="s">{</span>
                    <span class="s">"node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",</span>
                    <span class="s">"paths":["/opt/local-path-provisioner"]</span>
            <span class="s">}</span>
            <span class="s">]</span>
    <span class="s">}</span>
  <span class="na">setup</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">#!/bin/sh</span>
    <span class="s">set -eu</span>
    <span class="s">mkdir -m 0777 -p "$VOL_DIR"</span>
  <span class="na">teardown</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">#!/bin/sh</span>
    <span class="s">set -eu</span>
    <span class="s">rm -rf "$VOL_DIR"</span>
  <span class="na">helperPod.yaml</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">apiVersion: v1</span>
    <span class="s">kind: Pod</span>
    <span class="s">metadata:</span>
      <span class="s">name: helper-pod</span>
    <span class="s">spec:</span>
      <span class="s">containers:</span>
      <span class="s">- name: helper-pod</span>
        <span class="s">image: busybox</span>
        <span class="s">imagePullPolicy: IfNotPresent</span>
</code></pre></div></div>

<ul>
  <li>test-pod 배포</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">test-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">test-pod</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nfs-pvc</span>
        <span class="na">mountPath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/mydata"</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nfs-pvc</span>
      <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
        <span class="na">claimName</span><span class="pi">:</span> <span class="s">my-pvc</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-pvc</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">standard</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">128Mi</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="kubernetes" /><category term="kubernetes" /><category term="storageclass" /><summary type="html"><![CDATA[kubernetes 에서 storage class가 없는 경우 실습을 목적으로 local-storage를 설치하여 실습을 목적으로 하는 경우 사용해 볼 수 있는 provisioner 입니다로 Install local-storage-class to kubernetes Kubernetes에 local-storage 를 사용하고자 하는 경우 다음의 설정을 하면 storage class를 사용할 수 있습니다.]]></summary></entry><entry><title type="html">Airflow DAG 선언 유형</title><link href="http://localhost:4000/workflow/dag-type/" rel="alternate" type="text/html" title="Airflow DAG 선언 유형" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/dag-type</id><content type="html" xml:base="http://localhost:4000/workflow/dag-type/"><![CDATA[<h2 id="install-local-storage-class-to-kubernetes">Install local-storage-class to kubernetes</h2>
<p>Apache Airflow에서 DAG을 선언하는 다음과 같이 3가 유형이 있습니다.</p>

<ul>
  <li>with DAG</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">DAG</span> <span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="err">”</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span>
       <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
       <span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span>
       <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">op</span> <span class="o">=</span> <span class="n">DummyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="err">”</span><span class="n">dummy</span><span class="err">”</span><span class="p">)</span>

</code></pre></div></div>

<ul>
  <li>표준 생성자 유형</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dag</span><span class="o">=</span><span class="n">DAG</span> <span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="err">”</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span>
       <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
       <span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span>
       <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> 
<span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="err">”</span><span class="n">start</span><span class="err">”</span><span class="p">,</span> <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span>

</code></pre></div></div>

<ul>
  <li>데코레이터 유형(@)</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@dag (
    dag_id='data_pipeline_ex05',
       default_args = default_args,
       schedule_interval='@daily'
) 
def hello_dag():
    @task
    def hello_task1():
        print('Hello World')

    hello_task1()

# DAG 호출
dag = hello_dag()

</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Install local-storage-class to kubernetes Apache Airflow에서 DAG을 선언하는 다음과 같이 3가 유형이 있습니다.]]></summary></entry><entry><title type="html">Airflow task</title><link href="http://localhost:4000/workflow/tasks/" rel="alternate" type="text/html" title="Airflow task" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/tasks</id><content type="html" xml:base="http://localhost:4000/workflow/tasks/"><![CDATA[<h2 id="airflow-task">Airflow Task</h2>
<p>Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다.
Task는</p>

<ul>
  <li>Operator : 지정한 작읍을 수행하는 Operator</li>
  <li>Sensor : 어떤 조건이 만족하는지 주기적으로 스캔이 필요할 때 사용하며 조건이 만족하는 경우 Task가 수행.</li>
  <li>Hook : DB나 서비스 같은 외부 시스템과 통신하기 위한 인터페이스를 제공하여 연결 상태를 유지
등을 사용할 수 있습니다.</li>
</ul>

<h2 id="task-instance">Task Instance</h2>

<p>DAG실행될 때 마다 Task Instance를 생성하여 Executor로 전달하여 해당작업을 실행합니다. 그리고 해당 Task Instance를 다시 Metadata로 보내서 상태를 업데이트하며, Task Instance의 작업이 남아 있으면 Executor로 다시 보내집니다. 작업이 완료가 되면 스케줄러에게 보냅니다.
Operator
Operator는 task를 어떻게 실행시킬지 정의합니다. 하나의 워크플로우안에서 한개 이상의 task를 정의할 수 있습니다. 하나의 Task가 하나의 Operator라고 할 수 있다.
Operator는 Action Operator와 Transfer Operator로 구분됩니다.</p>

<ul>
  <li>Action Operator : 작업을 수행하거나 다른 시스템에 작업을 수행하도록 trigger합니다.</li>
  <li>Transfer Operator : 특정 시스템에 다른 시스템으로 데이터를 이동</li>
  <li>Sensor Operator : 특정 조건에 일치할 때 까지 기다렸다가, 만족되면 이후 과정을 진행하도록 기다려는 Operator.</li>
</ul>

<p>Airflow는 기본 Operator는 Bash와 Python Operator가 대표적이며 그외 많은 Operator를 지원하고 있습니다. Operator에 공통적으로 **kwargs라는 keywoard Arguments를 전달하는 부분이 있으며, DAG을 정의할 때 default_args 전달하는 것처럼 전달합니다.</p>

<h2 id="task-dependencies">Task Dependencies</h2>
<p>Apache Airflow의 DAG 내에 task들의 dependency를 설정함으로써 task 실행 순서와 병렬 실행 task들 등을 정의할 수 있습니다.
Task 간 의존성은 다음과 같이</p>
<ul>
  <li>set_downstream 또는 » 기호</li>
  <li>set_upstream 또는 « 기호 
같은 함수 또는 기호로 설정할 수 있습니다. 
set_downstream 는 Task 실행 후에 수행할 task를 설정
set_upstream 는 Task 실행 전에 수행할 task를 설정</li>
</ul>

<p>예시)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>

<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">dedent</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="s">'data_pipeline_ex09'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">description</span><span class="o">=</span><span class="s">'Hello world'</span><span class="p">,</span>
  <span class="n">schedule_interval</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">hello</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s">'Hello!'</span><span class="p">)</span>

<span class="n">t1</span> <span class="o">=</span>  <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'echo_hello'</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo "Hi from bash operator"'</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">python_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"python_task"</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">hello</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">templated_command</span> <span class="o">=</span> <span class="n">dedent</span><span class="p">(</span>
  <span class="s">"""
  
  """</span>
<span class="p">)</span>

<span class="n">t3</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'templated'</span><span class="p">,</span>
  <span class="n">bash_command</span><span class="o">=</span><span class="n">templated_command</span><span class="p">,</span>
  <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'my_param'</span><span class="p">:</span> <span class="s">'Parameter I passed in'</span><span class="p">},</span>
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="n">t2</span> <span class="o">&gt;&gt;</span> <span class="n">t3</span>
<span class="c1"># t1.set_downstream(t2) 
# t3.set_upstream(t2)
</span></code></pre></div></div>

<p>t1, t2, t3 task가 순차적으로 실행됩니다.</p>

<p>t1.set_downstream(t2)</p>

<p>t2는 성공적으로 실행되는 t1에 의존하여 실행됩니다..
t2.set_upstream(t1)</p>

<p>비트 시프트 연산자를 사용하여 작업을 연결할 수도 있습니다.:
t1 » t2</p>

<p>그리고 비트 시프트 연산자와의 업스트림 종속성 표기:
t2 « t1</p>

<p>여러 종속성을 연결하는 것은 비트 시프트 연산자로 간결해집니다.
t1 » t2 » t3</p>

<p>작업 목록을 종속성으로 설정할 수도 있습니다. 이러한 작업은 모두 동일한 효과를 갖습니다.:
t1.set_downstream([t2, t3])
t1 » [t2, t3]
[t2, t3] « t1</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="task" /><summary type="html"><![CDATA[Airflow Task Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다. Task는]]></summary></entry><entry><title type="html">Apache Airflow - DAG</title><link href="http://localhost:4000/workflow/apache-airflow-dag/" rel="alternate" type="text/html" title="Apache Airflow - DAG" /><published>2022-11-20T00:00:00+09:00</published><updated>2022-11-20T00:00:00+09:00</updated><id>http://localhost:4000/workflow/apache-airflow-dag</id><content type="html" xml:base="http://localhost:4000/workflow/apache-airflow-dag/"><![CDATA[<h2 id="dag-directed-acyclic-graph">DAG (Directed Acyclic Graph)</h2>
<p>DAG(Directed Acyclic Graph)는 Airflow에서 실행할 작업들을 순서에 맞게 구성한 워크플로를 의미합니다.
DAG을 구성하는 태스크(Task)라고 하며, 화살표 방향으로 순차, 병렬 실행합니다.
DAG은 Python 코드로 정의하며 $AIRFLOW_HOME/dags폴더에 위치합니다.</p>

<ul>
  <li>default_args</li>
</ul>

<p>DAG에서 사용될 Attribute를 default_args로 분리하여 정의하여 DAG  파라메터로 전달합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="err">“</span><span class="n">start_date</span><span class="err">”</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="err">“</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span> 
<span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span> 
<span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span> 
<span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
</code></pre></div></div>

<ul>
  <li>catchup</li>
</ul>

<p>DAG을 생성할 때 전달하는 파라메터로써 Airflow에서는 default로 true로 설정되어 있는 옵션입니다. catchup기본 설정은 airflow.cfg 파일에 catchup_by_default값을 변경합니다. 
catchup은 DAG이 스케줄링에서 dagrun을 실행하지 못했던 것을 채우기 위한 기능으로 backfill 이라고도 합니다.</p>

<ul>
  <li>Cron Preset</li>
</ul>

<p>DAG을 실행하기 위한 스케줄링에 사용하며, DAG을 정의할때 schedule_interval인자로 전달합니다.</p>

<p><img src="/assets/images/03-cron-preset.png" alt="transparent black overlay" /></p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/04-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>예시 )</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/05-ex-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<ul>
  <li>스케줄링 간격 정의(timedelta)</li>
</ul>

<p>스케줄 간격 정의 – 빈도 기반
cron expression은 간격(빈도)마다 스케줄을 정의할 수는 없습니다. 예를 들면 DAG을 3일에 한번씩 실행하는 cron을 정의하는 것은 어렵습니다. Airflow에서는 timedelta 인스턴스를 지원하여 빈도기반 스케줄링을 정의할 수 있습니다.
예를 들면 3일마다 또는 3시간마다 실행하도록 하는 것을 timedelta 인스턴스를 활용할 수 있습니다.</p>

<h2 id="dag-runs">DAG Runs</h2>
<p>DAG Run은 Task 인스턴스들을 DAG 에 정의된 특정 execution_date에 실행하는 DAG의 인스턴스입니다. 
execution_date는 Airflow 2.2에서는 local_date로 변경되었습니다.
DAG는 Airflow 스케줄러 또는 외부 Trigger에 의해 실행될 수 있습니다. 
Execution_date가 다른 여개 개의 DAG가 동시에 실행될 수 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/06-dag-runs.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>DAG Runs를 선택하면 다음과 같이 실행 중이거나 종료된 DAG의 실행이력이 표시됩니다. CLI 명령어는 다음과 같습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow dags list
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="DAG" /><summary type="html"><![CDATA[DAG (Directed Acyclic Graph) DAG(Directed Acyclic Graph)는 Airflow에서 실행할 작업들을 순서에 맞게 구성한 워크플로를 의미합니다. DAG을 구성하는 태스크(Task)라고 하며, 화살표 방향으로 순차, 병렬 실행합니다. DAG은 Python 코드로 정의하며 $AIRFLOW_HOME/dags폴더에 위치합니다.]]></summary></entry><entry><title type="html">Apache Airflow - 개요</title><link href="http://localhost:4000/workflow/apache-airflow-overview/" rel="alternate" type="text/html" title="Apache Airflow - 개요" /><published>2022-11-20T00:00:00+09:00</published><updated>2022-11-20T00:00:00+09:00</updated><id>http://localhost:4000/workflow/apache-airflow-overview</id><content type="html" xml:base="http://localhost:4000/workflow/apache-airflow-overview/"><![CDATA[<p>Airflow는 2014년 10월 Airbnb의 Maxime Beauchemin에 의해 시작되었다. 
첫 번째 커밋부터 오픈 소스였으며 공식적으로 Airbnb GitHub에 포함되었으며 2015년 6월에 발표되었습니다. 
이 프로젝트는 2016년 3월 Apache Software Foundation의 인큐베이터 프로그램에 합류했으며 재단은 2019년 1월 Apache Airflow를 최상위 프로젝트로 발표, 현재 아파치 재단에서 관리중인 오픈소스 프로젝트입니다.</p>

<p>Airflow는</p>

<ul>
  <li>워크플로를 작성, 예약 및 모니터링하는 플랫폼이며,</li>
  <li>Workflow를 정의하고 실행,</li>
  <li>반복 된 작업을 자동화</li>
</ul>

<p>하기 위해 사용합니다.</p>

<p>각 작업들은 DAG(Directed Acycle Graph)를 통해 구조화하며, 
DAG에 연결된 화살표 방향 순서대로 작업을 실행하고, 순차/병렬 실행이 가능합니다.
Airflow는 일정 시간 단위마다 주기적으로 실행하는 스케줄링 기능을 지원합니다.
또한 Backfill 이라는 과거 특정시점부터 현재까지 작업을 처리하는 것도 지원합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="workflow" /><summary type="html"><![CDATA[Airflow는 2014년 10월 Airbnb의 Maxime Beauchemin에 의해 시작되었다. 첫 번째 커밋부터 오픈 소스였으며 공식적으로 Airbnb GitHub에 포함되었으며 2015년 6월에 발표되었습니다. 이 프로젝트는 2016년 3월 Apache Software Foundation의 인큐베이터 프로그램에 합류했으며 재단은 2019년 1월 Apache Airflow를 최상위 프로젝트로 발표, 현재 아파치 재단에서 관리중인 오픈소스 프로젝트입니다.]]></summary></entry><entry><title type="html">Apache Airflow - 구조</title><link href="http://localhost:4000/workflow/apache-airflow-structure/" rel="alternate" type="text/html" title="Apache Airflow - 구조" /><published>2022-11-20T00:00:00+09:00</published><updated>2022-11-20T00:00:00+09:00</updated><id>http://localhost:4000/workflow/apache-airflow-structure</id><content type="html" xml:base="http://localhost:4000/workflow/apache-airflow-structure/"><![CDATA[<h2 id="airflow-구조">Airflow 구조</h2>
<p>Airflow는 다음과 같은 구조를 가지고 있습니다.</p>
<ul>
  <li>Scheduler : Airflow의 DAG와 작업들을 모니터링하고 실행순서와 상태관리</li>
  <li>Worker : Airflow의 작업을 실행하는 공간</li>
  <li>Metadata database : Airflow에서 실행할 작업에 관한 정보를 저장</li>
  <li>Webserver: Airflow의 User Interface 에 해당하는 dashboard</li>
  <li>DAG Directory</li>
</ul>

<p><img src="/assets/images/01-airflow-architecture.png" alt="transparent black overlay" /></p>

<p>Airflow는 스케줄러가 DAG Directory를 주기적으로 스캔하고 새로운 DAG 파일이 생성되면 Worker에서 실행합니다.</p>

<h2 id="airflow-webserver">Airflow Webserver</h2>
<p>Webserver에 로그인하면 다음과 같이 DAG 목록이 출력됩니다.</p>
<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/02-dag-list.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>조## DAG (Directed Acyclic Graph) 
DAG(Directed Acyclic Graph)는 Airflow에서 실행할 작업들을 순서에 맞게 구성한 워크플로를 의미합니다.
DAG을 구성하는 태스크(Task)라고 하며, 화살표 방향으로 순차, 병렬 실행합니다.
DAG은 Python 코드로 정의하며 $AIRFLOW_HOME/dags폴더에 위치합니다.</p>

<ul>
  <li>default_args</li>
</ul>

<p>DAG에서 사용될 Attribute를 default_args로 분리하여 정의하여 DAG  파라메터로 전달합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="err">“</span><span class="n">start_date</span><span class="err">”</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="err">“</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span> 
<span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span> 
<span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span> 
<span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
</code></pre></div></div>

<ul>
  <li>catchup</li>
</ul>

<p>DAG을 생성할 때 전달하는 파라메터로써 Airflow에서는 default로 true로 설정되어 있는 옵션입니다. catchup기본 설정은 airflow.cfg 파일에 catchup_by_default값을 변경합니다. 
catchup은 DAG이 스케줄링에서 dagrun을 실행하지 못했던 것을 채우기 위한 기능으로 backfill 이라고도 합니다.</p>

<ul>
  <li>Cron Preset</li>
</ul>

<p>DAG을 실행하기 위한 스케줄링에 사용하며, DAG을 정의할때 schedule_interval인자로 전달합니다.</p>

<p><img src="/assets/images/03-cron-preset.png" alt="transparent black overlay" /></p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/04-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>예시 )</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/05-ex-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<ul>
  <li>스케줄링 간격 정의(timedelta)</li>
</ul>

<p>스케줄 간격 정의 – 빈도 기반
cron expression은 간격(빈도)마다 스케줄을 정의할 수는 없습니다. 예를 들면 DAG을 3일에 한번씩 실행하는 cron을 정의하는 것은 어렵습니다. Airflow에서는 timedelta 인스턴스를 지원하여 빈도기반 스케줄링을 정의할 수 있습니다.
예를 들면 3일마다 또는 3시간마다 실행하도록 하는 것을 timedelta 인스턴스를 활용할 수 있습니다.</p>

<h2 id="dag-runs">DAG Runs</h2>
<p>DAG Run은 Task 인스턴스들을 DAG 에 정의된 특정 execution_date에 실행하는 DAG의 인스턴스입니다. 
execution_date는 Airflow 2.2에서는 local_date로 변경되었습니다.
DAG는 Airflow 스케줄러 또는 외부 Trigger에 의해 실행될 수 있습니다. 
Execution_date가 다른 여개 개의 DAG가 동시에 실행될 수 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/06-dag-runs.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>DAG Runs를 선택하면 다음과 같이 실행 중이거나 종료된 DAG의 실행이력이 표시됩니다. CLI 명령어는 다음과 같습니다.
airflow dags list</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="workflow" /><summary type="html"><![CDATA[Airflow 구조 Airflow는 다음과 같은 구조를 가지고 있습니다. Scheduler : Airflow의 DAG와 작업들을 모니터링하고 실행순서와 상태관리 Worker : Airflow의 작업을 실행하는 공간 Metadata database : Airflow에서 실행할 작업에 관한 정보를 저장 Webserver: Airflow의 User Interface 에 해당하는 dashboard DAG Directory]]></summary></entry></feed>