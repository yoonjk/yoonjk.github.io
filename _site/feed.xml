<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-12-17T15:40:04+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Cloud Native Journey</title><subtitle>Software Engineer/Architect</subtitle><author><name>Jaeguk Yun</name></author><entry><title type="html">Airflow Hooks</title><link href="http://localhost:4000/workflow/Airflow-hooks/" rel="alternate" type="text/html" title="Airflow Hooks" /><published>2022-12-17T00:00:00+09:00</published><updated>2022-12-17T00:00:00+09:00</updated><id>http://localhost:4000/workflow/Airflow%20hooks</id><content type="html" xml:base="http://localhost:4000/workflow/Airflow-hooks/"><![CDATA[<h2 id="airflow-hooks">Airflow Hooks</h2>

<p>Hook은 DB나 서비스 같은 외부 시스템(Database, Storage)과 통신하기 위한 인터페이스를 제공하여 연결상태를 유지하여 작업을 처리하기 위해 사용합니다.
Apache Airflow의 Hook에서csv to db를 또는 db to csv 작업을 할 때 대표적인 Hook은 다음과 같은 것이 있습니다.</p>

<ul>
  <li>PostgresHook</li>
  <li>MySqlHook</li>
  <li>S3</li>
  <li>HDFS</li>
</ul>

<h2 id="apache-airflow-hooks를-실행하는-방법">Apache Airflow Hooks를 실행하는 방법?</h2>

<p>Airflow Hook을 다음의 4단계로 작성합니다 .</p>

<ul>
  <li>Prepare your PostgreSQL Environment</li>
  <li>Create a CSV file using the format</li>
  <li>PostgreSQL 연결 설정 정보 작성</li>
  <li>Airflow PostgresHook DAG 작성</li>
</ul>

<p>Airflow가 제공 한 PostgreSQL Hooks를 사용하여 테이블의 내용을 CSV 파일로 추출합니다.</p>

<p>우선 PostgreSQL에서 테이블을 만들고 일부 데이터를 로드 합니다. 이렇게 하려면 PSQL 쉘로 가서 아래 명령을 실행합니다.</p>

<p>그리고 PostgresHook을 처리하는 DAG을 작성합니다.</p>

<h4 id="prepare-your-postgresql-environment">Prepare your PostgreSQL Environment</h4>

<p>우선 PostgreSQL에서 테이블을 만들고 일부 데이터를로드 해야합니다. 이렇게 하려면 PSQL 쉘에서  아래 명령을 실행합니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">customer</span><span class="p">(</span>
  <span class="n">id</span> <span class="nb">serial</span><span class="p">,</span>
  <span class="n">first_name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
  <span class="n">last_name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
  <span class="n">email</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="p">);</span>
</code></pre></div></div>

<p>여기에서는 4 개의 열 ID, First_Name, Last_name 및 email 이 있는 고객 테이블을 작성하고 있습니다</p>

<h4 id="create-a-csv-file-using-the-format">Create a CSV file using the format</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>serial,first_name,last_name,email
1,john,michael,john@gmail.com
2,mary,cooper,mcooper@gmail.com
3,sheldon,cooper,scopper@gmail.com
4,john,michael,john@gmail.com
5,mary,cooper,mcooper@gmail.com
6,sheldon,cooper,scopper@gmail.com
</code></pre></div></div>

<p>COPY CSV to POD into customer table</p>

<p>POD에 customer.csv 파일을 복사합니다.</p>

<p>POSTGRES_POD=$(kubectl get pods -o jsonpath=’{.items[0].metadata.name}’)</p>

<p>kubectl cp customer.csv $POSTGRES_POD:/tmp</p>

<p>postgres에 접속합니다.</p>

<p>psql -U postgres</p>

<p>COPY customer FROM ‘/tmp/customer.csv’ DELIMITER ‘,’ CSV HEADER;</p>

<h4 id="postgresql-연결-설정-정보-작성">PostgreSQL 연결 설정 정보 작성</h4>

<p>Airflow UI에서 Admin &gt; Connections 메뉴를 선택하고, Connection Type이 Postgres를 선택하고 Postgres 접속정보를 입력하고 저장합니다.</p>

<table>
  <thead>
    <tr>
      <th>Key</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Connection Type :</td>
      <td>Postgres</td>
    </tr>
    <tr>
      <td>Host</td>
      <td>ip address</td>
    </tr>
    <tr>
      <td>Schema</td>
      <td>database</td>
    </tr>
    <tr>
      <td>Login</td>
      <td>postgres account</td>
    </tr>
    <tr>
      <td>Password</td>
      <td>postgres password</td>
    </tr>
    <tr>
      <td>Port</td>
      <td>postgres port</td>
    </tr>
  </tbody>
</table>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/09-hooks-postgres-conn.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="airflow-postgreshook-dag-작성">Airflow PostgresHook DAG 작성</h4>

<p>PostgresHook을 다음과 같이 구현하고 테스트합니다</p>

<p>성공적으로 실행되면 파일 저장을 위해 구성된 디렉토리로 이동하면 출력 CSV 파일을 찾을 수 있습니다</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span>
<span class="kn">from</span> <span class="nn">airflow.providers.postgres.hooks.postgres</span> <span class="kn">import</span> <span class="n">PostgresHook</span> 

<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 

<span class="kn">import</span> <span class="nn">logging</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="n">POSTGRES_CONN_ID</span> <span class="o">=</span><span class="s">'postgres-conn'</span>

<span class="k">def</span> <span class="nf">export_db_to_csv</span><span class="p">(</span><span class="n">sql</span><span class="p">):</span>
  <span class="n">pg_hook</span> <span class="o">=</span> <span class="n">PostgresHook</span><span class="p">.</span><span class="n">get_hook</span><span class="p">(</span><span class="n">POSTGRES_CONN_ID</span><span class="p">)</span>
  <span class="n">logging</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">'Exporting query to file:{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">sql</span><span class="p">))</span>
  <span class="n">pg_hook</span><span class="p">.</span><span class="n">copy_expert</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">'/opt/airflow/data/customer.csv'</span><span class="p">)</span>
  
<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'postgres-hook-db-to-csv'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s">'training'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'start'</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'end'</span><span class="p">)</span> 
  <span class="n">export_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span> <span class="o">=</span> <span class="s">'export-task'</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">export_db_to_csv</span><span class="p">,</span>
    <span class="n">op_kwargs</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s">'sql'</span><span class="p">:</span> <span class="s">"COPY (SELECT * FROM CUSTOMER WHERE first_name = 'john' ) TO STDOUT WITH CSV HEADER"</span>
    <span class="p">}</span>
  <span class="p">)</span>
  
  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="n">export_task</span> <span class="o">&gt;&gt;</span> <span class="n">end</span> 
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Hooks]]></summary></entry><entry><title type="html">Airflow Trigger_rules</title><link href="http://localhost:4000/workflow/trigger_rules/" rel="alternate" type="text/html" title="Airflow Trigger_rules" /><published>2022-12-15T00:00:00+09:00</published><updated>2022-12-15T00:00:00+09:00</updated><id>http://localhost:4000/workflow/trigger_rules</id><content type="html" xml:base="http://localhost:4000/workflow/trigger_rules/"><![CDATA[<h2 id="airflow-trigger-rules">Airflow Trigger rules</h2>
<p>일반적으로 Task는 이전 Task들이 성공할 때만 실행됩니다. 
trigger rule이 default로 all_success이기 때문입니다. 기본적으로 모든 상위 작업이 성공하면 작업이 실행됩니다. 이 action은 일반적으로 기대하는 것입니다.</p>

<p>그러나 더 복잡한 것을 원한다면 어떻게 해야 할까요?
상위 task 중 한 개 task가 성공하자마자 작업을 수행하고 싶다면 어떻게? 
아니면 작업이 실패하면 다른 작업 세트를 실행하고 싶습니까?
또는 작업이 성공하거나 실패하거나 이벤트가 건너 뛸 경우에 따라 다르게 action 을 해야 하는 경우?</p>

<p>좀더 복잡한 workflow는 Task간 다양한 의존성이 존재합니다. 일반적인 워크플로 동작은  모든 직접 업스트림 작업이 성공할 때 작업을 트리거하는 것이지만 Airflow는 더 복잡한 종속성 설정을 허용합니다.
이러한 다양한 의존성을 지원하기 위한 Trigger Rule들이 다음과 같이 존재합니다</p>

<p>모든 Operator 에는  생성된 작업이 트리거되는 규칙을 정의하는 trigger_rule 인수가 있습니다. trigger_rule  의 기본값은 all_success이며 “모든 직접 업스트림 작업이 성공하면 이 작업 트리거”로 정의할 수 있습니다. 여기에 설명된 다른 모든 규칙은 직접 상위 작업을 기반으로 하며 작업을 만드는 동안 모든위 Operator에게 전달할 수 있는 값입니다.</p>

<ul>
  <li>all_success: (default) 모든 상위 Task가 성공한 경우</li>
  <li>all_failed: 모든 Parent Task가 실패 또는 upstream_failed 상태일 떄 하위 Task가 실행</li>
  <li>all_done: 모든 상위 Task가 완료된 경우 하위 Task 실행.</li>
  <li>one_failed: 적어도 한 부모가 실패하자마자 모든 부모가 완료 될 때까지 기다리지 않고 실행됩니다.</li>
  <li>one_success: 적어도 한 부모가 성공하자마자 모든 부모가 완료 될 때까지 기다리지 않고 Trigger 됩니다.</li>
  <li>none_failed: 모든 상위 Task가 실패가 없는 경우(failed or upstream_failed) i.e. 모든 부모가 성공했거나 skip인 경우 하위 Task 실행.</li>
  <li>none_skipped:상위 Task의 상태가 Skip이 없는 경우 하위 Task 실행, i.e. all parents are in a success, failed, or upstream_failed state</li>
</ul>

<p>아래의 task Graph view 처럼 trigger rule이 all_success인 경우 end task는 실행되지 않고 skip하게 되는 경우도 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-none_ailed_min_one_success.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>어떤 dag은 이전 Task에 실패가 없고 최소한 한개 이상 성공한 경우end task를 항상 실행하고자 할 때 end task에 trigger rule을 none_failed_min_one_success
로 설정하면 다음과 같이 end task를 실행할 수 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-none_ailed_min_one_success.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>예시)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t1</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="err">’</span><span class="n">end</span><span class="err">’</span><span class="p">,</span> <span class="n">trigger_rule</span><span class="o">=</span><span class="err">’</span> <span class="n">none_failed_min_one_success</span><span class="err">’</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="all_success">all_success</h4>
<p>이것은 매우 간단하고 이미 보았습니다. 모든 업스트림 작업 (부모)이 성공했을 때 작업이 시작됩니다</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-all_success2.png" alt="" />
  <figcaption></figcaption>
</figure>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-all_success3.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="all_failed">all_failed</h4>
<p>모든 상위 작업이 실패하면 Task C 는 작업이 Trigger 됩니다</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-all_failed.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="all_done">all_done</h4>

<p>모든 업스트림 작업 (상위)이 자신의 상태에 관계없이 실행을 수행하면 작업을 트리거하고 합니다. 이 트리거 규칙은 업스트림 작업의 상태에 관계없이 항상 실행하려는 작업이 있는 경우 유용 할 수 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-all_done.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="none_failed">none_failed</h4>

<p>모든 업스트림 작업이 성공하거나 skip이면  Task D는 트리거 됩니다</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-none_failed.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="one_success">one_success</h4>

<p>한 명의 상위 또는 업스트림 작업이 성공하자마자 트리거됩니다. 단 모든 상위 task가 종료될 때까지 기다리지 않습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-one_success.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="one_failed">one_failed</h4>

<p>한 개의 상위 또는 업스트림 작업이 최소한 1개라도 실패하면 task D는 trigger 됩니다.단 모든 상위 task가 종료될 때까지 기다리지 않습니다</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-one_failed.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="none_failed_min_one_success">none_failed_min_one_success</h4>

<p>한 개의 상위 또는 업스트림 작업이 모두 실패가 없고 최소한 1개라도 성공하면 task D는 trigger 됩니다.단 모든 상위 task가 종료될 때까지 기다리지 않습니다</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/08-trigger-rule-none_failed_min_one_success.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>예제 )</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.empty</span> <span class="kn">import</span> <span class="n">EmptyOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">BranchPythonOperator</span> 
<span class="c1"># Utils 
</span><span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 
<span class="kn">import</span> <span class="nn">random</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> 
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">check_condition</span><span class="p">():</span>
  <span class="n">num</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">6</span><span class="p">:</span>
    <span class="k">return</span> <span class="s">'greater'</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="s">'smaller'</span>
  
<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">'trigger_rule'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="s">'training'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'start'</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'end'</span><span class="p">,</span> <span class="n">trigger_rule</span> <span class="o">=</span> <span class="s">'all_done'</span><span class="p">)</span>

  
  <span class="n">greater</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'greater'</span><span class="p">,</span> <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo "value is greater than 6" &amp;&amp; sleep 30'</span><span class="p">)</span>
  <span class="n">smaller</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span><span class="n">task_id</span> <span class="o">=</span> <span class="s">'smaller'</span><span class="p">,</span> <span class="n">bash_command</span> <span class="o">=</span><span class="s">'echo "value is smaller thant 6" &amp;&amp; exit 1'</span><span class="p">)</span>

  <span class="n">start</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="n">greater</span><span class="p">,</span> <span class="n">smaller</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">end</span> 
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Trigger rules 일반적으로 Task는 이전 Task들이 성공할 때만 실행됩니다. trigger rule이 default로 all_success이기 때문입니다. 기본적으로 모든 상위 작업이 성공하면 작업이 실행됩니다. 이 action은 일반적으로 기대하는 것입니다.]]></summary></entry><entry><title type="html">Create your first Airflow DAG</title><link href="http://localhost:4000/workflow/myfirst-dag/" rel="alternate" type="text/html" title="Create your first Airflow DAG" /><published>2022-12-14T00:00:00+09:00</published><updated>2022-12-14T00:00:00+09:00</updated><id>http://localhost:4000/workflow/myfirst-dag</id><content type="html" xml:base="http://localhost:4000/workflow/myfirst-dag/"><![CDATA[<h2 id="my-first-dag-개발">My First DAG 개발</h2>
<p>Apache Airflow Dag 개발 절차는 다음의 7단계 절차로 구현합니다.</p>

<ul>
  <li>Airflow 관련 Module import</li>
  <li>DAG Arguments 정의</li>
  <li>Python Function 또는 task 에서 사용하는 Variable 정의 (Optional)</li>
  <li>Instatiate DAG 정의</li>
  <li>Task 정의</li>
  <li>Task간 의존성 정의</li>
  <li>Verify DAG</li>
</ul>

<p>개발절차를 예제로 살펴보면 다음과 같습니다.</p>

<h4 id="1-airflow-관련-module-import">1. Airflow 관련 Module import</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
</code></pre></div></div>

<h4 id="2-dag-arguments-정의">2. DAG Arguments 정의</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="3-python-function-또는-task-에서-사용하는-variable-정의optional">3. Python Function 또는 task 에서 사용하는 Variable 정의(Optional)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hello_airflow</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Hello airflow"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="4-instantiate-dag-정의">4. Instantiate DAG 정의</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span> <span class="o">=</span> <span class="s">"myFirstDag"</span><span class="p">,</span>
  <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
  <span class="n">dags</span> <span class="o">=</span> <span class="p">[</span><span class="s">'training'</span><span class="p">]</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
</code></pre></div></div>

<h4 id="5--task-정의">5.  Task 정의</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">t1</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"bash"</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">"echo Hello airflow"</span><span class="p">,</span>
  <span class="p">)</span>
  
  <span class="n">t2</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"python"</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">hello_airflow</span><span class="p">,</span>
  <span class="p">)</span>
</code></pre></div></div>

<h4 id="6-task간-의존성-정의">6. Task간 의존성 정의</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  t1 &gt;&gt; t2
</code></pre></div></div>

<h4 id="7-verify-dag">7. Verify DAG</h4>

<p>myFirstDag을 airflow에 배포하여 dag을 테스트합니다. 
테스트 aifrlow Webserver UI에서 하거나 airflow cli를 사용하여 테스트합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[My First DAG 개발 Apache Airflow Dag 개발 절차는 다음의 7단계 절차로 구현합니다.]]></summary></entry><entry><title type="html">Airflow Best Practices - I</title><link href="http://localhost:4000/workflow/airflow-best-practices-1/" rel="alternate" type="text/html" title="Airflow Best Practices - I" /><published>2022-12-14T00:00:00+09:00</published><updated>2022-12-14T00:00:00+09:00</updated><id>http://localhost:4000/workflow/airflow%20best-practices-1</id><content type="html" xml:base="http://localhost:4000/workflow/airflow-best-practices-1/"><![CDATA[<h2 id="좀더-낳은-dag-작성">좀더 낳은 DAG 작성</h2>
<p>DAG는 데이터 파이프라인에 해당합니다. 
DAG는 매일 사용되므로 모범 사례를 따르는 것이 중요합니다.
최적화되고, 이해하기 쉽고, 문서화되고, 잘 조직되어야 합니다. 
수백 개의 DAG로 빠르게 끝날 수 있으므로이 부분을 과소 평가하지 마십시오. 
그것은 당신에게 많은 고통과 문제를 덜어 줄 것입니다.</p>

<h4 id="dag의-명확한-목적-정의">DAG의 명확한 목적 정의</h4>

<p>DAG를 만들기 전에, 당신은 당신이 그것에서 무엇을 기대하는지 생각해야합니다. 
도움이 될 수 있는 몇 가지 질문이 있습니다.</p>

<ul>
  <li>입력은 무엇입니까?</li>
  <li>무엇이 출력 될까요?</li>
  <li>언제 트리거해야합니까?</li>
  <li>어느 시간 간격으로?</li>
  <li>상호 작용할 타사 도구는 무엇입니까?</li>
  <li>작업은 무엇입니까? (매우 중요)</li>
  <li>간단하게 만들 수 있습니까?</li>
</ul>

<p>마지막 질문이 중요합니다. 
원하는 것을 달성하기 위해 DAG를 빌드해야하는지 또는 빌드 및 유지 관리가 
더 쉬운 다른 솔루션이 있는지 항상 자문 해보십시오.
데이터 파이프라인을 지나치게 복잡하게 만들지 마십시오.
DAG에는 데이터를 데이터 웨어하우스로 내보내거나 필요한 경우 프로덕션에서 
기계 학습 모델을 업데이트하는 것과 같은 명확한 목적이 있어야 합니다.</p>

<h4 id="task에-대한-명확한-목적-정의">Task에 대한 명확한 목적 정의</h4>
<p>DAG를 통해 실행하려는 작업을 명확하게 파악합니다. 
하나의 작업(task) = 여러 작업이 아닌 
하나의 작업 = 하나의 작업을 갖도록 
가능한 한 설계하십시오. 
예를 들어 보겠습니다..</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># DON'T
</span><span class="k">def</span> <span class="nf">process_data</span><span class="p">():</span>
  <span class="n">wrangling</span><span class="p">()</span>
  <span class="n">cleaning</span><span class="p">()</span>
  <span class="n">transforming</span><span class="p">()</span>
  <span class="n">validating</span><span class="p">()</span>

<span class="n">task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">"my_task"</span><span class="p">,</span>
  <span class="n">python_callable</span><span class="o">=</span><span class="n">process_data</span><span class="p">,</span>
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DO
t1 = PythonOperator(
  task_id="wrangling",
  python_callable=wrangling,
)
t2 = PythonOperator(
  task_id="cleaning",
  python_callable=cleaning,
)
t3 = PythonOperator(
  task_id="transforming",
  python_callable=transforming,
)
t4 = PythonOperator(
  task_id="validating",
  python_callable=validating,
)

</code></pre></div></div>

<p>위의 예에서 볼 수 있듯이 모든 것을 
PythonOperator에 넣고 싶지만 강력히 권장하지 않습니다. 
유효성 검사 함수가  실패하는 반면 wrangling, cleaning및 transforming은 성공한다고 가정 해 봅시다  . 하나의 기능만 실패하기 때문에 Airflow는 전체 작업을 실패로 간주합니다. 따라서 유효성 검사를 수행하는  하나의 함수만 다시 시도하는 합니다. 그러나 모든 작업을 하나의 작업에 넣을 때 모든 함수가 다시 시도됩니다.</p>

<p>그렇기 때문에</p>

<ul>
  <li>one Task = one Operator</li>
</ul>

<p>어야합니다. 무언가가 실패하면 이 부분만 다시 실행되고 다른 부분은 실행되지 않습니다. 이렇게 하면 데이터의 불일치를 방지하고 실패한 항목과 그 이유를 더 쉽게 파악할 수 있습니다.</p>

<h4 id="dag-및-컨텍스트-관리자">DAG 및 컨텍스트 관리자</h4>
<p>Python에서는 컨텍스트 관리자를 활용하여 원할 때 정확하게 리소스를 할당하고 
해제할 수 있습니다. 
가장 널리 사용되는 컨텍스트 관리자는 <strong>with</strong> 입니다.
예를 들어 보겠습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DON'T
dag = DAG("simple_pipe", default_args=default_args, schedule_interval="*/5 * * * *", catchup=False) as dag:
t1 = PythonOperator(
  task_id="t1",
  python_callable=my_func
  dag=dag
)
t2 = PythonOperator(
  task_id="t2",
  python_callable=my_func
  dag=dag
)
t3 = PythonOperator(
  task_id="t3",
  python_callable=my_func
  dag=dag
)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DO
with DAG("simple_pipe", default_args=default_args, schedule_interval="*/5 * * * *", catchup=False) as dag:
  t1 = PythonOperator(
      task_id="t1",
      python_callable=my_func
  )
  t2 = PythonOperator(
      task_id="t2",
      python_callable=my_func
  )
  t3 = PythonOperator(
      task_id="t3",
      python_callable=my_func
  )
</code></pre></div></div>

<p><strong>with</strong> 문은  각 작업에 dag 변수를 할당할 필요성을 제거하여 코드를 더 깔끔하게 만듭니다. 
이렇게하면 DAG  에 속한 작업을 명확하게 볼 수 있으며 (DAG 파일에 python 함수가있는 경우 
상황이 빠르게 지저분 해질 수 있음) 컨텍스트 관리자가 DAG 수명주기를 처리하도록합니다</p>

<h4 id="default-arguments">Default arguments</h4>

<p>Task의 생성자는 이메일, 재시도 횟수, 시작 날짜, 큐 등과 같은 다양한 인수를 허용합니다. 아래와 같이 DAG 개체 정의 바로 앞에 사전이있는 많은 DAG를 이미 보았을 것입니다</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DON'T
with DAG('dag', 
  start_date=datetime(2019, 1, 1), 
  schedule_interval='*/10 * * * *', 
  catchup=False
):
  t0 = DummyOperator(task_id='t0', retries=2, retry_delay=timedelta(minutes=5))
  t1 = DummyOperator(task_id='t1', retries=2, retry_delay=timedelta(minutes=5))
  t2 = DummyOperator(task_id='t2', retries=2, retry_delay=timedelta(minutes=5))
  t3 = DummyOperator(task_id='t3', retries=2, retry_delay=timedelta(minutes=5))
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DO
default_args = {
  'retries': 1,
  'retry_delay': timedelta(minutes=5)
}

with DAG('dag', start_date=datetime(2019, 1, 1), default_args=default_args, schedule_interval='*/10 * * * *', catchup=False):
    t0 = DummyOperator(task_id='t0')
    t1 = DummyOperator(task_id='t1')
    t2 = DummyOperator(task_id='t2')
    t3 = DummyOperator(task_id='t3')

</code></pre></div></div>

<p>일반적으로 default_args 라고 하는 
이 사전의 목적은 DAG의 모든 작업에 공통적인 매개 변수 집합을 정의하는 것입니다.
이렇게 하면 동일한 인수를 반복해서 반복하지 않아도 되므로 DAG가 더 명확해지고 오류가 발생할 가능성이 줄어듭니다. 모든 작업에 대한 사전을 사용하여 기본 인수 집합을 정의하고 한 작업에 특정 값이 필요한 경우 연산자 정의에서 해당 인수를 덮어씁니다.</p>

<h4 id="의미있는-고유-식별자-또는-dag-id-정의">의미있는 고유 식별자 또는 DAG ID 정의</h4>

<p>DAG 개체를 인스턴스화할 때 DAG ID를 지정해야  합니다.  DAG ID는 모든 DAG에서 고유해야 합니다. DAG ID가 동일한 두 개의 DAG가 있으면 안 되며, 그렇지 않으면 하나의 DAG만 표시되고 예기치 않은 동작이 발생할 수 있습니다. DAG에 대한 설명과 함께 의미 있는 DAG ID를 정의합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DON'T
with DAG(
  'dag_1', 
  start_date=datetime(2019, 1 ,1), 
  schedule_interval='*/10 * * * *')
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DO
with DAG('csv_to_datawarehouse', 
  description='Fetch data from CSV, process and load them in the data warehouse' 
  start_date=datetime(2019, 1 ,1), 
  schedule_interval='*/10 * * * *')
</code></pre></div></div>

<p>수백 개의 서로 다른 DAG가 있을 때를 생각해 보십시오. 의미 있는 DAG ID와 설명을 통해 어떤 DAG가 어떤 작업을 수행하는지 빠르게 알 수 있습니다. 한 가지 더, 여러 DAG가 서로 어느 정도 관련되어있는 경우 모든 DAG에 공통 접두사를 넣는 것이 좋습니다.</p>

<h4 id="start_date">start_date</h4>
<p>여기에 큰 주제가 있습니다. 
Airflow에서 DAG를 예약하는 방식은 처음에는 이해하기 다소 어려울 수 있습니다. 
<strong>start_date</strong> DAG가 예약되기 시작하는 날짜를 정의합니다. 
한 가지 알아야 할 것은 각 작업 또는 운영자가 다른 <strong>start_date</strong> 가질 수 있다는 것입니다. 예, 동일한 DAG 내의 작업은 다른 날짜를 시작할 수 있습니다. 나는 이것에 대해 강력히 조언합니다. 
다른 시작 날짜를 정의하지 마십시오. 
일을 단순하고 규칙적으로 정의 하십시오.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DON'T
default_args = {
  'retries': 1,
  'retry_delay': timedelta(minutes=5)
}

with DAG(
  dag_id = 'dag', 
  start_date=datetime(2019, 1, 1), 
  default_args=default_args, 
  schedule_interval='*/10 * * * *', 
  catchup=False
) as dag:

  t0 = DummyOperator(task_id='t0', start_date=datetime(2019, 1, 15))
  t1 = DummyOperator(task_id='t1', start_date=datetime(2019, 2, 16))
  t2 = DummyOperator(task_id='t2', start_date=datetime(2019, 3, 6))
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># DO
default_args = {
  'retries': 1,
  'retry_delay': timedelta(minutes=5),
  'start_date': datetime(2019, 1, 1)
}

with DAG(dag_id = 'dag', 
  default_args=default_args, 
  schedule_interval='*/10 * * * *', 
  catchup=False
) as dag:
  t0 = DummyOperator(task_id='t0')
  t1 = DummyOperator(task_id='t1')
  t2 = DummyOperator(task_id='t2')
  t3 = DummyOperator(task_id='t3')

  t0 &gt;&gt; [t1, t2] &gt;&gt; t3
</code></pre></div></div>

<p><strong>start_date</strong> 는 정적이어야 합니다. 
 혼란 스럽기 때문에 datetime.now() 와 같은 함수로 동적 시작 날짜를 정의하지 마십시오. 
 작업은 start_date + schedule_interval이 전달되면 실행됩니다. 
 시작 날짜가 now()로 설정되면 이론적으로 날짜가 지속적으로 앞으로 이동하므로 
 작업이 실행되지 않습니다.</p>

<h4 id="catchup-parameter">catchup parameter</h4>

<p>Airflow는 최근에 실행된 DAG 실행과 현재 날짜 사이에 트리거되지 않은 DAG 실행을 자동으로 실행합니다.  어떤 이유로 DAG를 일시 중지하고 지연을 따라 잡으려는 경우 매우 유용합니다. 그럼에도 불구하고 이 기능에 주의해야 합니다. 실제로 DAG의 start_date 1년 전으로 설정되어 있고 일정 간격이 10분으로 설정되어 있다고 가정해 보겠습니다. 해당 DAG 예약을 시작하면 수천 개의 DAG 실행이 동시에 실행됩니다. 이로 인해 다른 작업이 실행되지 않거나 Airflow 인스턴스 속도가 느려질 수 있습니다. 이를 방지하려면 기본적으로이 매개 변수를 False로 하는 것이 좋습니다. DAG 정의 또는 구성 파일에서 catchup 매개 변수를 False로 설정합니다</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>default_args = {
  'description': 'Fetch data from CSV, process and load them in the data warehouse',
  'start_date': datetime(2019, 1 ,1), 
  'schedule_interval' : '*/10 * * * *',
  'catchup': False
}

with DAG(
  dag_id = 'csv_to_datawarehouse', 
  default_args = default_args
)
</code></pre></div></div>

<p>Airflow CLI에서 에어플로우 백필  명령을 계속 사용할 수 있습니다. 
제 생각에는 이것이 트리거되지 않은 DAG 실행을 따라 잡는 가장 좋은 방법입니다.</p>

<h4 id="schedule_interval">schedule_interval</h4>

<p>일정 간격은 DAG가 트리거되는 시간 간격을 정의합니다. Airflow는 데이터 스트리밍 솔루션이 아니므로 일정 간격을 1초로 설정하지 마세요.
CRON 표현식이나 타임 델타 객체로 정의 된 schedule_interval 이미 보셨을 것입니다</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># CRON EXPRESSION
with DAG(
  'dag', 
  default_args=default_args, 
  schedule_interval='*/10 * * * *', 
  catchup=False
) as dag:
  t0 = DummyOperator(task_id='t0')

# TIMEDELTA OBJECT

with DAG(
  dag_id = 'dag', 
  default_args=default_args, 
  schedule_interval=timedelta(minutes=10),
  catchup=False
) as dag:
  t0 = DummyOperator(task_id='t0')
</code></pre></div></div>

<p>Cron 표현은 매우 강력하지만 처음에는 이해하기 어려울 수 있습니다. 다음 웹 사이트를 살펴보고  일정 간격이 예상한 간격인지 확인하십시오.</p>

<p>이제 Cron 표현식 대신 Timedelta 객체를 언제 사용해야합니까? 특정 schedule interval은  Cron 표현식으로 표현할 수 없습니다. 3일에 한 번씩 DAG를 트리거하려면 timedelta(일=3)  를 사용하여 시간 델타 개체를 정의해야 합니다. Cron 표현식을 사용하여 수행하려고하면 월말에 해당 DAG가 30 일 또는 31  일에 트리거 된 다음 다음 달 1 일에  트리거되어 3 일 간격을 깨뜨립니다.</p>

<p>즉 cron expression으로는 3일 간격으로 처리할 수 없습니다.</p>

<p>요약하자면, 이전 간격과 관련하여 일정 간격을 수행해야 한다면 timedelta 객체를 사용하십시오.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[좀더 낳은 DAG 작성 DAG는 데이터 파이프라인에 해당합니다. DAG는 매일 사용되므로 모범 사례를 따르는 것이 중요합니다. 최적화되고, 이해하기 쉽고, 문서화되고, 잘 조직되어야 합니다. 수백 개의 DAG로 빠르게 끝날 수 있으므로이 부분을 과소 평가하지 마십시오. 그것은 당신에게 많은 고통과 문제를 덜어 줄 것입니다.]]></summary></entry><entry><title type="html">Cloud-Native CI/CD 이해</title><link href="http://localhost:4000/devops/cloud-native-cicd/" rel="alternate" type="text/html" title="Cloud-Native CI/CD 이해" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/cloud-native-cicd</id><content type="html" xml:base="http://localhost:4000/devops/cloud-native-cicd/"><![CDATA[<h2 id="cloud-native-cicd-이해">Cloud-Native CI/CD 이해</h2>
<p>클라우드 네이티브 소프트웨어 개발이 무엇을 의미하는지 더 잘 이해 했으므로 CI/CD 파이프 라인의 맥락에서 그것이 무엇을 의미하는지 살펴 보겠습니다.</p>

<p>Cloud-Native CI/CD는 세 가지 원칙을 기반</p>

<ul>
  <li><strong>Containers</strong></li>
  <li><strong>Serverless</strong></li>
  <li><strong>DevOps</strong></li>
</ul>

<p><strong>Containers</strong></p>

<p>CI/CD의 컨텍스트에서 클라우드 네이티브는 모든 것이 컨테이너 내에서 실행되어야 함을 의미합니다. 응용 프로그램을 테스트하거나 패키지하기 위해 코드베이스에서 완료되는 각 작업은 자체 격리된 컨테이너에서 수행해야 합니다.
이러한 컨테이너를 사용하면 모든 팀 멤버 또는 자동화된 시스템이 동일한 작업을 실행하고 동일한 예측 가능한 최종 결과를 얻을 수 있습니다.
이는 또한 일부 소스 코드에서 특정 작업을 실행하는 데 필요한 모든 런타임 및 구성이 파이프라인이 실행될 때마다 항상 동일하다는 것을 의미합니다. 이렇게 하면 파이프라인의 안정성이 향상되며 필요한 도구를 설치하는 데 시스템 관리자의 도움이 필요하지 않습니다.</p>

<p><strong>Serverless</strong></p>

<p>클라우드 네이티브 CI/CD에 대해 이야기할 때 서버리스는 Azure 함수 또는 AWS 람다와 같은 서비스로서의 함수를 의미하지 않습니다. 중앙 CI 엔진을 유지 관리하고 관리할 필요 없이 온디맨드로 실행하고 확장하는 것입니다.
소프트웨어 개발자는 리소스 할당 내에서 파이프라인을 효율적이고 신속하게 편집하고 실행할 수 있어야 합니다. 파이프라인을 관리하는 중앙 시스템에서 관리자 권한이 필요하지 않습니다. 클라우드 네이티브 CI/CD 솔루션이 성공하려면 모든 시스템 사용자가 액세스하고 관리할 수 있어야 합니다.</p>

<p>Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다.
Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.</p>

<p><strong>DevOps</strong></p>

<p>클라우드 네이티브 CI/CD는 DevOps를 염두에 두고 구축해야 합니다. 팀이 다른 팀을 대신하여 배달 파이프라인을 관리하는 중앙 우수 센터 팀에 의존하지 않고 애플리케이션과 함께 배달 파이프라인을 소유할 수 있도록 해야 합니다.
소프트웨어 개발 팀이 파이프라인을 담당하도록 하면 파이프라인을 관리하고 항상 필요한 최신 소프트웨어를 사용하여 작업을 수행할 수 있습니다.
이것이 바로 Kubernetes에서 기본적으로 실행되는 클라우드 네이티브 CI/CD 솔루션인 Tekton을 만들게 된 원칙입니다. 다음 섹션에서는 Tekton에 대해 자세히 알아보고 클라우드 네이티브 사고 방식으로 CI/CD에 접근한 방법을 알아봅니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[Cloud-Native CI/CD 이해 클라우드 네이티브 소프트웨어 개발이 무엇을 의미하는지 더 잘 이해 했으므로 CI/CD 파이프 라인의 맥락에서 그것이 무엇을 의미하는지 살펴 보겠습니다.]]></summary></entry><entry><title type="html">Tekton First Pipeline</title><link href="http://localhost:4000/devops/tekton-first-pipeline/" rel="alternate" type="text/html" title="Tekton First Pipeline" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/tekton-first-pipeline</id><content type="html" xml:base="http://localhost:4000/devops/tekton-first-pipeline/"><![CDATA[<h2 id="first-pipeline-작성">First Pipeline 작성</h2>
<p>Tekton을 이용하여 Pipeline을 작성하는 것을 실습합니다.</p>

<p>Pipeline은 CI/CD 워크플로의 일부로 특정 실행 순서로 정렬된 일련의 Task를 정의합니다.</p>

<p>이번에는 first Pipeline을 작성할 것입니다, First Pipeline에서는 이전에 작성했던 Hello World! 그리고 goodbye World! Task를 포함하는 Pipeline을 작성합니다.</p>

<p>goodbye task를 다음과 같이 작성하고 적용합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> goodbye.yaml
</code></pre></div></div>

<p>[goodbye.yaml]</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span> 
<span class="na">kind</span><span class="pi">:</span> <span class="s">Task</span> 
<span class="na">metadata</span><span class="pi">:</span> 
  <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye</span> 
      <span class="na">image</span><span class="pi">:</span> <span class="s">alpine</span> 
      <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">#!/bin/sh</span>
        <span class="s">echo "Goodbye World!" </span>
</code></pre></div></div>

<h2 id="pipeline-작성">Pipeline 작성</h2>
<p>hello-world 타스크와 goodbye 타스크를 연결하는 pipeline을 작성합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-goodbye-pipeline.yaml
</code></pre></div></div>

<p>[hello-goodbye-pipeline.yaml]</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span> 
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pipeline</span> 
<span class="na">metadata</span><span class="pi">:</span> 
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-goodbye-pipeline</span> 
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">tasks</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">first-task</span> 
      <span class="na">taskRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye-task</span>
      <span class="na">taskRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye</span>
</code></pre></div></div>

<h2 id="pipeline-run-작성">Pipeline Run 작성</h2>
<p>Pipeline을 인스턴스화하는 Pipeline Run을 다음과 같이 작성해서 Kubernetes에 적용합니다.</p>

<p>[hello-goodbye-pipeline-run.yaml]</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-goodbye-pipeline-run.yaml
</code></pre></div></div>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span> 
<span class="na">kind</span><span class="pi">:</span> <span class="s">PipelineRun</span> 
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-goodbye-pipeline-run</span> 
<span class="na">spec</span><span class="pi">:</span> 
  <span class="na">pipelineRef</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">hello-goodbye-pipeline</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[First Pipeline 작성 Tekton을 이용하여 Pipeline을 작성하는 것을 실습합니다.]]></summary></entry><entry><title type="html">Getting Start Tekton</title><link href="http://localhost:4000/devops/tekton-getting-start/" rel="alternate" type="text/html" title="Getting Start Tekton" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/tekton-getting-start</id><content type="html" xml:base="http://localhost:4000/devops/tekton-getting-start/"><![CDATA[<h2 id="getting-start-tekton">Getting start tekton</h2>
<p>API에서 Task Kubernetes resource type이 Task로 표현되는 Task는 작업에 필요한 로직을 수행하기 위해 순차적으로 실행되는 일련의 Step을 정의합니다. 모든 Task는 Kubernetes 클러스터에서 포드로 실행되며 각 Step은 Pod내에 자신의 컨테이너에서 실행됩니다.</p>

<p>아래와 같이 Hello World Task를 작성하여 Kubernetes 에 적용합니다.</p>

<h2 id="hello-world-task-작성">Hello World Task 작성</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-world.yaml
</code></pre></div></div>

<p>[hello-world.yaml 파일]</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Task</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">alpine</span>
      <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">#!/bin/sh</span>
        <span class="s">echo "Hello World"</span>
</code></pre></div></div>
<h2 id="run-task-작성">Run Task 작성</h2>
<p>이 Task를 실행하려면 TaskRun을 사용하여 인스턴스화해야 합니다. 
다음 내용으로 hello-world-run.yaml이라는 다른 파일을 만듭니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-world-run.yaml
</code></pre></div></div>

<p>[hello-world-run.yaml]</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">TaskRun</span> 
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world-run</span>
<span class="na">spec</span><span class="pi">:</span> 
  <span class="na">taskRef</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[Getting start tekton API에서 Task Kubernetes resource type이 Task로 표현되는 Task는 작업에 필요한 로직을 수행하기 위해 순차적으로 실행되는 일련의 Step을 정의합니다. 모든 Task는 Kubernetes 클러스터에서 포드로 실행되며 각 Step은 Pod내에 자신의 컨테이너에서 실행됩니다.]]></summary></entry><entry><title type="html">Tekton 개요</title><link href="http://localhost:4000/devops/tekton-overveiew/" rel="alternate" type="text/html" title="Tekton 개요" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/tekton-overveiew</id><content type="html" xml:base="http://localhost:4000/devops/tekton-overveiew/"><![CDATA[<h2 id="tekton-개요">Tekton 개요</h2>
<p>Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다.
Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.</p>

<h4 id="cicd는-누가-사용하는가">CI/CD는 누가 사용하는가?</h4>
<ul>
  <li>Tekton 사용자는 일반적으로 다음 범주에 속합니다.조직의 개발자를 위한 CI/CD 시스템을 구축하는 플랫폼 엔지니어.</li>
  <li>CI/CD 시스템을 사용하여 작업을 수행하는 개발자.</li>
</ul>

<h4 id="tekton-장점">Tekton 장점</h4>

<p>Tekton은 CI/CD 시스템의 빌드/배포 사용자에게 다음과 같은 이점을 제공합니다.</p>
<ul>
  <li><strong>사용자 정의 가능</strong>. TEKTON 엔터티는 완전히 사용자 CUSTOMIZING 할 수 있어, 높은 수준의 유연성을 지워합니다. 플랫폼 엔지니어는 개발자가 다양한 시나리오에서 사용할 수 있도록 매우 상세한 빌딩 블록 카탈로그를 정의할 수 있습니다.</li>
  <li><strong>재사용 가능</strong>. TEKTON 엔티티는 완전히 이식 가능하므로, 일단 정의되면 조직 내의 모든 사용자가 주어진 파이프라인을 사용하고 해당 구성 요소를 재사용할 수 있습니다. 이를 통해 개발자는 “바퀴를 다시 발명”하지 않고도 복잡한 파이프라인을 신속하게 구축할 수 있다.</li>
  <li><strong>확장 가능</strong>. Tekton 카탈로그는 Tekton 빌딩 블록의 커뮤니티 중심 리포지토리입니다. Tekton 카탈로그에서 미리 만들어진 구성 요소를 사용하여 새 파이프라인을 빠르게 생성하고 기존 파이프라인을 확장할 수 있습니다.</li>
  <li><strong>표준화</strong>. Tekton은 Kubernetes 클러스터에 확장으로 설치 및 실행되며 잘 확립된 Kubernetes 리소스 모델을 사용합니다. Tekton 워크로드는 Kubernetes 컨테이너내에서 실행됩니다.</li>
  <li><strong>Scalable</strong>. 워크로드 용량을 늘리려면 클러스터에 노드를 추가하기만 하면 됩니다. Tekton은 리소스 할당이나 파이프라인에 대한 기타 수정 사항을 재정의할 필요 없이 클러스터와 함께 scalable됩니다.,</li>
</ul>

<h4 id="tekton-구성요소">Tekton 구성요소</h4>

<p>Tekton은 다음 구성 요소로 구성됩니다.</p>

<p>•	<strong>Tekton Pipelines</strong>  은 Tekton의 기반입니다. CI/CD 파이프라인을 어셈블할 수 있는 빌딩 블록 역할을 하는 Kubernetes Custom Resources세트를 정의합니다.</p>

<p>•	<strong>Tekton Triggers</strong> 를 사용하면 이벤트를 기반으로 파이프라인을 인스턴스화할 수 있습니다. 예를 들어 GitHub 리포지토리에 대해 PR이 병합될 때마다 파이프라인의 인스턴스화 및 실행을 트리거할 수 있습니다. 특정 Tekton 트리거를 시작하는 사용자 인터페이스를 구축할 수도 있습니다.</p>

<p>•	<strong>Tekton CLI</strong> 는 Tekton과 상호 작용할 수 있도록 Kubernetes CLI 위에 구축된 tkn이라는 CLI를 제공합니다.</p>

<p>•	<strong>Tekton Dashboard</strong> 는 파이프라인 실행에 대한 정보를 표시하는 Tekton Pipelines용 웹 기반 유저 인터페이스입니다.</p>

<p>•	<strong>Tekton Catalog</strong> 는 자체 파이프라인에서 사용할 준비가 된 고품질의 커뮤니티에  Tekton 빌딩 블록(Task, Pipeline 등)의 리포지토리입니다.</p>

<p>•	<strong>Tekton Hub</strong> 는 Tekton 카탈로그에 액세스하기 위한 웹 기반 그래픽 인터페이스입니다.</p>

<p>•	<strong>Tekton Operator</strong> 는 Kubernetes 클러스터에서 Tekton 프로젝트를 설치, 업데이트 및 제거할 수 있는 Kubernetes Operator 패턴입니다.</p>

<h4 id="tekton-concept">Tekton Concept</h4>
<p>Tekton으로 무엇을 할 수 있습니까?</p>

<p>Tekton은 실행하려는 워크로드를 지정하는 Task개념을 도입했습니다.</p>

<p>•	<strong>Task</strong> – 일련의 순차적인 Step을 정의하고 각 Step은 특정 inputs 세트에 대해 특정 빌드 도구를 호출하고 다음 단계에서 입력으로 사용할 수 있는 특정 outputs세트를 생성합니다.</p>

<p>•	<strong>Pipeline</strong> - defines a series of ordered Tasks, and just like Steps in a Task, a Task in a Pipeline can use the output of a previously executed Task as its input. 일련의 순차적인 Tasks를 정의하고 작업의 단계와 마찬가지로 파이프라인의 작업은 이전에 실행된 작업의 출력을 입력으로 사용할 수 있습니다.</p>

<p>•	<strong>TaskRun</strong> - 특정 입력과 출력 집합을 생성하기 위해 지정한 Task를 인스턴스화합니다. 다시 말해서, Task는 Tekton에게 무엇을 해야 하는지 알려주고, TaskRun은 Tekton에게 무엇을 할 것인지와 빌드 플래그와 같이 정확히 수행하는 방법에 대한 추가 세부 정보를 알려줍니다.</p>

<p>•	<strong>PipelineRun</strong> - 특정 입력 집합에서 특정 대상에 대한 특정 출력 집합을 생성하기 위해 저정한 파이프라인을 인스턴스화합니다.</p>

<p>각 Task는 Kubernetes Pod로 실행됩니다. 따라서 기본적으로 파이프라인 내의 작업은 데이터를 공유하지 않습니다. 작업 간에 데이터를 공유하려면 다음 작업에서 출력을 사용할 수 있도록 하고 이전에 실행된 Task의 출력을 입력으로 사용하도록 명시적으로 각 작업을 구성해야 합니다.</p>

<h4 id="언제-어떤-것을-사용합니까">언제 어떤 것을 사용합니까?</h4>
<p>•	<strong>Task</strong> - 테스트 실행, 린트 실행 또는 Kaniko 캐시 구축과 같은 단순한 워크로드에 유용합니다. 하나의 Task는 Kubernetes Pod로 실행되고 단일 디스크를 사용하며 일반적으로 작업을 단순하게 유지합니다.</p>

<p>•	<strong>Pipeline</strong> - 정적 분석, 테스트, 빌드,  복잡한 프로젝트 프로젝트처럼 복잡한 워크로드에 유용합니다.</p>

<h4 id="개념모델">개념모델</h4>

<p>Tekton 구성요소 및 데이터 모델</p>

<ul>
  <li>Steps</li>
  <li>Tasks</li>
  <li>Pipelines</li>
</ul>

<p>Step은 Python 웹 앱에 대한 일부 단위 테스트 실행 또는 Java 프로그램 컴파일과 같은 CI/CD 워크플로의 작업입니다. Tekton은 제공한 컨테이너 이미지로 각 Step을 수행합니다. 예를 들어, 공식 Go 이미지를 사용하여 로컬 워크스테이션(go 빌드)에서와 동일한 방식으로 Go 프로그램을 컴파일할 수 있습니다.</p>

<h4 id="task는-순차적인-step의-모음입니다">Task는 순차적인 Step의 모음입니다.</h4>

<p>Tekton은 Kubernetes Pod형식으로 Task를 실행하며, 여기서 각 Step은 Pod에서 실행 중인 컨테이너가 됩니다. 이 디자인을 사용하면 여러 관련 단계에 대한 공유 환경을 설정할 수 있습니다. 예를 들어 Task의 각 Step내에서 액세스할 수 있는 Kubernetes 볼륨을 작업에 탑재할 수 있습니다.</p>

<figure style="width: 50%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-task.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="pipeline-은-순차적-task의-모음입니다">Pipeline 은 순차적 Task의 모음입니다.</h4>
<p>Tekton은 모든 작업을 수집하여 DAG(방향성 비순환 그래프)로 연결하고 그래프를 순서대로 실행합니다. 즉, 여러 Kubernetes 포드를 생성하고 각 포드가 원하는 대로 성공적으로 실행을 완료하도록 합니다. Tekton은 개발자에게 프로세스에 대한 완전한 제어 권한을 부여합니다. 작업 완료의 fan-in/fan-out 시나리오를 설정하거나, 불안정한 테스트가 있는 경우 자동으로 재시도하도록 Tekton에 요청하거나, 작업이 진행하기 전에 충족해야 하는 조건을 지정할 수 있습니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-pipeline.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>Task 및 Pipeline은 Kubernetes 클러스터에서 사용자 지정 리소스로 지정됩니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-pipeline-on-kubernetes.png" alt="" />
  <figcaption></figcaption>
</figure>

<h2 id="taskrun-and-pipelinerun">TaskRun and PipelineRun</h2>
<p>PipelineRun은 이름에서 알 수 있듯이 특정 Pipeline을 실행입니다. 예를 들어 Tekton에 CI/CD 워크플로를 하루에 두 번 실행하도록 요청할 수 있으며 각 실행은 Kubernetes 클러스터에서 추적할 수 있는 PipelineRun 리소스가 됩니다. PipelineRuns를 사용하여 각 작업 실행의 세부 사항을 포함하여 CI/CD 워크플로의 상태를 볼 수 있습니다.</p>

<p>마찬가지로 taskRun은 지정한 Task를 실행합니다. TaskRun은 Pipeline인 외부에서 지정한 Task를 선택하여 실행 할 수 있습니다. 이를 통해 작업의 각 단계 실행에 대한 세부 사항을 볼 수 있습니다.</p>

<p>. <strong>TaskRuns 및 pipelineRuns</strong> 는 Task 및 Pipeline 리소스를 연결합니다. 설계를 통해 개발자는 다양한 입력 및 출력에 대해 Task와Pipleline을 재사용할 수 있습니다.</p>

<p>taskRuns 또는 pipelineRuns를 수동으로 생성하여 Tekton Task 또는 Pipeline을 즉시 실행하도록 트리거할 수 있습니다. 또는 Tekton Triggers와 같은 Tekton 구성 요소에 요청 시 자동으로 실행을 생성하도록 요청할 수 있습니다. 예를 들어 새 pull 요청이 git 리포지토리에 체크인될 때마다 파이프라인을 실행할 수 있습니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-arch.png" alt="" />
  <figcaption></figcaption>
</figure>

<h2 id="tekton-작동원리">Tekton 작동원리</h2>

<p>Tekton Pipelines는 각 단계를 래핑하여 작동합니다. 보다 구체적으로 말하면 Tekton Pipelines는 단계 컨테이너에 진입점 바이너리를 주입하여 시스템이 준비될 때 지정한 명령을 실행합니다.
Tekton Pipelines는 Kubernetes annotation을 사용하여 파이프라인의 상태를 추적합니다. 이러한 annotation은 Kubernetes Downward API를 사용하여 파일 형식으로 각 step컨테이너 내부에 투영됩니다. 진입점 바이너리는 투영된 파일을 자세히 관찰하고 특정 주석이 파일로 나타나는 경우에만 제공된 명령을 시작합니다.</p>

<p>예를 들어, Tekton에 작업에서 두 단계를 연속적으로 실행하도록 요청하면 두 번째 step컨테이너에 주입된 진입점 바이너리는 첫 번째 단계 컨테이너가 성공적으로 완료되었다고 annotation이 보고할 때까지 유휴 상태로 기다립니다.</p>

<p>또한 Tekton Pipelines는 입력 리소스 검색 및 blob 스토리지 솔루션에 대한 출력 업로드와 같은 특정 기본 제공 기능을 지원하기 위해 일부 컨테이너가 Step컨테이너 전후에 자동으로 실행되도록 예약합니다. taskRuns 및 pipelineRuns를 통해 실행 상태도 추적할 수 있습니다. 시스템은 또한 단계 컨테이너를 실행하기 전에 환경을 설정하기 위해 여러 다른 작업을 수행합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[Tekton 개요 Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다. Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.]]></summary></entry><entry><title type="html">Airflow Task</title><link href="http://localhost:4000/workflow/tasks/" rel="alternate" type="text/html" title="Airflow Task" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/tasks</id><content type="html" xml:base="http://localhost:4000/workflow/tasks/"><![CDATA[<h2 id="airflow-task">Airflow Task</h2>
<p>Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다.
Task는</p>

<ul>
  <li>Operator : 지정한 작읍을 수행하는 Operator</li>
  <li>Sensor : 어떤 조건이 만족하는지 주기적으로 스캔이 필요할 때 사용하며 조건이 만족하는 경우 Task가 수행.</li>
  <li>Hook : DB나 서비스 같은 외부 시스템과 통신하기 위한 인터페이스를 제공하여 연결 상태를 유지
등을 사용할 수 있습니다.</li>
</ul>

<h2 id="task-instance">Task Instance</h2>

<p>DAG실행될 때 마다 Task Instance를 생성하여 Executor로 전달하여 해당작업을 실행합니다. 그리고 해당 Task Instance를 다시 Metadata로 보내서 상태를 업데이트하며, Task Instance의 작업이 남아 있으면 Executor로 다시 보내집니다. 작업이 완료가 되면 스케줄러에게 보냅니다.
Operator
Operator는 task를 어떻게 실행시킬지 정의합니다. 하나의 워크플로우안에서 한개 이상의 task를 정의할 수 있습니다. 하나의 Task가 하나의 Operator라고 할 수 있다.
Operator는 Action Operator와 Transfer Operator로 구분됩니다.</p>

<ul>
  <li>Action Operator : 작업을 수행하거나 다른 시스템에 작업을 수행하도록 trigger합니다.</li>
  <li>Transfer Operator : 특정 시스템에 다른 시스템으로 데이터를 이동</li>
  <li>Sensor Operator : 특정 조건에 일치할 때 까지 기다렸다가, 만족되면 이후 과정을 진행하도록 기다려는 Operator.</li>
</ul>

<p>Airflow는 기본 Operator는 Bash와 Python Operator가 대표적이며 그외 많은 Operator를 지원하고 있습니다. Operator에 공통적으로 **kwargs라는 keywoard Arguments를 전달하는 부분이 있으며, DAG을 정의할 때 default_args 전달하는 것처럼 전달합니다.</p>

<h2 id="task-dependencies">Task Dependencies</h2>
<p>Apache Airflow의 DAG 내에 task들의 dependency를 설정함으로써 task 실행 순서와 병렬 실행 task들 등을 정의할 수 있습니다.
Task 간 의존성은 다음과 같이</p>
<ul>
  <li>set_downstream 또는 » 기호</li>
  <li>set_upstream 또는 « 기호 
같은 함수 또는 기호로 설정할 수 있습니다. 
set_downstream 는 Task 실행 후에 수행할 task를 설정
set_upstream 는 Task 실행 전에 수행할 task를 설정</li>
</ul>

<p>예시)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>

<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">dedent</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="s">'data_pipeline_ex09'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">description</span><span class="o">=</span><span class="s">'Hello world'</span><span class="p">,</span>
  <span class="n">schedule_interval</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">hello</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s">'Hello!'</span><span class="p">)</span>

<span class="n">t1</span> <span class="o">=</span>  <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'echo_hello'</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo "Hi from bash operator"'</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">python_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"python_task"</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">hello</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">templated_command</span> <span class="o">=</span> <span class="n">dedent</span><span class="p">(</span>
  <span class="s">"""
  
  """</span>
<span class="p">)</span>

<span class="n">t3</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'templated'</span><span class="p">,</span>
  <span class="n">bash_command</span><span class="o">=</span><span class="n">templated_command</span><span class="p">,</span>
  <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'my_param'</span><span class="p">:</span> <span class="s">'Parameter I passed in'</span><span class="p">},</span>
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="n">t2</span> <span class="o">&gt;&gt;</span> <span class="n">t3</span>
<span class="c1"># t1.set_downstream(t2) 
# t3.set_upstream(t2)
</span></code></pre></div></div>

<p>t1, t2, t3 task가 순차적으로 실행됩니다.</p>

<p>t1.set_downstream(t2)</p>

<p>t2는 성공적으로 실행되는 t1에 의존하여 실행됩니다.</p>

<p>t2.set_upstream(t1)</p>

<p>비트 시프트 연산자를 사용하여 작업을 연결할 수도 있습니다.:
t1 » t2</p>

<p>그리고 비트 시프트 연산자와의 업스트림 종속성 표기:
t2 « t1</p>

<p>여러 종속성을 연결하는 것은 비트 시프트 연산자로 간결해집니다.
t1 » t2 » t3</p>

<p>작업 목록을 종속성으로 설정할 수도 있습니다. 
이러한 작업은 모두 동일한 효과를 갖습니다</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t1</span><span class="p">.</span><span class="n">set_downstream</span><span class="p">([</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">])</span>
<span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]</span>
<span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">t1</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="task" /><summary type="html"><![CDATA[Airflow Task Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다. Task는]]></summary></entry><entry><title type="html">Airflow XCom</title><link href="http://localhost:4000/workflow/xcom/" rel="alternate" type="text/html" title="Airflow XCom" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/xcom</id><content type="html" xml:base="http://localhost:4000/workflow/xcom/"><![CDATA[<h2 id="airflow-xcom">Airflow XCom</h2>
<p>Airflow 작업(Task) 간에 데이터를 전달하는 첫 번째 방법은 작업 데이터를 공유하기 위한 주요 Airflow 기능인 XCom을 사용하는 것입니다.
XCom은 task간 데이터를 공유가 필요할 때,  데이터를 공유하기 위해 push, pull 을 사용하여 값을 전달하고, 값을 가져올 수 있습니다.. 
XComs는 작업에서 보내는 의미의 “푸시” , 작업에서 수신하는 것을 의미하는 “pulled”일 수 있습니다. 푸시된 XCom은 에어플로우 메타데이터 데이터베이스에 저장되고 다른 모든 작업에서 사용할 수 있게 됩니다. 작업이 값을 반환할 때마다.
Airflow에서는 여러 분산환경에서 서로 다른 Worker에서 Task가 실행 될 수 있기 때문에 Xcom을 사용합니다. Variable과 비슷하지만 Xcom은 특정 DAG내부에서만 공유되는 특징이 있습니다. 여러 DAG에서 공유해서 사용하려면 Variable을 사용해야 합니다.  PythonOperator를 사용하면 return값이 자동으로 Xcom에 push됩니다.</p>

<p>Airflow UI의 Admin &gt; XComs 메뉴에서XCom을 내용을 볼 수 있습니다. 다음과 같은 내용이 표시되어야 합니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/07-xcom_ui.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="xcom-사용시기-및-제약사항">XCom 사용시기 및 제약사항</h4>
<p>XComs는 작업 간에 소량의 데이터를 전달하는 데 사용해야 합니다. 예를 들어 작업 메타데이터, 날짜, 모델 정확도 또는 단일 값 쿼리 결과는 모두 XCom과 함께 사용하기에 이상적인 데이터입니다.
XCom으로 작은 데이터 세트를 전달하는 것을 막을 수는 없지만 그렇게 할 때는 매우 주의하십시오. 이것은 XCom이 설계된 목적이 아니며 팬더 데이터 프레임과 같은 데이터를 전달하는 데 사용하면 DAG의 성능이 저하되고 메타데이터 데이터베이스의 저장소를 차지할 수 있습니다.
XCom은 작업 간에 큰 데이터 세트를 전달하는 데 사용할 수 없습니다. XCom의 크기 제한은 사용 중인 메타데이터 데이터베이스에 따라 결정됩니다</p>

<ul>
  <li>Postgres: 1 Gb</li>
  <li>SQLite: 2 Gb</li>
  <li>MySQL: 64 Kb</li>
</ul>

<p>이러한 한계가 그리 크지 않다는 것을 알 수 있습니다. 데이터가 최대 허용 한도를 충족한다고 생각되더라도 XComs를 사용하지 마십시오. 대신 더 많은 양의 데이터에 더 적합한 중간 데이터 저장소를 사용하십시오.</p>

<h4 id="custom-xcom-backends">Custom XCom Backends</h4>

<p>커스텀 XCom 백엔드는 에어플로우 2.0 이상에서 사용할 수 있는 새로운 기능입니다. XCom 백엔드를 사용하면 Airflow의 메타데이터 데이터베이스의 기본값이 아닌 S3, GCS 또는 HDFS와 같은 외부 시스템에서 XCom을 푸시하고 풀 할 수 있습니다. 또한 사용자 고유의 직렬화 및 역직렬화 메서드를 구현하여 XCom이 처리되는 방법을 정의할 수 있습니다. 이것은 그 자체로 개념이며 사용자 지정 XCom 백엔드를 읽으면 더 많은 것을 배울 수 있습니다.</p>

<p>예시)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">push_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">contenxt</span><span class="p">[</span><span class="err">‘</span><span class="n">task_instance</span><span class="err">’</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">변수명</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">전달할</span> <span class="n">value</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">pull_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">[</span><span class="err">‘</span><span class="n">ti</span><span class="err">’</span><span class="p">].</span><span class="n">xcom_pull</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">변수명</span><span class="p">,</span> <span class="n">task_ids</span><span class="o">=</span><span class="n">대상</span> <span class="n">Task이름</span><span class="p">)</span>

</code></pre></div></div>
<ul>
  <li>Xcom 예시 1)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span>

<span class="c1"># Utils 
</span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span><span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'tags'</span><span class="p">:</span> <span class="s">'training'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span> 

<span class="k">def</span> <span class="nf">xcom_push</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">context</span><span class="p">[</span><span class="s">'task_instance'</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">'pushed_value'</span><span class="p">,</span>
    <span class="n">value</span><span class="o">=</span><span class="s">'xcom_push_test_message!'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">pull_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">[</span><span class="s">'ti'</span><span class="p">].</span><span class="n">xcom_pull</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">'pushed_value'</span><span class="p">,</span> 
    <span class="n">task_ids</span><span class="o">=</span><span class="s">'push_by_xcom'</span>
  <span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span><span class="o">=</span><span class="s">'xcom_dag'</span><span class="p">,</span> 
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span> 
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>

  <span class="n">push_by_xcom</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'push_by_xcom'</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">xcom_push</span>
  <span class="p">)</span>
  
  <span class="n">pull_task1</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'pull_example1'</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">pull_func</span>
  <span class="p">)</span>
  
  <span class="n">pull_task2</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'pull_example2'</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo ""'</span>
  <span class="p">)</span>
  
  <span class="n">push_by_xcom</span> <span class="o">&gt;&gt;</span> <span class="n">pull_task1</span> <span class="o">&gt;&gt;</span> <span class="n">pull_task2</span>
</code></pre></div></div>

<ul>
  <li>Xcom 예시 2)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">airflow.operators.python_operator</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'https://covidtracking.com/api/v1/states/'</span>
<span class="n">state</span> <span class="o">=</span> <span class="s">'wa'</span>

<span class="k">def</span> <span class="nf">get_testing_increase</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">ti</span><span class="p">):</span>
    <span class="s">"""
    Gets totalTestResultsIncrease field from Covid API for given state and returns value
    """</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">+</span><span class="s">'{0}/current.json'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>
    <span class="n">testing_increase</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">text</span><span class="p">)[</span><span class="s">'totalTestResultsIncrease'</span><span class="p">]</span>

    <span class="n">ti</span><span class="p">.</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'testing_increase'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">testing_increase</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">analyze_testing_increases</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">ti</span><span class="p">):</span>
    <span class="s">"""
    Evaluates testing increase results
    """</span>
    <span class="n">testing_increases</span><span class="o">=</span><span class="n">ti</span><span class="p">.</span><span class="n">xcom_pull</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'testing_increase'</span><span class="p">,</span> <span class="n">task_ids</span><span class="o">=</span><span class="s">'get_testing_increase_data_{0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Testing increases for {0}:'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">state</span><span class="p">),</span> <span class="n">testing_increases</span><span class="p">)</span>
    <span class="c1">#run some analysis here
</span>
<span class="c1"># Default settings applied to all tasks
</span><span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'owner'</span><span class="p">:</span> <span class="s">'airflow'</span><span class="p">,</span>
    <span class="s">'depends_on_past'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">'email_on_failure'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">'email_on_retry'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span><span class="s">'xcom_dag'</span><span class="p">,</span>
         <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2021</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
         <span class="n">max_active_runs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
         <span class="n">schedule_interval</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
         <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
         <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
         <span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>

    <span class="n">opr_get_covid_data</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="s">'get_testing_increase_data_{0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">state</span><span class="p">),</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">get_testing_increase</span><span class="p">,</span>
        <span class="n">op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">'state'</span><span class="p">:</span><span class="n">state</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="n">opr_analyze_testing_data</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="s">'analyze_data'</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">analyze_testing_increases</span><span class="p">,</span>
                <span class="n">op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">'state'</span><span class="p">:</span><span class="n">state</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="n">opr_get_covid_data</span> <span class="o">&gt;&gt;</span> <span class="n">opr_analyze_testing_data</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow XCom Airflow 작업(Task) 간에 데이터를 전달하는 첫 번째 방법은 작업 데이터를 공유하기 위한 주요 Airflow 기능인 XCom을 사용하는 것입니다. XCom은 task간 데이터를 공유가 필요할 때, 데이터를 공유하기 위해 push, pull 을 사용하여 값을 전달하고, 값을 가져올 수 있습니다.. XComs는 작업에서 보내는 의미의 “푸시” , 작업에서 수신하는 것을 의미하는 “pulled”일 수 있습니다. 푸시된 XCom은 에어플로우 메타데이터 데이터베이스에 저장되고 다른 모든 작업에서 사용할 수 있게 됩니다. 작업이 값을 반환할 때마다. Airflow에서는 여러 분산환경에서 서로 다른 Worker에서 Task가 실행 될 수 있기 때문에 Xcom을 사용합니다. Variable과 비슷하지만 Xcom은 특정 DAG내부에서만 공유되는 특징이 있습니다. 여러 DAG에서 공유해서 사용하려면 Variable을 사용해야 합니다. PythonOperator를 사용하면 return값이 자동으로 Xcom에 push됩니다.]]></summary></entry></feed>