<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-12-14T17:55:23+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Cloud Native Journey</title><subtitle>Software Engineer/Architect</subtitle><author><name>Jaeguk Yun</name></author><entry><title type="html">Apache Airflow My First DAG 개발</title><link href="http://localhost:4000/workflow/myfirst-dag/" rel="alternate" type="text/html" title="Apache Airflow My First DAG 개발" /><published>2022-12-14T00:00:00+09:00</published><updated>2022-12-14T00:00:00+09:00</updated><id>http://localhost:4000/workflow/myfirst-dag</id><content type="html" xml:base="http://localhost:4000/workflow/myfirst-dag/"><![CDATA[<h2 id="my-first-dag-개발">My First DAG 개발</h2>
<p>Apache Airflow Dag 개발 절차는 다음의 7단계 절차로 구현됩니다.</p>

<ul>
  <li>Airflow 관련 Module import</li>
  <li>DAG Arguments 정의</li>
  <li>Python Function 또는 task 에서 사용하는 Variable 정의</li>
  <li>Instatiate DAG 정의</li>
  <li>Task 정의</li>
  <li>Task간 의존성 정의</li>
  <li>Verify DAG</li>
</ul>

<p>개발절차를 예제로 살펴보면 다음과 같습니다.</p>

<h4 id="1-airflow-관련-module-import">1. Airflow 관련 Module import</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
</code></pre></div></div>

<h4 id="2-dag-arguments-정의">2. DAG Arguments 정의</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
    <span class="s">'tags'</span><span class="p">:</span> <span class="s">'training'</span><span class="p">,</span>
    <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="3-python-function-또는-task-에서-사용하는-variable-정의optional">3. Python Function 또는 task 에서 사용하는 Variable 정의(Optional)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hello_airflow</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Hello airflow"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="4-instantiate-dag-정의">4. Instantiate DAG 정의</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
    <span class="n">dag_id</span> <span class="o">=</span> <span class="s">"myFirstDag"</span><span class="p">,</span>
    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s">"@daily"</span>
<span class="p">)</span>
</code></pre></div></div>

<h4 id="5--task-정의">5.  Task 정의</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t1</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"bash"</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">"echo Hello airflow"</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"python"</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">hello_airflow</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>
</code></pre></div></div>

<h4 id="6-task간-의존성-정의">6. Task간 의존성 정의</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>t1 &gt;&gt; t2
</code></pre></div></div>

<h4 id="7-verify-dag">7. Verify DAG</h4>

<p>myFirstDag을 airflow에 배포하여 dag을 테스트합니다. 
테스트 aifrlow Webserver UI에서 하거나 airflow cli를 사용하여 테스트합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[My First DAG 개발 Apache Airflow Dag 개발 절차는 다음의 7단계 절차로 구현됩니다.]]></summary></entry><entry><title type="html">Airflow Task</title><link href="http://localhost:4000/workflow/tasks/" rel="alternate" type="text/html" title="Airflow Task" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/tasks</id><content type="html" xml:base="http://localhost:4000/workflow/tasks/"><![CDATA[<h2 id="airflow-task">Airflow Task</h2>
<p>Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다.
Task는</p>

<ul>
  <li>Operator : 지정한 작읍을 수행하는 Operator</li>
  <li>Sensor : 어떤 조건이 만족하는지 주기적으로 스캔이 필요할 때 사용하며 조건이 만족하는 경우 Task가 수행.</li>
  <li>Hook : DB나 서비스 같은 외부 시스템과 통신하기 위한 인터페이스를 제공하여 연결 상태를 유지
등을 사용할 수 있습니다.</li>
</ul>

<h2 id="task-instance">Task Instance</h2>

<p>DAG실행될 때 마다 Task Instance를 생성하여 Executor로 전달하여 해당작업을 실행합니다. 그리고 해당 Task Instance를 다시 Metadata로 보내서 상태를 업데이트하며, Task Instance의 작업이 남아 있으면 Executor로 다시 보내집니다. 작업이 완료가 되면 스케줄러에게 보냅니다.
Operator
Operator는 task를 어떻게 실행시킬지 정의합니다. 하나의 워크플로우안에서 한개 이상의 task를 정의할 수 있습니다. 하나의 Task가 하나의 Operator라고 할 수 있다.
Operator는 Action Operator와 Transfer Operator로 구분됩니다.</p>

<ul>
  <li>Action Operator : 작업을 수행하거나 다른 시스템에 작업을 수행하도록 trigger합니다.</li>
  <li>Transfer Operator : 특정 시스템에 다른 시스템으로 데이터를 이동</li>
  <li>Sensor Operator : 특정 조건에 일치할 때 까지 기다렸다가, 만족되면 이후 과정을 진행하도록 기다려는 Operator.</li>
</ul>

<p>Airflow는 기본 Operator는 Bash와 Python Operator가 대표적이며 그외 많은 Operator를 지원하고 있습니다. Operator에 공통적으로 **kwargs라는 keywoard Arguments를 전달하는 부분이 있으며, DAG을 정의할 때 default_args 전달하는 것처럼 전달합니다.</p>

<h2 id="task-dependencies">Task Dependencies</h2>
<p>Apache Airflow의 DAG 내에 task들의 dependency를 설정함으로써 task 실행 순서와 병렬 실행 task들 등을 정의할 수 있습니다.
Task 간 의존성은 다음과 같이</p>
<ul>
  <li>set_downstream 또는 » 기호</li>
  <li>set_upstream 또는 « 기호 
같은 함수 또는 기호로 설정할 수 있습니다. 
set_downstream 는 Task 실행 후에 수행할 task를 설정
set_upstream 는 Task 실행 전에 수행할 task를 설정</li>
</ul>

<p>예시)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>

<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">dedent</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="s">'data_pipeline_ex09'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">description</span><span class="o">=</span><span class="s">'Hello world'</span><span class="p">,</span>
  <span class="n">schedule_interval</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">hello</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s">'Hello!'</span><span class="p">)</span>

<span class="n">t1</span> <span class="o">=</span>  <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'echo_hello'</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo "Hi from bash operator"'</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">python_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"python_task"</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">hello</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">templated_command</span> <span class="o">=</span> <span class="n">dedent</span><span class="p">(</span>
  <span class="s">"""
  
  """</span>
<span class="p">)</span>

<span class="n">t3</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'templated'</span><span class="p">,</span>
  <span class="n">bash_command</span><span class="o">=</span><span class="n">templated_command</span><span class="p">,</span>
  <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'my_param'</span><span class="p">:</span> <span class="s">'Parameter I passed in'</span><span class="p">},</span>
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="n">t2</span> <span class="o">&gt;&gt;</span> <span class="n">t3</span>
<span class="c1"># t1.set_downstream(t2) 
# t3.set_upstream(t2)
</span></code></pre></div></div>

<p>t1, t2, t3 task가 순차적으로 실행됩니다.</p>

<p>t1.set_downstream(t2)</p>

<p>t2는 성공적으로 실행되는 t1에 의존하여 실행됩니다.</p>

<p>t2.set_upstream(t1)</p>

<p>비트 시프트 연산자를 사용하여 작업을 연결할 수도 있습니다.:
t1 » t2</p>

<p>그리고 비트 시프트 연산자와의 업스트림 종속성 표기:
t2 « t1</p>

<p>여러 종속성을 연결하는 것은 비트 시프트 연산자로 간결해집니다.
t1 » t2 » t3</p>

<p>작업 목록을 종속성으로 설정할 수도 있습니다. 
이러한 작업은 모두 동일한 효과를 갖습니다</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t1</span><span class="p">.</span><span class="n">set_downstream</span><span class="p">([</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">])</span>
<span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]</span>
<span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">t1</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="task" /><summary type="html"><![CDATA[Airflow Task Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다. Task는]]></summary></entry><entry><title type="html">Airflow Xcon</title><link href="http://localhost:4000/workflow/xcon/" rel="alternate" type="text/html" title="Airflow Xcon" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/xcon</id><content type="html" xml:base="http://localhost:4000/workflow/xcon/"><![CDATA[<h2 id="airflow-xcom">Airflow Xcom</h2>
<p>Airflow task간 데이터를 공유가 필요할 때,  데이터를 공유하기 위해 push, pull 을 사용하여 값을 전달하고, 값을 가져오기 위해 사용합니다. Airflow에서는 여러 분산환경에서 서로 다른 Work에서 Task가 실행 될 수 있기 때문에 Xcom을 사용합니다. Variable과 비슷하지만 Xcom은 특정 DAG내부에서만 공유되는 특징이 있습니다. 여러 DAG에서 공유해서 사용하려면 Variable을 사용해야 합니다.  PythonOperator를 사용하면 return값이 자동으로 Xcom에 push됩니다.</p>

<p>예시)</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">push_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
<span class="n">contenxt</span><span class="p">[</span><span class="err">‘</span><span class="n">task_instance</span><span class="err">’</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">변수명</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">전달할</span> <span class="n">value</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">pull_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">[</span><span class="err">‘</span><span class="n">ti</span><span class="err">’</span><span class="p">].</span><span class="n">xcom_pull</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">변수명</span><span class="p">,</span> <span class="n">task_ids</span><span class="o">=</span><span class="n">대상</span> <span class="n">Task이름</span><span class="p">)</span>

</code></pre></div></div>
<ul>
  <li>Xcon 예시</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span>

<span class="c1"># Utils 
</span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span><span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'tags'</span><span class="p">:</span> <span class="s">'training'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span> 

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span><span class="o">=</span><span class="s">'xcom_dag'</span><span class="p">,</span> 
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span> 
<span class="p">)</span> 

<span class="k">def</span> <span class="nf">xcom_push</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">context</span><span class="p">[</span><span class="s">'task_instance'</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">'pushed_value'</span><span class="p">,</span>
    <span class="n">value</span><span class="o">=</span><span class="s">'xcom_push_test_message!'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">pull_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">[</span><span class="s">'ti'</span><span class="p">].</span><span class="n">xcom_pull</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">'pushed_value'</span><span class="p">,</span> 
    <span class="n">task_ids</span><span class="o">=</span><span class="s">'push_by_xcom'</span>
  <span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="n">push_by_xcom</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'push_by_xcom'</span><span class="p">,</span>
  <span class="n">python_callable</span><span class="o">=</span><span class="n">xcom_push</span><span class="p">,</span> 
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">pull_task1</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'pull_example1'</span><span class="p">,</span>
  <span class="n">python_callable</span><span class="o">=</span><span class="n">pull_func</span><span class="p">,</span> 
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">pull_task2</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'pull_example2'</span><span class="p">,</span>
  <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo ""'</span><span class="p">,</span> 
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">push_by_xcom</span> <span class="o">&gt;&gt;</span> <span class="n">pull_task1</span> <span class="o">&gt;&gt;</span> <span class="n">pull_task2</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Xcom Airflow task간 데이터를 공유가 필요할 때, 데이터를 공유하기 위해 push, pull 을 사용하여 값을 전달하고, 값을 가져오기 위해 사용합니다. Airflow에서는 여러 분산환경에서 서로 다른 Work에서 Task가 실행 될 수 있기 때문에 Xcom을 사용합니다. Variable과 비슷하지만 Xcom은 특정 DAG내부에서만 공유되는 특징이 있습니다. 여러 DAG에서 공유해서 사용하려면 Variable을 사용해야 합니다. PythonOperator를 사용하면 return값이 자동으로 Xcom에 push됩니다.]]></summary></entry><entry><title type="html">Tekton 개요</title><link href="http://localhost:4000/devops/tekton-overveiew/" rel="alternate" type="text/html" title="Tekton 개요" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/tekton-overveiew</id><content type="html" xml:base="http://localhost:4000/devops/tekton-overveiew/"><![CDATA[<h2 id="tekton-개요">Tekton 개요</h2>
<p>Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다.
Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.</p>

<h4 id="cicd는-누가-사용하는가">CI/CD는 누가 사용하는가?</h4>
<ul>
  <li>Tekton 사용자는 일반적으로 다음 범주에 속합니다.조직의 개발자를 위한 CI/CD 시스템을 구축하는 플랫폼 엔지니어.</li>
  <li>CI/CD 시스템을 사용하여 작업을 수행하는 개발자.</li>
</ul>

<h4 id="tekton-장점">Tekton 장점</h4>

<p>Tekton은 CI/CD 시스템의 빌드/배포 사용자에게 다음과 같은 이점을 제공합니다.</p>
<ul>
  <li><strong>사용자 정의 가능</strong>. TEKTON 엔터티는 완전히 사용자 CUSTOMIZING 할 수 있어, 높은 수준의 유연성을 지워합니다. 플랫폼 엔지니어는 개발자가 다양한 시나리오에서 사용할 수 있도록 매우 상세한 빌딩 블록 카탈로그를 정의할 수 있습니다.</li>
  <li><strong>재사용 가능</strong>. TEKTON 엔티티는 완전히 이식 가능하므로, 일단 정의되면 조직 내의 모든 사용자가 주어진 파이프라인을 사용하고 해당 구성 요소를 재사용할 수 있습니다. 이를 통해 개발자는 “바퀴를 다시 발명”하지 않고도 복잡한 파이프라인을 신속하게 구축할 수 있다.</li>
  <li><strong>확장 가능</strong>. Tekton 카탈로그는 Tekton 빌딩 블록의 커뮤니티 중심 리포지토리입니다. Tekton 카탈로그에서 미리 만들어진 구성 요소를 사용하여 새 파이프라인을 빠르게 생성하고 기존 파이프라인을 확장할 수 있습니다.</li>
  <li><strong>표준화</strong>. Tekton은 Kubernetes 클러스터에 확장으로 설치 및 실행되며 잘 확립된 Kubernetes 리소스 모델을 사용합니다. Tekton 워크로드는 Kubernetes 컨테이너내에서 실행됩니다.</li>
  <li><strong>Scalable</strong>. 워크로드 용량을 늘리려면 클러스터에 노드를 추가하기만 하면 됩니다. Tekton은 리소스 할당이나 파이프라인에 대한 기타 수정 사항을 재정의할 필요 없이 클러스터와 함께 scalable됩니다.,</li>
</ul>

<h4 id="tekton-구성요소">Tekton 구성요소</h4>

<p>Tekton은 다음 구성 요소로 구성됩니다.</p>

<p>•	<strong>Tekton Pipelines</strong>  은 Tekton의 기반입니다. CI/CD 파이프라인을 어셈블할 수 있는 빌딩 블록 역할을 하는 Kubernetes Custom Resources세트를 정의합니다.</p>

<p>•	<strong>Tekton Triggers</strong> 를 사용하면 이벤트를 기반으로 파이프라인을 인스턴스화할 수 있습니다. 예를 들어 GitHub 리포지토리에 대해 PR이 병합될 때마다 파이프라인의 인스턴스화 및 실행을 트리거할 수 있습니다. 특정 Tekton 트리거를 시작하는 사용자 인터페이스를 구축할 수도 있습니다.</p>

<p>•	<strong>Tekton CLI</strong> 는 Tekton과 상호 작용할 수 있도록 Kubernetes CLI 위에 구축된 tkn이라는 CLI를 제공합니다.</p>

<p>•	<strong>Tekton Dashboard</strong> 는 파이프라인 실행에 대한 정보를 표시하는 Tekton Pipelines용 웹 기반 유저 인터페이스입니다.</p>

<p>•	<strong>Tekton Catalog</strong> 는 자체 파이프라인에서 사용할 준비가 된 고품질의 커뮤니티에  Tekton 빌딩 블록(Task, Pipeline 등)의 리포지토리입니다.</p>

<p>•	<strong>Tekton Hub</strong> 는 Tekton 카탈로그에 액세스하기 위한 웹 기반 그래픽 인터페이스입니다.</p>

<p>•	<strong>Tekton Operator</strong> 는 Kubernetes 클러스터에서 Tekton 프로젝트를 설치, 업데이트 및 제거할 수 있는 Kubernetes Operator 패턴입니다.</p>

<h4 id="tekton-concept">Tekton Concept</h4>
<p>Tekton으로 무엇을 할 수 있습니까?</p>

<p>Tekton은 실행하려는 워크로드를 지정하는 Task개념을 도입했습니다.</p>

<p>•	<strong>Task</strong> – 일련의 순차적인 Step을 정의하고 각 Step은 특정 inputs 세트에 대해 특정 빌드 도구를 호출하고 다음 단계에서 입력으로 사용할 수 있는 특정 outputs세트를 생성합니다.</p>

<p>•	<strong>Pipeline</strong> - defines a series of ordered Tasks, and just like Steps in a Task, a Task in a Pipeline can use the output of a previously executed Task as its input. 일련의 순차적인 Tasks를 정의하고 작업의 단계와 마찬가지로 파이프라인의 작업은 이전에 실행된 작업의 출력을 입력으로 사용할 수 있습니다.</p>

<p>•	<strong>TaskRun</strong> - 특정 입력과 출력 집합을 생성하기 위해 지정한 Task를 인스턴스화합니다. 다시 말해서, Task는 Tekton에게 무엇을 해야 하는지 알려주고, TaskRun은 Tekton에게 무엇을 할 것인지와 빌드 플래그와 같이 정확히 수행하는 방법에 대한 추가 세부 정보를 알려줍니다.</p>

<p>•	<strong>PipelineRun</strong> - 특정 입력 집합에서 특정 대상에 대한 특정 출력 집합을 생성하기 위해 저정한 파이프라인을 인스턴스화합니다.</p>

<p>각 Task는 Kubernetes Pod로 실행됩니다. 따라서 기본적으로 파이프라인 내의 작업은 데이터를 공유하지 않습니다. 작업 간에 데이터를 공유하려면 다음 작업에서 출력을 사용할 수 있도록 하고 이전에 실행된 Task의 출력을 입력으로 사용하도록 명시적으로 각 작업을 구성해야 합니다.</p>

<h4 id="언제-어떤-것을-사용합니까">언제 어떤 것을 사용합니까?</h4>
<p>•	<strong>Task</strong> - 테스트 실행, 린트 실행 또는 Kaniko 캐시 구축과 같은 단순한 워크로드에 유용합니다. 하나의 Task는 Kubernetes Pod로 실행되고 단일 디스크를 사용하며 일반적으로 작업을 단순하게 유지합니다.</p>

<p>•	<strong>Pipeline</strong> - 정적 분석, 테스트, 빌드,  복잡한 프로젝트 프로젝트처럼 복잡한 워크로드에 유용합니다.</p>

<h4 id="개념모델">개념모델</h4>

<p>Tekton 구성요소 및 데이터 모델</p>

<ul>
  <li>Steps</li>
  <li>Tasks</li>
  <li>Pipelines</li>
</ul>

<p>Step은 Python 웹 앱에 대한 일부 단위 테스트 실행 또는 Java 프로그램 컴파일과 같은 CI/CD 워크플로의 작업입니다. Tekton은 제공한 컨테이너 이미지로 각 Step을 수행합니다. 예를 들어, 공식 Go 이미지를 사용하여 로컬 워크스테이션(go 빌드)에서와 동일한 방식으로 Go 프로그램을 컴파일할 수 있습니다.</p>

<h4 id="task는-순차적인-step의-모음입니다">Task는 순차적인 Step의 모음입니다.</h4>

<p>Tekton은 Kubernetes Pod형식으로 Task를 실행하며, 여기서 각 Step은 Pod에서 실행 중인 컨테이너가 됩니다. 이 디자인을 사용하면 여러 관련 단계에 대한 공유 환경을 설정할 수 있습니다. 예를 들어 Task의 각 Step내에서 액세스할 수 있는 Kubernetes 볼륨을 작업에 탑재할 수 있습니다.</p>

<figure style="width: 50%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-task.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="pipeline-은-순차적-task의-모음입니다">Pipeline 은 순차적 Task의 모음입니다.</h4>
<p>Tekton은 모든 작업을 수집하여 DAG(방향성 비순환 그래프)로 연결하고 그래프를 순서대로 실행합니다. 즉, 여러 Kubernetes 포드를 생성하고 각 포드가 원하는 대로 성공적으로 실행을 완료하도록 합니다. Tekton은 개발자에게 프로세스에 대한 완전한 제어 권한을 부여합니다. 작업 완료의 fan-in/fan-out 시나리오를 설정하거나, 불안정한 테스트가 있는 경우 자동으로 재시도하도록 Tekton에 요청하거나, 작업이 진행하기 전에 충족해야 하는 조건을 지정할 수 있습니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-pipeline.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>Task 및 Pipeline은 Kubernetes 클러스터에서 사용자 지정 리소스로 지정됩니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-pipeline-on-kubernetes.png" alt="" />
  <figcaption></figcaption>
</figure>

<h2 id="taskrun-and-pipelinerun">TaskRun and PipelineRun</h2>
<p>PipelineRun은 이름에서 알 수 있듯이 특정 Pipeline을 실행입니다. 예를 들어 Tekton에 CI/CD 워크플로를 하루에 두 번 실행하도록 요청할 수 있으며 각 실행은 Kubernetes 클러스터에서 추적할 수 있는 PipelineRun 리소스가 됩니다. PipelineRuns를 사용하여 각 작업 실행의 세부 사항을 포함하여 CI/CD 워크플로의 상태를 볼 수 있습니다.</p>

<p>마찬가지로 taskRun은 지정한 Task를 실행합니다. TaskRun은 Pipeline인 외부에서 지정한 Task를 선택하여 실행 할 수 있습니다. 이를 통해 작업의 각 단계 실행에 대한 세부 사항을 볼 수 있습니다.</p>

<p>. <strong>TaskRuns 및 pipelineRuns</strong> 는 Task 및 Pipeline 리소스를 연결합니다. 설계를 통해 개발자는 다양한 입력 및 출력에 대해 Task와Pipleline을 재사용할 수 있습니다.</p>

<p>taskRuns 또는 pipelineRuns를 수동으로 생성하여 Tekton Task 또는 Pipeline을 즉시 실행하도록 트리거할 수 있습니다. 또는 Tekton Triggers와 같은 Tekton 구성 요소에 요청 시 자동으로 실행을 생성하도록 요청할 수 있습니다. 예를 들어 새 pull 요청이 git 리포지토리에 체크인될 때마다 파이프라인을 실행할 수 있습니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-arch.png" alt="" />
  <figcaption></figcaption>
</figure>

<h2 id="tekton-작동원리">Tekton 작동원리</h2>

<p>Tekton Pipelines는 각 단계를 래핑하여 작동합니다. 보다 구체적으로 말하면 Tekton Pipelines는 단계 컨테이너에 진입점 바이너리를 주입하여 시스템이 준비될 때 지정한 명령을 실행합니다.
Tekton Pipelines는 Kubernetes annotation을 사용하여 파이프라인의 상태를 추적합니다. 이러한 annotation은 Kubernetes Downward API를 사용하여 파일 형식으로 각 step컨테이너 내부에 투영됩니다. 진입점 바이너리는 투영된 파일을 자세히 관찰하고 특정 주석이 파일로 나타나는 경우에만 제공된 명령을 시작합니다.</p>

<p>예를 들어, Tekton에 작업에서 두 단계를 연속적으로 실행하도록 요청하면 두 번째 step컨테이너에 주입된 진입점 바이너리는 첫 번째 단계 컨테이너가 성공적으로 완료되었다고 annotation이 보고할 때까지 유휴 상태로 기다립니다.</p>

<p>또한 Tekton Pipelines는 입력 리소스 검색 및 blob 스토리지 솔루션에 대한 출력 업로드와 같은 특정 기본 제공 기능을 지원하기 위해 일부 컨테이너가 Step컨테이너 전후에 자동으로 실행되도록 예약합니다. taskRuns 및 pipelineRuns를 통해 실행 상태도 추적할 수 있습니다. 시스템은 또한 단계 컨테이너를 실행하기 전에 환경을 설정하기 위해 여러 다른 작업을 수행합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[Tekton 개요 Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다. Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.]]></summary></entry><entry><title type="html">Cloud-Native CI/CD 이해</title><link href="http://localhost:4000/devops/cloud-native-cicd/" rel="alternate" type="text/html" title="Cloud-Native CI/CD 이해" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/cloud-native-cicd</id><content type="html" xml:base="http://localhost:4000/devops/cloud-native-cicd/"><![CDATA[<h2 id="cloud-native-cicd-이해">Cloud-Native CI/CD 이해</h2>
<p>클라우드 네이티브 소프트웨어 개발이 무엇을 의미하는지 더 잘 이해 했으므로 CI/CD 파이프 라인의 맥락에서 그것이 무엇을 의미하는지 살펴 보겠습니다.</p>

<p>Cloud-Native CI/CD는 세 가지 원칙을 기반</p>

<ul>
  <li><strong>Containers</strong></li>
  <li><strong>Serverless</strong></li>
  <li><strong>DevOps</strong></li>
</ul>

<p><strong>Containers</strong></p>

<p>CI/CD의 컨텍스트에서 클라우드 네이티브는 모든 것이 컨테이너 내에서 실행되어야 함을 의미합니다. 응용 프로그램을 테스트하거나 패키지하기 위해 코드베이스에서 완료되는 각 작업은 자체 격리된 컨테이너에서 수행해야 합니다.
이러한 컨테이너를 사용하면 모든 팀 멤버 또는 자동화된 시스템이 동일한 작업을 실행하고 동일한 예측 가능한 최종 결과를 얻을 수 있습니다.
이는 또한 일부 소스 코드에서 특정 작업을 실행하는 데 필요한 모든 런타임 및 구성이 파이프라인이 실행될 때마다 항상 동일하다는 것을 의미합니다. 이렇게 하면 파이프라인의 안정성이 향상되며 필요한 도구를 설치하는 데 시스템 관리자의 도움이 필요하지 않습니다.</p>

<p><strong>Serverless</strong></p>

<p>클라우드 네이티브 CI/CD에 대해 이야기할 때 서버리스는 Azure 함수 또는 AWS 람다와 같은 서비스로서의 함수를 의미하지 않습니다. 중앙 CI 엔진을 유지 관리하고 관리할 필요 없이 온디맨드로 실행하고 확장하는 것입니다.
소프트웨어 개발자는 리소스 할당 내에서 파이프라인을 효율적이고 신속하게 편집하고 실행할 수 있어야 합니다. 파이프라인을 관리하는 중앙 시스템에서 관리자 권한이 필요하지 않습니다. 클라우드 네이티브 CI/CD 솔루션이 성공하려면 모든 시스템 사용자가 액세스하고 관리할 수 있어야 합니다.</p>

<p>Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다.
Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.</p>

<p><strong>DevOps</strong></p>

<p>클라우드 네이티브 CI/CD는 DevOps를 염두에 두고 구축해야 합니다. 팀이 다른 팀을 대신하여 배달 파이프라인을 관리하는 중앙 우수 센터 팀에 의존하지 않고 애플리케이션과 함께 배달 파이프라인을 소유할 수 있도록 해야 합니다.
소프트웨어 개발 팀이 파이프라인을 담당하도록 하면 파이프라인을 관리하고 항상 필요한 최신 소프트웨어를 사용하여 작업을 수행할 수 있습니다.
이것이 바로 Kubernetes에서 기본적으로 실행되는 클라우드 네이티브 CI/CD 솔루션인 Tekton을 만들게 된 원칙입니다. 다음 섹션에서는 Tekton에 대해 자세히 알아보고 클라우드 네이티브 사고 방식으로 CI/CD에 접근한 방법을 알아봅니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[Cloud-Native CI/CD 이해 클라우드 네이티브 소프트웨어 개발이 무엇을 의미하는지 더 잘 이해 했으므로 CI/CD 파이프 라인의 맥락에서 그것이 무엇을 의미하는지 살펴 보겠습니다.]]></summary></entry><entry><title type="html">Tekton First Pipeline</title><link href="http://localhost:4000/devops/tekton-first-pipeline/" rel="alternate" type="text/html" title="Tekton First Pipeline" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/tekton-first-pipeline</id><content type="html" xml:base="http://localhost:4000/devops/tekton-first-pipeline/"><![CDATA[<h2 id="first-pipeline-작성">First Pipeline 작성</h2>
<p>Tekton을 이용하여 Pipeline을 작성하는 것을 실습합니다.</p>

<p>Pipeline은 CI/CD 워크플로의 일부로 특정 실행 순서로 정렬된 일련의 Task를 정의합니다.</p>

<p>이번에는 first Pipeline을 작성할 것입니다, First Pipeline에서는 이전에 작성했던 Hello World! 그리고 goodbye World! Task를 포함하는 Pipeline을 작성합니다.</p>

<p>goodbye task를 다음과 같이 작성하고 적용합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> goodbye.yaml
</code></pre></div></div>

<p>[goodbye.yaml]</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span> 
<span class="na">kind</span><span class="pi">:</span> <span class="s">Task</span> 
<span class="na">metadata</span><span class="pi">:</span> 
  <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye</span> 
      <span class="na">image</span><span class="pi">:</span> <span class="s">alpine</span> 
      <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">#!/bin/sh</span>
        <span class="s">echo "Goodbye World!" </span>
</code></pre></div></div>

<h2 id="pipeline-작성">Pipeline 작성</h2>
<p>hello-world 타스크와 goodbye 타스크를 연결하는 pipeline을 작성합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-goodbye-pipeline.yaml
</code></pre></div></div>

<p>[hello-goodbye-pipeline.yaml]</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span> 
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pipeline</span> 
<span class="na">metadata</span><span class="pi">:</span> 
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-goodbye-pipeline</span> 
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">tasks</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">first-task</span> 
      <span class="na">taskRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye-task</span>
      <span class="na">taskRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">goodbye</span>
</code></pre></div></div>

<h2 id="pipeline-run-작성">Pipeline Run 작성</h2>
<p>Pipeline을 인스턴스화하는 Pipeline Run을 다음과 같이 작성해서 Kubernetes에 적용합니다.</p>

<p>[hello-goodbye-pipeline-run.yaml]</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-goodbye-pipeline-run.yaml
</code></pre></div></div>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span> 
<span class="na">kind</span><span class="pi">:</span> <span class="s">PipelineRun</span> 
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-goodbye-pipeline-run</span> 
<span class="na">spec</span><span class="pi">:</span> 
  <span class="na">pipelineRef</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">hello-goodbye-pipeline</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[First Pipeline 작성 Tekton을 이용하여 Pipeline을 작성하는 것을 실습합니다.]]></summary></entry><entry><title type="html">Getting Start Tekton</title><link href="http://localhost:4000/devops/tekton-getting-start/" rel="alternate" type="text/html" title="Getting Start Tekton" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/devops/tekton-getting-start</id><content type="html" xml:base="http://localhost:4000/devops/tekton-getting-start/"><![CDATA[<h2 id="getting-start-tekton">Getting start tekton</h2>
<p>API에서 Task Kubernetes resource type이 Task로 표현되는 Task는 작업에 필요한 로직을 수행하기 위해 순차적으로 실행되는 일련의 Step을 정의합니다. 모든 Task는 Kubernetes 클러스터에서 포드로 실행되며 각 Step은 Pod내에 자신의 컨테이너에서 실행됩니다.</p>

<p>아래와 같이 Hello World Task를 작성하여 Kubernetes 에 적용합니다.</p>

<h2 id="hello-world-task-작성">Hello World Task 작성</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-world.yaml
</code></pre></div></div>

<p>[hello-world.yaml 파일]</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Task</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">alpine</span>
      <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">#!/bin/sh</span>
        <span class="s">echo "Hello World"</span>
</code></pre></div></div>
<h2 id="run-task-작성">Run Task 작성</h2>
<p>이 Task를 실행하려면 TaskRun을 사용하여 인스턴스화해야 합니다. 
다음 내용으로 hello-world-run.yaml이라는 다른 파일을 만듭니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> hello-world-run.yaml
</code></pre></div></div>

<p>[hello-world-run.yaml]</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">tekton.dev/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">TaskRun</span> 
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world-run</span>
<span class="na">spec</span><span class="pi">:</span> 
  <span class="na">taskRef</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">hello-world</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="devops" /><category term="tekton" /><summary type="html"><![CDATA[Getting start tekton API에서 Task Kubernetes resource type이 Task로 표현되는 Task는 작업에 필요한 로직을 수행하기 위해 순차적으로 실행되는 일련의 Step을 정의합니다. 모든 Task는 Kubernetes 클러스터에서 포드로 실행되며 각 Step은 Pod내에 자신의 컨테이너에서 실행됩니다.]]></summary></entry><entry><title type="html">Deploy mysql8.0 to kubernetes</title><link href="http://localhost:4000/kubernetes/deploy-to-kubernetes/" rel="alternate" type="text/html" title="Deploy mysql8.0 to kubernetes" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/kubernetes/deploy-to-kubernetes</id><content type="html" xml:base="http://localhost:4000/kubernetes/deploy-to-kubernetes/"><![CDATA[<h2 id="mysql-yaml-파일">MYSQL YAML 파일</h2>
<p>Kubernetes에 테스트용으로 Stand-alone으로 배포하여 테스트하기 위한 YAML 파일입니다.</p>

<pre><code class="language-YAML">apiVersion: v1
kind: Service
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  ports:
    - port: 3306
  selector:
    app: mysql
  type: NodePort
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pv-claim
  labels:
    app: mysql
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: nfs-standard
  volumeMode: Filesystem
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  selector:
    matchLabels:
      app: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - image: mysql:8.0
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: ROOT_PASSWORD
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-persistent-storage
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: mysql-pv-claim
</code></pre>]]></content><author><name>Jaeguk Yun</name></author><category term="kubernetes" /><category term="mysql" /><summary type="html"><![CDATA[MYSQL YAML 파일 Kubernetes에 테스트용으로 Stand-alone으로 배포하여 테스트하기 위한 YAML 파일입니다.]]></summary></entry><entry><title type="html">Install local storage class to kubernetes</title><link href="http://localhost:4000/kubernetes/local-storage-class-on-ks/" rel="alternate" type="text/html" title="Install local storage class to kubernetes" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/kubernetes/local-storage-class-on-ks</id><content type="html" xml:base="http://localhost:4000/kubernetes/local-storage-class-on-ks/"><![CDATA[<p>kubernetes 에서 storage class가 없는 경우 실습을 목적으로 
local-storage를 설치하여 실습을 목적으로 하는 경우 사용해 볼 수 있는 provisioner 입니다로</p>
<h2 id="install-local-storage-class-to-kubernetes">Install local-storage-class to kubernetes</h2>
<p>Kubernetes에 local-storage 를 사용하고자 하는 경우 다음의 설정을 하면 storage class를 사용할 수 있습니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Namespace</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-role</span>
<span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">nodes"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">persistentvolumeclaims"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">configmaps"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">get"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">list"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">watch"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">endpoints"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">persistentvolumes"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">pods"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">*"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">events"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">create"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">patch"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">storage.k8s.io"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">storageclasses"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">get"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">list"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">watch"</span> <span class="pi">]</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRoleBinding</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-bind</span>
<span class="na">roleRef</span><span class="pi">:</span>
  <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-role</span>
<span class="na">subjects</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
    <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">serviceAccountName</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">rancher/local-path-provisioner:v0.0.22</span>
          <span class="na">imagePullPolicy</span><span class="pi">:</span> <span class="s">IfNotPresent</span>
          <span class="na">command</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="s">local-path-provisioner</span>
            <span class="pi">-</span> <span class="s">--debug</span>
            <span class="pi">-</span> <span class="s">start</span>
            <span class="pi">-</span> <span class="s">--config</span>
            <span class="pi">-</span> <span class="s">/etc/config/config.json</span>
          <span class="na">volumeMounts</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-volume</span>
              <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/etc/config/</span>
          <span class="na">env</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">POD_NAMESPACE</span>
              <span class="na">valueFrom</span><span class="pi">:</span>
                <span class="na">fieldRef</span><span class="pi">:</span>
                  <span class="na">fieldPath</span><span class="pi">:</span> <span class="s">metadata.namespace</span>
      <span class="na">volumes</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-volume</span>
          <span class="na">configMap</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-config</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">standard</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">rancher.io/local-path</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">WaitForFirstConsumer</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>

<span class="nn">---</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-config</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">config.json</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">{</span>
            <span class="s">"nodePathMap":[</span>
            <span class="s">{</span>
                    <span class="s">"node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",</span>
                    <span class="s">"paths":["/opt/local-path-provisioner"]</span>
            <span class="s">}</span>
            <span class="s">]</span>
    <span class="s">}</span>
  <span class="na">setup</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">#!/bin/sh</span>
    <span class="s">set -eu</span>
    <span class="s">mkdir -m 0777 -p "$VOL_DIR"</span>
  <span class="na">teardown</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">#!/bin/sh</span>
    <span class="s">set -eu</span>
    <span class="s">rm -rf "$VOL_DIR"</span>
  <span class="na">helperPod.yaml</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">apiVersion: v1</span>
    <span class="s">kind: Pod</span>
    <span class="s">metadata:</span>
      <span class="s">name: helper-pod</span>
    <span class="s">spec:</span>
      <span class="s">containers:</span>
      <span class="s">- name: helper-pod</span>
        <span class="s">image: busybox</span>
        <span class="s">imagePullPolicy: IfNotPresent</span>
</code></pre></div></div>

<ul>
  <li>test-pod 배포</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">test-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">test-pod</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nfs-pvc</span>
        <span class="na">mountPath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/mydata"</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nfs-pvc</span>
      <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
        <span class="na">claimName</span><span class="pi">:</span> <span class="s">my-pvc</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-pvc</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">standard</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">128Mi</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="kubernetes" /><category term="kubernetes" /><category term="storageclass" /><summary type="html"><![CDATA[kubernetes 에서 storage class가 없는 경우 실습을 목적으로 local-storage를 설치하여 실습을 목적으로 하는 경우 사용해 볼 수 있는 provisioner 입니다로 Install local-storage-class to kubernetes Kubernetes에 local-storage 를 사용하고자 하는 경우 다음의 설정을 하면 storage class를 사용할 수 있습니다.]]></summary></entry><entry><title type="html">Airflow DAG 선언 유형</title><link href="http://localhost:4000/workflow/dag-type/" rel="alternate" type="text/html" title="Airflow DAG 선언 유형" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/dag-type</id><content type="html" xml:base="http://localhost:4000/workflow/dag-type/"><![CDATA[<h2 id="install-local-storage-class-to-kubernetes">Install local-storage-class to kubernetes</h2>
<p>Apache Airflow에서 DAG을 선언하는 다음과 같이 3가 유형이 있습니다.</p>

<ol>
  <li>with DAG</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">DAG</span> <span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="err">”</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span>
       <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
       <span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span>
       <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">op</span> <span class="o">=</span> <span class="n">DummyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="err">”</span><span class="n">dummy</span><span class="err">”</span><span class="p">)</span>

</code></pre></div></div>

<ul>
  <li>with DAG 예시</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.providers.http.sensors.http</span> <span class="kn">import</span> <span class="n">HttpSensor</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"owner"</span><span class="p">:</span> <span class="s">"airflow"</span><span class="p">,</span>
    <span class="s">"email_on_failure"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">"email_on_retry"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">"email"</span><span class="p">:</span> <span class="s">"admin@localhost.com"</span><span class="p">,</span>
    <span class="s">"retries"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s">"retry_delay"</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span><span class="s">"date_pipeline_ex02"</span><span class="p">,</span> 
  <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">17</span><span class="p">),</span>
  <span class="n">schedule_interval</span><span class="o">=</span><span class="s">"@daily"</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
  <span class="n">is_api_available</span> <span class="o">=</span> <span class="n">HttpSensor</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'is_api_available'</span><span class="p">,</span>
    <span class="n">http_conn_id</span><span class="o">=</span><span class="s">'user_api'</span><span class="p">,</span>
    <span class="n">endpoint</span><span class="o">=</span><span class="s">'api/'</span>
  <span class="p">)</span>

  <span class="n">is_api_available</span>
</code></pre></div></div>

<ol>
  <li>표준 생성자 DAG</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dag</span><span class="o">=</span><span class="n">DAG</span> <span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="err">”</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span>
       <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
       <span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span>
       <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> 
<span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="err">”</span><span class="n">start</span><span class="err">”</span><span class="p">,</span> <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span>

</code></pre></div></div>
<ul>
  <li>표준 생성자 DAG 예시</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">import</span> <span class="nn">pendulum</span>

<span class="c1"># timezone 한국시간으로 변경
</span><span class="n">kst</span> <span class="o">=</span> <span class="n">pendulum</span><span class="p">.</span><span class="n">timezone</span><span class="p">(</span><span class="s">"Asia/Seoul"</span><span class="p">)</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"start_date"</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="s">"catchup"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
    <span class="s">"myFirstDAG"</span><span class="p">,</span>
    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s">"@daily"</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">hello_airflow</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Hello airflow"</span><span class="p">)</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"bash"</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">"echo Hello airflow"</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t1</span>
</code></pre></div></div>

<ol>
  <li>데코레이터 DAG(@)</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@dag (
    dag_id='data_pipeline_ex05',
       default_args = default_args,
       schedule_interval='@daily'
) 
def hello_dag():
    @task
    def hello_task1():
        print('Hello World')

    hello_task1()

# DAG 호출
dag = hello_dag()

</code></pre></div></div>
<ul>
  <li>데코레이터 예시</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from airflow.decorators import dag, task 
from datetime import datetime, timedelta 
from airflow.utils.dates import days_ago 

default_args = {
    "start_date": days_ago(1),
    "catchup": False,
}

@dag (
    dag_id='data_pipeline_ex05',
       default_args = default_args,
       schedule_interval='@daily'
) 
def hello_dag():
    @task
    def hello_task1():
        print('Hello World')

    hello_task1()

# DAG 호출
dag = hello_dag()
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Install local-storage-class to kubernetes Apache Airflow에서 DAG을 선언하는 다음과 같이 3가 유형이 있습니다.]]></summary></entry></feed>