<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-11-27T17:28:37+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Cloud Native Journey</title><subtitle>Software Engineer/Architect</subtitle><author><name>Jaeguk Yun</name></author><entry><title type="html">Airflow task</title><link href="http://localhost:4000/workflow/tasks/" rel="alternate" type="text/html" title="Airflow task" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/tasks</id><content type="html" xml:base="http://localhost:4000/workflow/tasks/"><![CDATA[<h2 id="airflow-task">Airflow Task</h2>
<p>Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다.
Task는</p>

<ul>
  <li>Operator : 지정한 작읍을 수행하는 Operator</li>
  <li>Sensor : 어떤 조건이 만족하는지 주기적으로 스캔이 필요할 때 사용하며 조건이 만족하는 경우 Task가 수행.</li>
  <li>Hook : DB나 서비스 같은 외부 시스템과 통신하기 위한 인터페이스를 제공하여 연결 상태를 유지
등을 사용할 수 있습니다.</li>
</ul>

<h2 id="task-instance">Task Instance</h2>

<p>DAG실행될 때 마다 Task Instance를 생성하여 Executor로 전달하여 해당작업을 실행합니다. 그리고 해당 Task Instance를 다시 Metadata로 보내서 상태를 업데이트하며, Task Instance의 작업이 남아 있으면 Executor로 다시 보내집니다. 작업이 완료가 되면 스케줄러에게 보냅니다.
Operator
Operator는 task를 어떻게 실행시킬지 정의합니다. 하나의 워크플로우안에서 한개 이상의 task를 정의할 수 있습니다. 하나의 Task가 하나의 Operator라고 할 수 있다.
Operator는 Action Operator와 Transfer Operator로 구분됩니다.</p>

<ul>
  <li>Action Operator : 작업을 수행하거나 다른 시스템에 작업을 수행하도록 trigger합니다.</li>
  <li>Transfer Operator : 특정 시스템에 다른 시스템으로 데이터를 이동</li>
  <li>Sensor Operator : 특정 조건에 일치할 때 까지 기다렸다가, 만족되면 이후 과정을 진행하도록 기다려는 Operator.</li>
</ul>

<p>Airflow는 기본 Operator는 Bash와 Python Operator가 대표적이며 그외 많은 Operator를 지원하고 있습니다. Operator에 공통적으로 **kwargs라는 keywoard Arguments를 전달하는 부분이 있으며, DAG을 정의할 때 default_args 전달하는 것처럼 전달합니다.</p>

<h2 id="task-dependencies">Task Dependencies</h2>
<p>Apache Airflow의 DAG 내에 task들의 dependency를 설정함으로써 task 실행 순서와 병렬 실행 task들 등을 정의할 수 있습니다.
Task 간 의존성은 다음과 같이</p>
<ul>
  <li>set_downstream 또는 » 기호</li>
  <li>set_upstream 또는 « 기호 
같은 함수 또는 기호로 설정할 수 있습니다. 
set_downstream 는 Task 실행 후에 수행할 task를 설정
set_upstream 는 Task 실행 전에 수행할 task를 설정</li>
</ul>

<p>예시)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>

<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">dedent</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="s">'data_pipeline_ex09'</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">description</span><span class="o">=</span><span class="s">'Hello world'</span><span class="p">,</span>
  <span class="n">schedule_interval</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">hello</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s">'Hello!'</span><span class="p">)</span>

<span class="n">t1</span> <span class="o">=</span>  <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'echo_hello'</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo "Hi from bash operator"'</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">python_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"python_task"</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">hello</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">templated_command</span> <span class="o">=</span> <span class="n">dedent</span><span class="p">(</span>
  <span class="s">"""
  
  """</span>
<span class="p">)</span>

<span class="n">t3</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'templated'</span><span class="p">,</span>
  <span class="n">bash_command</span><span class="o">=</span><span class="n">templated_command</span><span class="p">,</span>
  <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'my_param'</span><span class="p">:</span> <span class="s">'Parameter I passed in'</span><span class="p">},</span>
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="n">t2</span> <span class="o">&gt;&gt;</span> <span class="n">t3</span>
<span class="c1"># t1.set_downstream(t2) 
# t3.set_upstream(t2)
</span></code></pre></div></div>

<p>t1, t2, t3 task가 순차적으로 실행됩니다.</p>

<p>t1.set_downstream(t2)</p>

<p>t2는 성공적으로 실행되는 t1에 의존하여 실행됩니다.</p>

<p>t2.set_upstream(t1)</p>

<p>비트 시프트 연산자를 사용하여 작업을 연결할 수도 있습니다.:
t1 » t2</p>

<p>그리고 비트 시프트 연산자와의 업스트림 종속성 표기:
t2 « t1</p>

<p>여러 종속성을 연결하는 것은 비트 시프트 연산자로 간결해집니다.
t1 » t2 » t3</p>

<p>작업 목록을 종속성으로 설정할 수도 있습니다. 
이러한 작업은 모두 동일한 효과를 갖습니다</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t1</span><span class="p">.</span><span class="n">set_downstream</span><span class="p">([</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">])</span>
<span class="n">t1</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]</span>
<span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">t1</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="task" /><summary type="html"><![CDATA[Airflow Task Task는 airflow의 기본 실행단위로 한개 이상의 Task를 이용해서 하나의 DAG을 정의합니다. Task간 순서를 표현하기 위해 작업간 «(스트림업), »(스트림다운) 종속성을 설정하여 합니다. Task는]]></summary></entry><entry><title type="html">Tekton 개요</title><link href="http://localhost:4000/workflow/tekton-overveiew/" rel="alternate" type="text/html" title="Tekton 개요" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/tekton-overveiew</id><content type="html" xml:base="http://localhost:4000/workflow/tekton-overveiew/"><![CDATA[<h2 id="tekton-개요">Tekton 개요</h2>
<p>Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다.
Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.</p>

<h4 id="cicd는-누가-사용하는가">CI/CD는 누가 사용하는가?</h4>
<ul>
  <li>Tekton 사용자는 일반적으로 다음 범주에 속합니다.조직의 개발자를 위한 CI/CD 시스템을 구축하는 플랫폼 엔지니어.</li>
  <li>CI/CD 시스템을 사용하여 작업을 수행하는 개발자.</li>
</ul>

<h4 id="tekton-장점">Tekton 장점</h4>

<p>Tekton은 CI/CD 시스템의 빌드/배포 사용자에게 다음과 같은 이점을 제공합니다.</p>
<ul>
  <li><strong>사용자 정의 가능</strong>. TEKTON 엔터티는 완전히 사용자 CUSTOMIZING 할 수 있어, 높은 수준의 유연성을 지워합니다. 플랫폼 엔지니어는 개발자가 다양한 시나리오에서 사용할 수 있도록 매우 상세한 빌딩 블록 카탈로그를 정의할 수 있습니다.</li>
  <li><strong>재사용 가능</strong>. TEKTON 엔티티는 완전히 이식 가능하므로, 일단 정의되면 조직 내의 모든 사용자가 주어진 파이프라인을 사용하고 해당 구성 요소를 재사용할 수 있습니다. 이를 통해 개발자는 “바퀴를 다시 발명”하지 않고도 복잡한 파이프라인을 신속하게 구축할 수 있다.</li>
  <li><strong>확장 가능</strong>. Tekton 카탈로그는 Tekton 빌딩 블록의 커뮤니티 중심 리포지토리입니다. Tekton 카탈로그에서 미리 만들어진 구성 요소를 사용하여 새 파이프라인을 빠르게 생성하고 기존 파이프라인을 확장할 수 있습니다.</li>
  <li><strong>표준화</strong>. Tekton은 Kubernetes 클러스터에 확장으로 설치 및 실행되며 잘 확립된 Kubernetes 리소스 모델을 사용합니다. Tekton 워크로드는 Kubernetes 컨테이너내에서 실행됩니다.</li>
  <li><strong>Scalable</strong>. 워크로드 용량을 늘리려면 클러스터에 노드를 추가하기만 하면 됩니다. Tekton은 리소스 할당이나 파이프라인에 대한 기타 수정 사항을 재정의할 필요 없이 클러스터와 함께 scalable됩니다.,</li>
</ul>

<h4 id="tekton-구성요소">Tekton 구성요소</h4>

<p>Tekton은 다음 구성 요소로 구성됩니다.</p>

<p>•	<strong>Tekton Pipelines</strong>  은 Tekton의 기반입니다. CI/CD 파이프라인을 어셈블할 수 있는 빌딩 블록 역할을 하는 Kubernetes Custom Resources세트를 정의합니다.</p>

<p>•	<strong>Tekton Triggers</strong> 를 사용하면 이벤트를 기반으로 파이프라인을 인스턴스화할 수 있습니다. 예를 들어 GitHub 리포지토리에 대해 PR이 병합될 때마다 파이프라인의 인스턴스화 및 실행을 트리거할 수 있습니다. 특정 Tekton 트리거를 시작하는 사용자 인터페이스를 구축할 수도 있습니다.</p>

<p>•	<strong>Tekton CLI</strong> 는 Tekton과 상호 작용할 수 있도록 Kubernetes CLI 위에 구축된 tkn이라는 CLI를 제공합니다.</p>

<p>•	<strong>Tekton Dashboard</strong> 는 파이프라인 실행에 대한 정보를 표시하는 Tekton Pipelines용 웹 기반 유저 인터페이스입니다.</p>

<p>•	<strong>Tekton Catalog</strong> 는 자체 파이프라인에서 사용할 준비가 된 고품질의 커뮤니티에  Tekton 빌딩 블록(Task, Pipeline 등)의 리포지토리입니다.</p>

<p>•	<strong>Tekton Hub</strong> 는 Tekton 카탈로그에 액세스하기 위한 웹 기반 그래픽 인터페이스입니다.</p>

<p>•	<strong>Tekton Operator</strong> 는 Kubernetes 클러스터에서 Tekton 프로젝트를 설치, 업데이트 및 제거할 수 있는 Kubernetes Operator 패턴입니다.</p>

<h4 id="tekton-concept">Tekton Concept</h4>
<p>Tekton으로 무엇을 할 수 있습니까?</p>

<p>Tekton은 실행하려는 워크로드를 지정하는 Task개념을 도입했습니다.</p>

<p>•	<strong>Task</strong> – 일련의 순차적인 Step을 정의하고 각 Step은 특정 inputs 세트에 대해 특정 빌드 도구를 호출하고 다음 단계에서 입력으로 사용할 수 있는 특정 outputs세트를 생성합니다.</p>

<p>•	<strong>Pipeline</strong> - defines a series of ordered Tasks, and just like Steps in a Task, a Task in a Pipeline can use the output of a previously executed Task as its input. 일련의 순차적인 Tasks를 정의하고 작업의 단계와 마찬가지로 파이프라인의 작업은 이전에 실행된 작업의 출력을 입력으로 사용할 수 있습니다.</p>

<p>•	<strong>TaskRun</strong> - 특정 입력과 출력 집합을 생성하기 위해 지정한 Task를 인스턴스화합니다. 다시 말해서, Task는 Tekton에게 무엇을 해야 하는지 알려주고, TaskRun은 Tekton에게 무엇을 할 것인지와 빌드 플래그와 같이 정확히 수행하는 방법에 대한 추가 세부 정보를 알려줍니다.</p>

<p>•	<strong>PipelineRun</strong> - 특정 입력 집합에서 특정 대상에 대한 특정 출력 집합을 생성하기 위해 저정한 파이프라인을 인스턴스화합니다.</p>

<p>각 Task는 Kubernetes Pod로 실행됩니다. 따라서 기본적으로 파이프라인 내의 작업은 데이터를 공유하지 않습니다. 작업 간에 데이터를 공유하려면 다음 작업에서 출력을 사용할 수 있도록 하고 이전에 실행된 Task의 출력을 입력으로 사용하도록 명시적으로 각 작업을 구성해야 합니다.</p>

<h4 id="언제-어떤-것을-사용합니까">언제 어떤 것을 사용합니까?</h4>
<p>•	<strong>Task</strong> - 테스트 실행, 린트 실행 또는 Kaniko 캐시 구축과 같은 단순한 워크로드에 유용합니다. 하나의 Task는 Kubernetes Pod로 실행되고 단일 디스크를 사용하며 일반적으로 작업을 단순하게 유지합니다.</p>

<p>•	<strong>Pipeline</strong> - 정적 분석, 테스트, 빌드,  복잡한 프로젝트 프로젝트처럼 복잡한 워크로드에 유용합니다.</p>

<h4 id="개념모델">개념모델</h4>

<p>Tekton 구성요소 및 데이터 모델</p>

<ul>
  <li>Steps</li>
  <li>Tasks</li>
  <li>Pipelines</li>
</ul>

<p>Step은 Python 웹 앱에 대한 일부 단위 테스트 실행 또는 Java 프로그램 컴파일과 같은 CI/CD 워크플로의 작업입니다. Tekton은 제공한 컨테이너 이미지로 각 Step을 수행합니다. 예를 들어, 공식 Go 이미지를 사용하여 로컬 워크스테이션(go 빌드)에서와 동일한 방식으로 Go 프로그램을 컴파일할 수 있습니다.</p>

<h4 id="task는-순차적인-step의-모음입니다">Task는 순차적인 Step의 모음입니다.</h4>

<p>Tekton은 Kubernetes Pod형식으로 Task를 실행하며, 여기서 각 Step은 Pod에서 실행 중인 컨테이너가 됩니다. 이 디자인을 사용하면 여러 관련 단계에 대한 공유 환경을 설정할 수 있습니다. 예를 들어 Task의 각 Step내에서 액세스할 수 있는 Kubernetes 볼륨을 작업에 탑재할 수 있습니다.</p>

<figure style="width: 50%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-task.png" alt="" />
  <figcaption></figcaption>
</figure>

<h4 id="pipeline-은-순차적-task의-모음입니다">Pipeline 은 순차적 Task의 모음입니다.</h4>
<p>Tekton은 모든 작업을 수집하여 DAG(방향성 비순환 그래프)로 연결하고 그래프를 순서대로 실행합니다. 즉, 여러 Kubernetes 포드를 생성하고 각 포드가 원하는 대로 성공적으로 실행을 완료하도록 합니다. Tekton은 개발자에게 프로세스에 대한 완전한 제어 권한을 부여합니다. 작업 완료의 fan-in/fan-out 시나리오를 설정하거나, 불안정한 테스트가 있는 경우 자동으로 재시도하도록 Tekton에 요청하거나, 작업이 진행하기 전에 충족해야 하는 조건을 지정할 수 있습니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-pipeline.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>Task 및 Pipeline은 Kubernetes 클러스터에서 사용자 지정 리소스로 지정됩니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-pipeline-on-kubernetes.png" alt="" />
  <figcaption></figcaption>
</figure>

<h2 id="taskrun-and-pipelinerun">TaskRun and PipelineRun</h2>
<p>PipelineRun은 이름에서 알 수 있듯이 특정 Pipeline을 실행입니다. 예를 들어 Tekton에 CI/CD 워크플로를 하루에 두 번 실행하도록 요청할 수 있으며 각 실행은 Kubernetes 클러스터에서 추적할 수 있는 PipelineRun 리소스가 됩니다. PipelineRuns를 사용하여 각 작업 실행의 세부 사항을 포함하여 CI/CD 워크플로의 상태를 볼 수 있습니다.</p>

<p>마찬가지로 taskRun은 지정한 Task를 실행합니다. TaskRun은 Pipeline인 외부에서 지정한 Task를 선택하여 실행 할 수 있습니다. 이를 통해 작업의 각 단계 실행에 대한 세부 사항을 볼 수 있습니다.</p>

<p>. <strong>TaskRuns 및 pipelineRuns</strong> 는 Task 및 Pipeline 리소스를 연결합니다. 설계를 통해 개발자는 다양한 입력 및 출력에 대해 Task와Pipleline을 재사용할 수 있습니다.</p>

<p>taskRuns 또는 pipelineRuns를 수동으로 생성하여 Tekton Task 또는 Pipeline을 즉시 실행하도록 트리거할 수 있습니다. 또는 Tekton Triggers와 같은 Tekton 구성 요소에 요청 시 자동으로 실행을 생성하도록 요청할 수 있습니다. 예를 들어 새 pull 요청이 git 리포지토리에 체크인될 때마다 파이프라인을 실행할 수 있습니다.</p>

<figure style="width: 70%" class="align-center">
  <img src="http://localhost:4000/assets/images/01-tekton-arch.png" alt="" />
  <figcaption></figcaption>
</figure>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="tekton" /><summary type="html"><![CDATA[Tekton 개요 Tekton은 CI/CD(지속적 통합 및 지속적 전달) 시스템을 만들기 위한 Kubernetes 네이티브 오픈 소스 프레임워크입니다. 여러 클라우드 공급자 또는 하이브리드 환경에서 애플리케이션을 구축, 테스트 및 배포하는 데 최적화되어 있습니다. Tekton은 CI/CD 파이프라인을 구축하기 위한 클라우드 네이티브 솔루션입니다. 빌딩 블록을 제공하는 Tekton 파이프 라인과 Tekton Cli 및 Tekton 카탈로그와 같은 지원 구성 요소로 구성되어 Tekton을 완벽한 생태계로 만듭니다. Tekton은 Linux Foundation 프로젝트인 CD Foundation의 일부입니다.]]></summary></entry><entry><title type="html">Install local storage class to kubernetes</title><link href="http://localhost:4000/kubernetes/local-storage-class-on-ks/" rel="alternate" type="text/html" title="Install local storage class to kubernetes" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/kubernetes/local-storage-class-on-ks</id><content type="html" xml:base="http://localhost:4000/kubernetes/local-storage-class-on-ks/"><![CDATA[<p>kubernetes 에서 storage class가 없는 경우 실습을 목적으로 
local-storage를 설치하여 실습을 목적으로 하는 경우 사용해 볼 수 있는 provisioner 입니다로</p>
<h2 id="install-local-storage-class-to-kubernetes">Install local-storage-class to kubernetes</h2>
<p>Kubernetes에 local-storage 를 사용하고자 하는 경우 다음의 설정을 하면 storage class를 사용할 수 있습니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Namespace</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-role</span>
<span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">nodes"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">persistentvolumeclaims"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">configmaps"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">get"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">list"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">watch"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">endpoints"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">persistentvolumes"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">pods"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">*"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">events"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">create"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">patch"</span> <span class="pi">]</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">storage.k8s.io"</span> <span class="pi">]</span>
    <span class="na">resources</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">storageclasses"</span> <span class="pi">]</span>
    <span class="na">verbs</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">get"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">list"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">watch"</span> <span class="pi">]</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRoleBinding</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-bind</span>
<span class="na">roleRef</span><span class="pi">:</span>
  <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-role</span>
<span class="na">subjects</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">kind</span><span class="pi">:</span> <span class="s">ServiceAccount</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
    <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">serviceAccountName</span><span class="pi">:</span> <span class="s">local-path-provisioner-service-account</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-provisioner</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">rancher/local-path-provisioner:v0.0.22</span>
          <span class="na">imagePullPolicy</span><span class="pi">:</span> <span class="s">IfNotPresent</span>
          <span class="na">command</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="s">local-path-provisioner</span>
            <span class="pi">-</span> <span class="s">--debug</span>
            <span class="pi">-</span> <span class="s">start</span>
            <span class="pi">-</span> <span class="s">--config</span>
            <span class="pi">-</span> <span class="s">/etc/config/config.json</span>
          <span class="na">volumeMounts</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-volume</span>
              <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/etc/config/</span>
          <span class="na">env</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">POD_NAMESPACE</span>
              <span class="na">valueFrom</span><span class="pi">:</span>
                <span class="na">fieldRef</span><span class="pi">:</span>
                  <span class="na">fieldPath</span><span class="pi">:</span> <span class="s">metadata.namespace</span>
      <span class="na">volumes</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">config-volume</span>
          <span class="na">configMap</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-config</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">standard</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">rancher.io/local-path</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">WaitForFirstConsumer</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>

<span class="nn">---</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">local-path-config</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">nfs</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">config.json</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">{</span>
            <span class="s">"nodePathMap":[</span>
            <span class="s">{</span>
                    <span class="s">"node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",</span>
                    <span class="s">"paths":["/opt/local-path-provisioner"]</span>
            <span class="s">}</span>
            <span class="s">]</span>
    <span class="s">}</span>
  <span class="na">setup</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">#!/bin/sh</span>
    <span class="s">set -eu</span>
    <span class="s">mkdir -m 0777 -p "$VOL_DIR"</span>
  <span class="na">teardown</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">#!/bin/sh</span>
    <span class="s">set -eu</span>
    <span class="s">rm -rf "$VOL_DIR"</span>
  <span class="na">helperPod.yaml</span><span class="pi">:</span> <span class="pi">|-</span>
    <span class="s">apiVersion: v1</span>
    <span class="s">kind: Pod</span>
    <span class="s">metadata:</span>
      <span class="s">name: helper-pod</span>
    <span class="s">spec:</span>
      <span class="s">containers:</span>
      <span class="s">- name: helper-pod</span>
        <span class="s">image: busybox</span>
        <span class="s">imagePullPolicy: IfNotPresent</span>
</code></pre></div></div>

<ul>
  <li>test-pod 배포</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">test-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">test-pod</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nfs-pvc</span>
        <span class="na">mountPath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/mydata"</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nfs-pvc</span>
      <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
        <span class="na">claimName</span><span class="pi">:</span> <span class="s">my-pvc</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-pvc</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">standard</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">128Mi</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="kubernetes" /><category term="kubernetes" /><category term="storageclass" /><summary type="html"><![CDATA[kubernetes 에서 storage class가 없는 경우 실습을 목적으로 local-storage를 설치하여 실습을 목적으로 하는 경우 사용해 볼 수 있는 provisioner 입니다로 Install local-storage-class to kubernetes Kubernetes에 local-storage 를 사용하고자 하는 경우 다음의 설정을 하면 storage class를 사용할 수 있습니다.]]></summary></entry><entry><title type="html">Airflow Xcon</title><link href="http://localhost:4000/workflow/xcon/" rel="alternate" type="text/html" title="Airflow Xcon" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/xcon</id><content type="html" xml:base="http://localhost:4000/workflow/xcon/"><![CDATA[<h2 id="airflow-xcon">Airflow Xcon</h2>
<p>Airflow task간 데이터를 공유가 필요할 때,  데이터를 공유하기 위해 push, pull 을 사용하여 값을 전달하고, 값을 가져오기 위해 사용합니다. Airflow에서는 여러 분산환경에서 서로 다른 Work에서 Task가 실행 될 수 있기 때문에 Xcom을 사용합니다. Variable과 비슷하지만 Xcom은 특정 DAG내부에서만 공유되는 특징이 있습니다. 여러 DAG에서 공유해서 사용하려면 Variable을 사용해야 합니다.  PythonOperator를 사용하면 return값이 자동으로 Xcom에 push됩니다.</p>

<p>예시)</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">push_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
<span class="n">contenxt</span><span class="p">[</span><span class="err">‘</span><span class="n">task_instance</span><span class="err">’</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">변수명</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">전달할</span> <span class="n">value</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">pull_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">[</span><span class="err">‘</span><span class="n">ti</span><span class="err">’</span><span class="p">].</span><span class="n">xcom_pull</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">변수명</span><span class="p">,</span> <span class="n">task_ids</span><span class="o">=</span><span class="n">대상</span> <span class="n">Task이름</span><span class="p">)</span>

</code></pre></div></div>
<ul>
  <li>Xcon 예시</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span>

<span class="c1"># Utils 
</span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span><span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'start_date'</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="s">'retries'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="s">'retry_delay'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
  <span class="s">'schedule_interval'</span><span class="p">:</span> <span class="s">'@daily'</span><span class="p">,</span>
  <span class="s">'tags'</span><span class="p">:</span> <span class="s">'training'</span><span class="p">,</span>
  <span class="s">'catchup'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span> 

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
  <span class="n">dag_id</span><span class="o">=</span><span class="s">'xcom_dag'</span><span class="p">,</span> 
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span> 
<span class="p">)</span> 

<span class="k">def</span> <span class="nf">xcom_push</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">context</span><span class="p">[</span><span class="s">'task_instance'</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">'pushed_value'</span><span class="p">,</span>
    <span class="n">value</span><span class="o">=</span><span class="s">'xcom_push_test_message!'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">pull_func</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">):</span>
  <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">[</span><span class="s">'ti'</span><span class="p">].</span><span class="n">xcom_pull</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">'pushed_value'</span><span class="p">,</span> 
    <span class="n">task_ids</span><span class="o">=</span><span class="s">'push_by_xcom'</span>
  <span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="n">push_by_xcom</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'push_by_xcom'</span><span class="p">,</span>
  <span class="n">python_callable</span><span class="o">=</span><span class="n">xcom_push</span><span class="p">,</span> 
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">pull_task1</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'pull_example1'</span><span class="p">,</span>
  <span class="n">python_callable</span><span class="o">=</span><span class="n">pull_func</span><span class="p">,</span> 
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">pull_task2</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
  <span class="n">task_id</span><span class="o">=</span><span class="s">'pull_example2'</span><span class="p">,</span>
  <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo ""'</span><span class="p">,</span> 
  <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">push_by_xcom</span> <span class="o">&gt;&gt;</span> <span class="n">pull_task1</span> <span class="o">&gt;&gt;</span> <span class="n">pull_task2</span>
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Airflow Xcon Airflow task간 데이터를 공유가 필요할 때, 데이터를 공유하기 위해 push, pull 을 사용하여 값을 전달하고, 값을 가져오기 위해 사용합니다. Airflow에서는 여러 분산환경에서 서로 다른 Work에서 Task가 실행 될 수 있기 때문에 Xcom을 사용합니다. Variable과 비슷하지만 Xcom은 특정 DAG내부에서만 공유되는 특징이 있습니다. 여러 DAG에서 공유해서 사용하려면 Variable을 사용해야 합니다. PythonOperator를 사용하면 return값이 자동으로 Xcom에 push됩니다.]]></summary></entry><entry><title type="html">Airflow DAG 선언 유형</title><link href="http://localhost:4000/workflow/dag-type/" rel="alternate" type="text/html" title="Airflow DAG 선언 유형" /><published>2022-11-27T00:00:00+09:00</published><updated>2022-11-27T00:00:00+09:00</updated><id>http://localhost:4000/workflow/dag-type</id><content type="html" xml:base="http://localhost:4000/workflow/dag-type/"><![CDATA[<h2 id="install-local-storage-class-to-kubernetes">Install local-storage-class to kubernetes</h2>
<p>Apache Airflow에서 DAG을 선언하는 다음과 같이 3가 유형이 있습니다.</p>

<ol>
  <li>with DAG</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">DAG</span> <span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="err">”</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span>
       <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
       <span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span>
       <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span> 
  <span class="n">op</span> <span class="o">=</span> <span class="n">DummyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="err">”</span><span class="n">dummy</span><span class="err">”</span><span class="p">)</span>

</code></pre></div></div>

<ul>
  <li>with DAG 예시</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">airflow.providers.http.sensors.http</span> <span class="kn">import</span> <span class="n">HttpSensor</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"owner"</span><span class="p">:</span> <span class="s">"airflow"</span><span class="p">,</span>
    <span class="s">"email_on_failure"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">"email_on_retry"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">"email"</span><span class="p">:</span> <span class="s">"admin@localhost.com"</span><span class="p">,</span>
    <span class="s">"retries"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s">"retry_delay"</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span><span class="s">"date_pipeline_ex02"</span><span class="p">,</span> 
  <span class="n">start_date</span><span class="o">=</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">17</span><span class="p">),</span>
  <span class="n">schedule_interval</span><span class="o">=</span><span class="s">"@daily"</span><span class="p">,</span>
  <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
  <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
  <span class="n">is_api_available</span> <span class="o">=</span> <span class="n">HttpSensor</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'is_api_available'</span><span class="p">,</span>
    <span class="n">http_conn_id</span><span class="o">=</span><span class="s">'user_api'</span><span class="p">,</span>
    <span class="n">endpoint</span><span class="o">=</span><span class="s">'api/'</span>
  <span class="p">)</span>

  <span class="n">is_api_available</span>
</code></pre></div></div>

<ol>
  <li>표준 생성자 DAG</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dag</span><span class="o">=</span><span class="n">DAG</span> <span class="p">(</span>
    <span class="n">dag_id</span><span class="o">=</span><span class="err">”</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span>
       <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
       <span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span>
       <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> 
<span class="n">start</span> <span class="o">=</span> <span class="n">EmptyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="err">”</span><span class="n">start</span><span class="err">”</span><span class="p">,</span> <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span>

</code></pre></div></div>
<ul>
  <li>표준 생성자 DAG 예시</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span> 
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span> 
<span class="kn">from</span> <span class="nn">airflow.operators.bash</span> <span class="kn">import</span> <span class="n">BashOperator</span> 
<span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span> 
<span class="kn">import</span> <span class="nn">pendulum</span>

<span class="c1"># timezone 한국시간으로 변경
</span><span class="n">kst</span> <span class="o">=</span> <span class="n">pendulum</span><span class="p">.</span><span class="n">timezone</span><span class="p">(</span><span class="s">"Asia/Seoul"</span><span class="p">)</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"start_date"</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="s">"catchup"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
    <span class="s">"myFirstDAG"</span><span class="p">,</span>
    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="s">"@daily"</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">hello_airflow</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Hello airflow"</span><span class="p">)</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">"bash"</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="s">"echo Hello airflow"</span><span class="p">,</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span>
<span class="p">)</span>

<span class="n">t1</span>
</code></pre></div></div>

<ol>
  <li>데코레이터 DAG(@)</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@dag (
    dag_id='data_pipeline_ex05',
       default_args = default_args,
       schedule_interval='@daily'
) 
def hello_dag():
    @task
    def hello_task1():
        print('Hello World')

    hello_task1()

# DAG 호출
dag = hello_dag()

</code></pre></div></div>
<ul>
  <li>데코레이터 예시</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from airflow.decorators import dag, task 
from datetime import datetime, timedelta 
from airflow.utils.dates import days_ago 

default_args = {
    "start_date": days_ago(1),
    "catchup": False,
}

@dag (
    dag_id='data_pipeline_ex05',
       default_args = default_args,
       schedule_interval='@daily'
) 
def hello_dag():
    @task
    def hello_task1():
        print('Hello World')

    hello_task1()

# DAG 호출
dag = hello_dag()
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><summary type="html"><![CDATA[Install local-storage-class to kubernetes Apache Airflow에서 DAG을 선언하는 다음과 같이 3가 유형이 있습니다.]]></summary></entry><entry><title type="html">Apache Airflow - DAG</title><link href="http://localhost:4000/workflow/apache-airflow-dag/" rel="alternate" type="text/html" title="Apache Airflow - DAG" /><published>2022-11-20T00:00:00+09:00</published><updated>2022-11-20T00:00:00+09:00</updated><id>http://localhost:4000/workflow/apache-airflow-dag</id><content type="html" xml:base="http://localhost:4000/workflow/apache-airflow-dag/"><![CDATA[<h2 id="dag-directed-acyclic-graph">DAG (Directed Acyclic Graph)</h2>
<p>DAG(Directed Acyclic Graph)는 Airflow에서 실행할 작업들을 순서에 맞게 구성한 워크플로를 의미합니다.
DAG을 구성하는 태스크(Task)라고 하며, 화살표 방향으로 순차, 병렬 실행합니다.
DAG은 Python 코드로 정의하며 $AIRFLOW_HOME/dags폴더에 위치합니다.</p>

<ul>
  <li>default_args</li>
</ul>

<p>DAG에서 사용될 Attribute를 default_args로 분리하여 정의하여 DAG  파라메터로 전달합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="err">“</span><span class="n">start_date</span><span class="err">”</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="err">“</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span> 
<span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span> 
<span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span> 
<span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
</code></pre></div></div>

<ul>
  <li>catchup</li>
</ul>

<p>DAG을 생성할 때 전달하는 파라메터로써 Airflow에서는 default로 true로 설정되어 있는 옵션입니다. catchup기본 설정은 airflow.cfg 파일에 catchup_by_default값을 변경합니다. 
catchup은 DAG이 스케줄링에서 dagrun을 실행하지 못했던 것을 채우기 위한 기능으로 backfill 이라고도 합니다.</p>

<ul>
  <li>Cron Preset</li>
</ul>

<p>DAG을 실행하기 위한 스케줄링에 사용하며, DAG을 정의할때 schedule_interval인자로 전달합니다.</p>

<p><img src="/assets/images/03-cron-preset.png" alt="transparent black overlay" /></p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/04-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>예시 )</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/05-ex-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<ul>
  <li>스케줄링 간격 정의(timedelta)</li>
</ul>

<p>스케줄 간격 정의 – 빈도 기반
cron expression은 간격(빈도)마다 스케줄을 정의할 수는 없습니다. 예를 들면 DAG을 3일에 한번씩 실행하는 cron을 정의하는 것은 어렵습니다. Airflow에서는 timedelta 인스턴스를 지원하여 빈도기반 스케줄링을 정의할 수 있습니다.
예를 들면 3일마다 또는 3시간마다 실행하도록 하는 것을 timedelta 인스턴스를 활용할 수 있습니다.</p>

<h2 id="dag-runs">DAG Runs</h2>
<p>DAG Run은 Task 인스턴스들을 DAG 에 정의된 특정 execution_date에 실행하는 DAG의 인스턴스입니다. 
execution_date는 Airflow 2.2에서는 local_date로 변경되었습니다.
DAG는 Airflow 스케줄러 또는 외부 Trigger에 의해 실행될 수 있습니다. 
Execution_date가 다른 여개 개의 DAG가 동시에 실행될 수 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/06-dag-runs.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>DAG Runs를 선택하면 다음과 같이 실행 중이거나 종료된 DAG의 실행이력이 표시됩니다. CLI 명령어는 다음과 같습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>airflow dags list
</code></pre></div></div>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="DAG" /><summary type="html"><![CDATA[DAG (Directed Acyclic Graph) DAG(Directed Acyclic Graph)는 Airflow에서 실행할 작업들을 순서에 맞게 구성한 워크플로를 의미합니다. DAG을 구성하는 태스크(Task)라고 하며, 화살표 방향으로 순차, 병렬 실행합니다. DAG은 Python 코드로 정의하며 $AIRFLOW_HOME/dags폴더에 위치합니다.]]></summary></entry><entry><title type="html">Apache Airflow - 개요</title><link href="http://localhost:4000/workflow/apache-airflow-overview/" rel="alternate" type="text/html" title="Apache Airflow - 개요" /><published>2022-11-20T00:00:00+09:00</published><updated>2022-11-20T00:00:00+09:00</updated><id>http://localhost:4000/workflow/apache-airflow-overview</id><content type="html" xml:base="http://localhost:4000/workflow/apache-airflow-overview/"><![CDATA[<p>Airflow는 2014년 10월 Airbnb의 Maxime Beauchemin에 의해 시작되었다. 
첫 번째 커밋부터 오픈 소스였으며 공식적으로 Airbnb GitHub에 포함되었으며 2015년 6월에 발표되었습니다. 
이 프로젝트는 2016년 3월 Apache Software Foundation의 인큐베이터 프로그램에 합류했으며 재단은 2019년 1월 Apache Airflow를 최상위 프로젝트로 발표, 현재 아파치 재단에서 관리중인 오픈소스 프로젝트입니다.</p>

<p>Airflow는</p>

<ul>
  <li>워크플로를 작성, 예약 및 모니터링하는 플랫폼이며,</li>
  <li>Workflow를 정의하고 실행,</li>
  <li>반복 된 작업을 자동화</li>
</ul>

<p>하기 위해 사용합니다.</p>

<p>각 작업들은 DAG(Directed Acycle Graph)를 통해 구조화하며, 
DAG에 연결된 화살표 방향 순서대로 작업을 실행하고, 순차/병렬 실행이 가능합니다.
Airflow는 일정 시간 단위마다 주기적으로 실행하는 스케줄링 기능을 지원합니다.
또한 Backfill 이라는 과거 특정시점부터 현재까지 작업을 처리하는 것도 지원합니다.</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="workflow" /><summary type="html"><![CDATA[Airflow는 2014년 10월 Airbnb의 Maxime Beauchemin에 의해 시작되었다. 첫 번째 커밋부터 오픈 소스였으며 공식적으로 Airbnb GitHub에 포함되었으며 2015년 6월에 발표되었습니다. 이 프로젝트는 2016년 3월 Apache Software Foundation의 인큐베이터 프로그램에 합류했으며 재단은 2019년 1월 Apache Airflow를 최상위 프로젝트로 발표, 현재 아파치 재단에서 관리중인 오픈소스 프로젝트입니다.]]></summary></entry><entry><title type="html">Apache Airflow - 구조</title><link href="http://localhost:4000/workflow/apache-airflow-structure/" rel="alternate" type="text/html" title="Apache Airflow - 구조" /><published>2022-11-20T00:00:00+09:00</published><updated>2022-11-20T00:00:00+09:00</updated><id>http://localhost:4000/workflow/apache-airflow-structure</id><content type="html" xml:base="http://localhost:4000/workflow/apache-airflow-structure/"><![CDATA[<h2 id="airflow-구조">Airflow 구조</h2>
<p>Airflow는 다음과 같은 구조를 가지고 있습니다.</p>
<ul>
  <li>Scheduler : Airflow의 DAG와 작업들을 모니터링하고 실행순서와 상태관리</li>
  <li>Worker : Airflow의 작업을 실행하는 공간</li>
  <li>Metadata database : Airflow에서 실행할 작업에 관한 정보를 저장</li>
  <li>Webserver: Airflow의 User Interface 에 해당하는 dashboard</li>
  <li>DAG Directory</li>
</ul>

<p><img src="/assets/images/01-airflow-architecture.png" alt="transparent black overlay" /></p>

<p>Airflow는 스케줄러가 DAG Directory를 주기적으로 스캔하고 새로운 DAG 파일이 생성되면 Worker에서 실행합니다.</p>

<h2 id="airflow-webserver">Airflow Webserver</h2>
<p>Webserver에 로그인하면 다음과 같이 DAG 목록이 출력됩니다.</p>
<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/02-dag-list.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>조## DAG (Directed Acyclic Graph) 
DAG(Directed Acyclic Graph)는 Airflow에서 실행할 작업들을 순서에 맞게 구성한 워크플로를 의미합니다.
DAG을 구성하는 태스크(Task)라고 하며, 화살표 방향으로 순차, 병렬 실행합니다.
DAG은 Python 코드로 정의하며 $AIRFLOW_HOME/dags폴더에 위치합니다.</p>

<ul>
  <li>default_args</li>
</ul>

<p>DAG에서 사용될 Attribute를 default_args로 분리하여 정의하여 DAG  파라메터로 전달합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
  <span class="err">“</span><span class="n">start_date</span><span class="err">”</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">with</span> <span class="n">DAG</span><span class="p">(</span>
<span class="err">“</span><span class="n">myFirstDag</span><span class="err">”</span><span class="p">,</span> 
<span class="n">schedule_interval</span><span class="o">=</span><span class="err">”</span><span class="o">@</span><span class="n">daily</span><span class="err">”</span><span class="p">,</span> 
<span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span> 
<span class="n">catchup</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
</code></pre></div></div>

<ul>
  <li>catchup</li>
</ul>

<p>DAG을 생성할 때 전달하는 파라메터로써 Airflow에서는 default로 true로 설정되어 있는 옵션입니다. catchup기본 설정은 airflow.cfg 파일에 catchup_by_default값을 변경합니다. 
catchup은 DAG이 스케줄링에서 dagrun을 실행하지 못했던 것을 채우기 위한 기능으로 backfill 이라고도 합니다.</p>

<ul>
  <li>Cron Preset</li>
</ul>

<p>DAG을 실행하기 위한 스케줄링에 사용하며, DAG을 정의할때 schedule_interval인자로 전달합니다.</p>

<p><img src="/assets/images/03-cron-preset.png" alt="transparent black overlay" /></p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/04-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>예시 )</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/05-ex-cron-preset.png" alt="" />
  <figcaption></figcaption>
</figure>

<ul>
  <li>스케줄링 간격 정의(timedelta)</li>
</ul>

<p>스케줄 간격 정의 – 빈도 기반
cron expression은 간격(빈도)마다 스케줄을 정의할 수는 없습니다. 예를 들면 DAG을 3일에 한번씩 실행하는 cron을 정의하는 것은 어렵습니다. Airflow에서는 timedelta 인스턴스를 지원하여 빈도기반 스케줄링을 정의할 수 있습니다.
예를 들면 3일마다 또는 3시간마다 실행하도록 하는 것을 timedelta 인스턴스를 활용할 수 있습니다.</p>

<h2 id="dag-runs">DAG Runs</h2>
<p>DAG Run은 Task 인스턴스들을 DAG 에 정의된 특정 execution_date에 실행하는 DAG의 인스턴스입니다. 
execution_date는 Airflow 2.2에서는 local_date로 변경되었습니다.
DAG는 Airflow 스케줄러 또는 외부 Trigger에 의해 실행될 수 있습니다. 
Execution_date가 다른 여개 개의 DAG가 동시에 실행될 수 있습니다.</p>

<figure style="width: 100%" class="align-left">
  <img src="http://localhost:4000/assets/images/06-dag-runs.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>DAG Runs를 선택하면 다음과 같이 실행 중이거나 종료된 DAG의 실행이력이 표시됩니다. CLI 명령어는 다음과 같습니다.
airflow dags list</p>]]></content><author><name>Jaeguk Yun</name></author><category term="workflow" /><category term="airflow" /><category term="workflow" /><summary type="html"><![CDATA[Airflow 구조 Airflow는 다음과 같은 구조를 가지고 있습니다. Scheduler : Airflow의 DAG와 작업들을 모니터링하고 실행순서와 상태관리 Worker : Airflow의 작업을 실행하는 공간 Metadata database : Airflow에서 실행할 작업에 관한 정보를 저장 Webserver: Airflow의 User Interface 에 해당하는 dashboard DAG Directory]]></summary></entry></feed>